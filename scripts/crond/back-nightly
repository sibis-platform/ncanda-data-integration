#!/bin/bash -l

##
##  See COPYING file distributed along with the ncanda-data-integration package
##  for the copyright and license terms
##


IMAGE_PROCESS_FLAG=1
PIPELINE_UPDATE_FLAG=1

# Set the SIBIS environment variable to the data integration repo
export SIBIS=`realpath $(dirname $0)/../../`
export SCRIPT_LABEL="back-nightly"

# When generating a release do not update pipeline
# exit 0
[ -r $HOME/.bashrc ] && . $HOME/.bashrc

# Import some useful functions
. $(dirname $0)/crontools.sh

#
# Previously front-hourly (all code after harvester runs)
#

LOG_DIR=${SIBIS_LOG_DIR}/back-nightly

# Over the weekend run full version
# 01/24/2024, JD: Start runnning full version on Thursday
Day=$(date +%a)
if [ "$Day" == "Thu" ]; then 
    update_args=""
    echo "${SCRIPT_LABEL}:Info: update_visit_data checks all forms"
else 
    update_args+=" --missing-only"
fi 

# DEBUGGING right now 
# update_args+=" --missing-only"

run_scripts=`ps -ef | grep [s]cripts/import/laptops/update_visit_data | grep -v vi | grep -v emacs`
if [ `echo $?` == 0 ]; then 
   num_scripts=`printf "$run_scripts\n" | wc -l`
   echo "${SCRIPT_LABEL}:Info: skipped update_visit_data as %num_scripts instance(s) of it are already running:"
   printf "$run_scripts"
else
   # Copy data from import_laptops to data_entry
   catch_output_email "${SCRIPT_LABEL}:Import Laptop: Data Import (update_visit_data)" ${SIBIS}/scripts/import/laptops/update_visit_data -p -t ${LOG_DIR} --max-days-after-visit 120 ${update_args}
fi 

catch_output_email "${SCRIPT_LABEL}:REDCap: Update Form Status (update_bulk_forms)" ${SIBIS}/scripts/redcap/update_bulk_forms -p -t ${LOG_DIR}

# -e {7,8,9}y_visit_arm_1
catch_output_email "${SCRIPT_LABEL}:REDCap: Date-event associations (wrong_date_association)" ${SIBIS}/scripts/redcap/wrong_date_associations.py -p -q 

#
# Previouly front-nighlty
#

######################################
# XNAT / Imaging Related
######################################

if [ ${IMAGE_PROCESS_FLAG} == 1 ]; then
  # Check MR session names etc. in XNAT
  catch_output_email "${SCRIPT_LABEL}:XNAT: Check Session Names (check_object_names)" ${SIBIS}/scripts/xnat/check_object_names -p -t ${LOG_DIR} --send-mail --zip-root ${SIBIS_DVD_DIR}

  # Check for new or updated sessions and
  catch_output_email "${SCRIPT_LABEL}:XNAT: Check New Sessions (check_new_sessions)" ${SIBIS}/scripts/xnat/check_new_sessions --qc-csv --qc-json --send-mail-to ncanda-image-qc@sri.com -p -t ${LOG_DIR}
  # --qc-csv ${SIBIS_ANALYSIS_DIR}/beta/image-qc/scan_qc.csv

  # Check whether any MR sessions are missing corresponding phantom scans
  catch_output_email "${SCRIPT_LABEL}:XNAT: Check Phantom Scan (check_phantom_scans)" ${SIBIS}/scripts/xnat/check_phantom_scans.py --check-all -p -t ${LOG_DIR}

  # Run fMRI QA on subjects ## Currently disabled because it isn't looked at but takes a long time to run
  ##catch_output_email "XNAT: Subject fMRI QA Messages" ${SIBIS}/scripts/xnat/fmri_qa_subjects
else 
    echo "${SCRIPT_LABEL}: Warning: Image data is not updated !"   
fi 

#
#
# if on instance is running then it is at least has a count of 2 ! Not sure why
run_scripts=`ps -ef | grep [c]rond/back-nightly | grep /bin/bash`
if [ `echo $?` == 0 ]; then
    num_scripts=`printf "$run_scripts\n" | wc -l`
    if [ $num_scripts -gt 2 ]; then 
	echo "${SCRIPT_LABEL}:Info: Not running all of back-nightly as $num_scripts instances of it are already running:"
	printf "$run_scripts"
	exit 0
    fi 
else 
   echo "${SCRIPT_LABEL}:Warning: No back-nightly running ! Something is wrong with querry"
fi 

 
######################################
# REDCap / NP / Clinical Data Related
######################################

# Import data from UPenn into REDCap
catch_output_email "${SCRIPT_LABEL}:Import WebCNP: Ingest to REDCap (cnp2redcap)" ${SIBIS}/scripts/import/webcnp/cnp2redcap -p -t ${LOG_DIR} --last-3-months

# Check whether subject birth dates and gender match checksum digit, plus whether all subjects on study arms appear in main arm also
catch_output_email "${SCRIPT_LABEL}:REDCap: Subject ID Checks (check_subject_ids)" ${SIBIS}/scripts/redcap/check_subject_ids -p -t ${LOG_DIR}

# Check (and update, if necessary) drinking exception status
catch_output_email "${SCRIPT_LABEL}:REDCap: Undeclared Drinking Exceptions (check_exceptions)" ${SIBIS}/scripts/redcap/check_exceptions -p -t ${LOG_DIR} --update-fn

# Generate SVN Reports
#catch_output_email "${SCRIPT_LABEL}:REDCap: SVN Reports Dashboards (svn_execute)" ${SIBIS}/scripts/dashboards/svn_execute.sh

#
# Original back-nightly
#

if [ ${PIPELINE_UPDATE_FLAG} == 1 ]; then
    if [ ${IMAGE_PROCESS_FLAG} == 1 ]; then
	# Import data from XNAT into REDCap and feed image analysis pipeline
	catch_output_email "${SCRIPT_LABEL}:REDCap: Import MR to Pipeline (import_mr_sessions)" ${SIBIS}/scripts/redcap/import_mr_sessions -p --max-days-after-visit 120 --pipeline-root-dir ${SIBIS_CASES_DIR} --run-pipeline-script ${SIBIS_IMAGE_SCRIPTS_DIR}/bin/ncanda_all_pipelines -t ${LOG_DIR}
    fi 

    # Export NP/clinical/dempgraphics data into image analysis pipeline directories
    #   This needs to come AFTER "import_mr_sessions", because otherwise we cannot get ages-at-MRI from REDCap for the export.
    catch_output_email "${SCRIPT_LABEL}:REDCap: Import REDCap to Pipeline (export_measures)" ${SIBIS}/scripts/redcap/export_measures -p --datadict-dir ${SIBIS_DATADICT_DIR}/redcap --locked_form_report ${SIBIS_CASES_DIR}

    # Update CSV summary files for the working pipeline
    catch_output_email "${SCRIPT_LABEL}:Reporting: Pipeline Summaries (update_csv_summaries)" ${SIBIS}/scripts/reporting/update_csv_summaries ${SIBIS_CASES_DIR}/ ${SIBIS_SUMMARIES_DIR}

    # Check which cases haven't been touched by export_measures (Only running on weekly basis)
    if [ -z "$update_args" ]; then
    :
#        catch_output_email "${SCRIPT_LABEL}: REDCap: Export Measures Check (check_updated_cases)" ${SIBIS_PYTHON_PATH}/sibispy/cmds/check_updated_cases.py -p -d ${SIBIS_CASES_DIR}
    fi 
else 
    echo "back-nightly: Warning: Pipeline is not updated !"   
fi 

# Remove pyxnat cache directory to conserve space
catch_output_email "${SCRIPT_LABEL}:Drop pyXNAT Cache Directory" rm -rf /tmp/RestAPI@localhost_8080.xnat /tmp/cache

# echo "${SCRIPT_LABEL}:Info: Completed back nightly" 

