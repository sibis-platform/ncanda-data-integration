#!/usr/bin/env python

##
##  See COPYING file distributed along with the ncanda-data-integration package
##  for the copyright and license terms
##

from __future__ import print_function
from builtins import str
import os
import re
import stat
import time
import argparse
import datetime
import sys

import sibispy
from sibispy import sibis_email 
from sibispy import sibislogger as slog
from sibispy import utils as sutils


session = sibispy.Session()
if not session.configure():
    print("Error: session configure file was not found")

    sys.exit()

server_address = str(session.get_xnat_server_address())

parser = argparse.ArgumentParser( description="Find new MR sessions in XNAT, check for missing and duplicate scans, and list all sessions with questionable scans." )
parser.add_argument("-v", "--verbose", action="store_true", default=False, help="Verbose operation.")
parser.add_argument("-m", "--send-mail", action="store_true", default=False, help="Send emails with problem reports to users and site admin.")
parser.add_argument("-e", "--eidlist", default =False, action='store',help="Allows for a subset of scans to be selected for export - seperate eids by comma")
parser.add_argument( "-a", "--check-all", help="Check all subjects and sessions, regardless of date.", action="store_true")
parser.add_argument( "-W", "--last-week", help="Check all subjects and sessions that were modified within the last week.", action="store_true")
parser.add_argument( "-M", "--last-month", help="Check all subjects and sessions that were modified within the last month (more precisely: the last 31 days).", action="store_true")
parser.add_argument( "--no-update", help="Do not update the persistent data stored on the XNAT server (e.g., last run date, list of flagged sessions).", action="store_true")
parser.add_argument("--zip-root", default='/var/tmp/burn2dvd', help="Root directory to create ZIP archives with T1w and T2w DICOM files for clinical reading.")
parser.add_argument("--zip-none", action="store_true", default=False, help="Do not create any ZIP archives (T1w and T2w DICOM files for clinical reading).")
parser.add_argument("--zip-all", action="store_true", default=False, help="Create ZIP archives (T1w and T2w DICOM files for clinical reading) for all sessions listed in eidlist, regardless of whether or not they have been processed before.")
parser.add_argument("-p", "--post-to-github", help="Post all issues to GitHub instead of std out.", action="store_true")
parser.add_argument("-t","--time-log-dir",
                    help="If set then time logs are written to that directory",
                    action="store",
                    default=None)
args = parser.parse_args()

# Setup logging
slog.init_log(args.verbose, args.post_to_github,'NCANDA XNAT: Check Object Names Message', 'check_object_names', args.time_log_dir)
slog.startTimer1()

#
# Export T1w and T2w DICOM files to ZIP archive
#
def export_t1t2_to_zip( experiment, experiment_label,xnat_dir):
    # Get list of all scans in the session
    scan_dirs = []
    for scan in experiment.scans.listing:
        scan_type = scan.type
        if ('t1spgr' in scan_type) or ('mprage' in scan_type) or ('t2fse' in scan_type):
            for _, val in sutils.objwalk(scan.fulldata):
                match = re.match('.*(' + xnat_dir + '/.*)scan_.*_catalog.xml.*', scan.xnat_session.get(scan.uri, query={'format':'xml'}).text, re.DOTALL)
                if match:
                    # Replace the path stored in XNAT with the NFS mount path.
                    xnat_path = match.group(1).replace('storage/XNAT',
                                                    'ncanda-xnat')
                    scan_dirs.append(xnat_path)
                    break

    if len( scan_dirs ) > 0:
        if args.verbose:
            print("INFO: exporting T1w and T2w DICOM files for",experiment,"/",experiment_label)

        # Remove common prefix to make archive more flat
        if len( scan_dirs ) > 1:
            basedir = os.path.commonprefix( scan_dirs )

            if not os.path.exists(basedir):
                # commonprefix gathered incorrect base dir, walk back up to parent directory
                basedir = os.path.dirname(basedir) + '/'
            scan_dirs_rel = [ re.sub( basedir, '', sdir ) for sdir in scan_dirs ]
        else:
            basedir = re.sub( 'SCANS/.*', 'SCANS/', scan_dirs[0] )
            scan_dirs_rel = [ re.sub( '.*/SCANS/', '', scan_dirs[0] ) ]

        # Get today's date for naming
        date_today = time.strftime( '%Y-%m-%d', time.localtime() )

        # Check if output directory is already there
        outdir = os.path.join( args.zip_root, date_today )
        if not os.path.exists( outdir ):
            os.makedirs( outdir )
            os.chmod( outdir, stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO )

        # Create ZIP file
        zipfile = os.path.join( outdir, experiment_label+'.zip' )

        (ecode,sout,eout) = sutils.zip(basedir,zipfile,' '.join(scan_dirs_rel)) 
        if ecode: 
            error = 'ERROR: unable to create ZIP file from these directories'
            slog.info(zipfile, error,scan_dirs = ' '.join( scan_dirs ), err_msg = str(eout), eid = str(experiment.id))
            try:
                os.remove(zipfile)
            except:
                pass

        if os.path.exists( zipfile ):
            os.chmod( zipfile, stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO )
            if args.verbose:
                print("Successfully created T1/T2 DICOM archive",zipfile)
            try:
                experiment.set( 'xnat:mrSessionData/fields/field[name=datetodvd]/field', date_today )
            except:
                error = "ERROR: failed to set DateToDVD field on experiment - removing archive file"
                slog.info(experiment_label,error,zipfile = zipfile,eid = str(experiment.id))
                os.remove( zipfile )

    return len( scan_dirs ) > 0

# RegExp pattern for subject IDs
subject_id_pattern = '^[A-FX]-[0-9]{5}-[MFPT]-[0-9]$'

# RegExp pattern for experiment labels
experiment_label_pattern = '^[A-FX]-[0-9]{5}-[MFPT]-[0-9]-20[0-9]{2}[01][0-9][0-3][0-9](-[0-9]){0,1}$'

#
# Check an experiment (MR session)
#
def validate_experiment( ifc, project, sid, slabel, eid, elabel, edate, einsert, xnat_dir,objects_force_write):
    if args.verbose:
        print("INFO: checking experiment %s (%s)" % (elabel,eid))

    global email
    global server_address

    check_again = []

    # in date, ditch the hyphens, which aren't supposed to be in the session label
    edate_short = re.sub( '-', '', edate )

    # Check for correct label, but only if subject ID isn't wrong
    if re.match( subject_id_pattern, slabel ):
        correct_label = '%s-%s' % ( slabel, edate_short )
        if re.match( '^%s(-[0-9]){0,1}' % correct_label, elabel ):
            if not 'P' in slabel:
                experiment = ifc.select.projects[project].subjects[sid].experiments[eid]
                edvddate = ifc.get_custom_variables( experiment, [ 'DateToDVD' ] )[0]
                if (eid in objects_force_write) or (edvddate == None) or not re.match( '^2[0,1][0-9]{2}-[0-1][0-9]-[0-3][0-9]$', edvddate ):
                    if args.zip_none:
                        check_again.append( eid )
                    else :
                        # Export T1/T2 DICOM files; returns "True" if any exist
                        if export_t1t2_to_zip( experiment, elabel,xnat_dir ):
                            # so check again until DatetoDVD is filled in with a date 
                            # not sure this is the best logic
                            check_again.append( eid )
        else:
            check_again.append( eid )
            if args.send_mail:
                experiment_uri = '%s/app/action/DisplayItemAction/search_element/xnat:mrSessionData/search_field/xnat:mrSessionData.ID/search_value/%s/popup/false' % (server_address,eid)
                email.add_user_message( einsert, 'Session "%s" (<a href="%s">%s</a>) is not named correctly (should be: "%s")' % (elabel, experiment_uri, eid, correct_label) )
            else:
                print('Session "%s" (%s) is not named correctly (should be: "%s")' % (elabel, eid, correct_label))
    else:
        # If subject ID was incorrect, match Session Name against pattern instead of (unknown) correct label
        if not re.match( experiment_label_pattern, elabel ):
            check_again.append( eid )
            if args.send_mail:
                experiment_uri = '%s/app/action/DisplayItemAction/search_element/xnat:mrSessionData/search_field/xnat:mrSessionData.ID/search_value/%s/popup/false' % (server_address,eid)
                email.add_user_message( einsert, 'Session "%s" (<a href="%s">%s</a>) does not conform with naming convention (fix subject ID first)' % (elabel, experiment_uri, eid) )
            else:
                print('Session "%s" (%s) does not conform to naming convention' % (elabel, eid))

    return check_again

#
# Check a subject ID, then check each experiment
#
def validate_subject( ifc, sid, slabel, sinsert ):
    if args.verbose:
        print("INFO: checking subject %s (%s)" % ( slabel, sid ))

    global email

    check_again = []

    # Check subject label
    if not re.match( subject_id_pattern, slabel ):
        check_again.append( sid )
        if args.send_mail:
            subject_uri = '%s/app/action/DisplayItemAction/search_element/xnat:subjectData/search_field/xnat:subjectData.ID/search_value/%s' % (server_address,sid)
            email.add_user_message( sinsert, 'Subject name "%s" (<a href="%s">%s</a>) does not conform with ID convention' % (slabel, subject_uri, sid) )
        else:
            print('Subject name "%s" (%s) does not conform to ID convention' % (slabel, sid))

    return check_again

#
# Check each subject in the project
#
experiment_list = []
subject_list = []

def validate_new_and_outstanding( ifc, project, objects_to_check, objects_force_write, date_last_checked,xnat_dir):
    # Get all subjects and sessions from XNAT - this speeds things up a lot
    subject_list = ifc.search( 'xnat:subjectData', ['xnat:subjectData/SUBJECT_ID','xnat:subjectData/SUBJECT_LABEL','xnat:subjectData/INSERT_USER','xnat:subjectData/INSERT_DATE'] ).where( [ ('xnat:subjectData/PROJECT','LIKE', '%'+project+'%') ] )
    experiment_list = ifc.search( 'xnat:mrSessionData', ['xnat:mrSessionData/SESSION_ID','xnat:mrSessionData/LABEL','xnat:mrSessionData/SUBJECT_ID','xnat:mrSessionData/DATE','xnat:mrSessionData/INSERT_USER','xnat:mrSessionData/LAST_MODIFIED'] ).where( [ ('xnat:mrSessionData/PROJECT','LIKE', '%'+project+'%') ] )

    check_again = []
    if len( subject_list ) > 0:
        subject_lookup = dict()
        # First, check each subject
        for (sid,slabel,sinsert,sdate) in list(subject_list.items()):
            subject_lookup[sid] = slabel
            if (sid in objects_to_check) or (sdate > date_last_checked):
                check_again += validate_subject( ifc, sid, slabel, sinsert )

                if len( [ eid for ( eid,elabel,esid,edate,einsert,emodified ) in list(experiment_list.items()) if sid == esid ] ) == 0:
                    check_again.append( sid )
                    if args.send_mail:
                        subject_uri = '%s/app/action/DisplayItemAction/search_element/xnat:subjectData/search_field/xnat:subjectData.ID/search_value/%s/project/%s' % (server_address,sid,project)
                        email.add_user_message( sinsert, 'Subject "%s" (<a href="%s">%s</a>) does not have any MR sessions. Consider deleting it.' % (slabel, subject_uri, sid) )
                    else:
                        print('Subject name "%s" (%s) does not have any MR sessions' % (slabel, sid))

        # Second check each experiment
        if len(experiment_list) > 0:
            for eid, elabel, sid, edate, einsert, emodified in list(experiment_list.items()):
                if (eid in objects_to_check) or (emodified > date_last_checked):
                    if sid in list(subject_lookup.keys()):
                        check_again += validate_experiment(ifc, project, sid, subject_lookup[sid], eid, elabel, edate, einsert,xnat_dir,objects_force_write)
                    else:
                        error = 'ERROR: cannot determine (unique) label'
                        slog.info(eid, error,
                                      subject=sid,
                                      project=project,
                                      date=edate)

    return check_again


# Create interface using stored configuration
ifc = session.connect_server('xnat', True)

# Set up email object to contact users and admin
email = sibis_email.xnat_email(session)

# Experiments to check from last run - these should be the ones we flagged last time and stored on the server for reconsideration
objects_to_check = []

objects_force_write = []

# Date format for XNAT dates and current date and time
xnat_date_format = '%Y-%m-%d %H:%M:%S'
now_str = time.strftime( xnat_date_format )

# Date (and time) when we last checked things
date_last_checked = time.localtime(0)

config_uri = '/data/config/pyxnat/check_object_names'
if not args.check_all:
    try:
        # Retrieve script config from XNAT server
        content = ifc._get_json( config_uri )

        # Extract date this script was last run
        creation_date = content[0]['create_date']
        date_last_checked = time.strptime( creation_date[0:19], xnat_date_format )
        if args.verbose:
            print('Script was last run %s' % creation_date)

        # Get list of previously flagged experiments that need to be checked again
        # Remove new line at the last element as otherwise dropped from list 
        objects_to_check_list =  content[0]['contents'][0:-1]
        # Only check if not NONE
        if objects_to_check_list != "NONE": 
            objects_to_check = objects_to_check_list.split( ',' ) 

    except Exception as e:
        # If we cannot get last script run date from server, leave at epoch (Jan 1, 1970)
        if args.verbose:
            print('Unable to retrieve date of last script run and list of flagged projects from server.')
            print(e) 



    if args.eidlist:
        added_checks = set(args.eidlist.split( ',' ) )
        objects_to_check +=  added_checks
        if args.zip_all: 
            objects_force_write = set(added_checks)

    objects_to_check  = set(objects_to_check)

    if args.verbose:
        print('Re-checking %d previously flagged objects' % len( objects_to_check ))


# If "last week" option is used, override last checked date
if args.last_week:
    date_last_checked = (datetime.datetime.now() - datetime.timedelta(7)).timetuple()

# If "last month" option is used, override last checked date
if args.last_month:
    date_last_checked = (datetime.datetime.now() - datetime.timedelta(31)).timetuple()

# For comparison - convert time of last check to string in XNAT date format
str_date_last_checked = time.strftime( xnat_date_format, date_last_checked )

# Get a list of all MR imaging sessions
project_ids = ifc.select.projects.keys()
check_again = []
for pid in project_ids:
    check_again += validate_new_and_outstanding( ifc, pid, objects_to_check, objects_force_write, str_date_last_checked,session.get_xnat_dir() )

if args.send_mail:
    email.send_all()

# Finally, update config stored on the server to have current date/time as the time that this script was last run
if not args.no_update:
    if args.verbose:
        print("Flagging %d objects for re-inspection during next script run" % len( check_again ))

    if len( check_again ) > 0:
        check_again_str = ','.join( set( check_again ) )
    else :
        check_again_str = 'NONE'

    content = ifc._exec( uri=config_uri, query={'inbody':'true'}, method='PUT', body=check_again_str, headers={'content-type':'text/plain'} )

slog.takeTimer1("script_time","{'TotalSubjects': " + str(len(subject_list)) + ", 'TotalExperiments': " +  str(len(experiment_list)) + "}")

