#!/usr/bin/env python

##
##  See COPYING file distributed along with the ncanda-data-integration package
##  for the copyright and license terms
##

import os
import re
import csv
import sys
import time
import argparse
import datetime
import yaml

import pyxnat
from sibisBeta import sibislogger as slog
import make_session_niftis

# Setup command line parser
parser = argparse.ArgumentParser(description="Find new MR sessions in XNAT, "
                                             "check for missing and duplicate "
                                             "scans, and list all sessions with"
                                             " questionable scans.")
parser.add_argument("-v", "--verbose",
                    help="Verbose operation",
                    action="store_true")
parser.add_argument("-m", "--send-mail-to",
                    help="Send results by email to the given address(es).",
                    action="store")
parser.add_argument("-a", "--check-all",
                    help="Check all MR sessions, regardless of date.",
                    action="store_true")
parser.add_argument("-W", "--last-week",
                    help="Check all MR sessions that were modified within the "
                         "last week.",
                    action="store_true")
parser.add_argument("-M", "--last-month",
                    help="Check all MR sessions that were modified within the "
                         "last month (more precisely: the last 31 days).",
                    action="store_true")
parser.add_argument("-e", "--eid",
                    help="Check all MR sessions that are associated with eid "
                         "(only for debugging).",
                    action="store")
parser.add_argument("--no-update",
                    help="Do not update the persistent data stored on the "
                         "XNAT server (e.g., last run date, list of flagged "
                         "sessions).",
                    action="store_true")
parser.add_argument("--qc-csv",
                    help="File path to write with scans to qc.",
                    default="/tmp/scan_qc.csv")
parser.add_argument("-f", "--force-qc-check",
                    help="Always perform quality check regardless if it was done before.",
                    action="store_true")
parser.add_argument("-p", "--post-to-github", help="Post all issues to GitHub instead of std out.", action="store_true")
args = parser.parse_args()

if args.eid:
    args.no_update = True

# Setup logging 
slog.init_log(args.verbose, args.post_to_github,'NCANDA XNAT: Check New Sessions Message', 'check_new_sessions')

# Create interface using stored configuration
ifc = pyxnat.Interface(config=os.path.join(os.path.expanduser("~"),
                                           '.server_config/ncanda.cfg'))

# Get sibis config 
yml = os.path.join(os.path.expanduser("~"), '.server_config/config.yml')
with open(yml, 'r') as fi:
    fi_data = yaml.load(fi)
    sibis_config = fi_data.get('operations')
    log_dir = os.path.join(fi_data.get('logdir'),'check_new_sessions')

if not sibis_config:
    raise IOError("Please ensure config.yml file exists at: {}".format(yml))


if not os.path.exists(log_dir):
    raise IOError("Please ensure {} exists!".format(log_dir))

if not os.path.exists(os.path.join(sibis_config, 'special_cases.yml')): 
    raise IOError("Please ensure special_cases.yml file exists at: {}".format(sibis_config))

# load exceptions for QC check 
with open(os.path.join(sibis_config, 'special_cases.yml'), 'r') as fi:
    complete_file = yaml.load(fi)
    incorrect_formatting_map = complete_file.get('incorrect_format')
    missing_scan_map = complete_file.get('incomplete_sessions')
    fi.close()

# Date format for XNAT dates
xnat_date_format = '%Y-%m-%d %H:%M:%S'
now_str = time.strftime(xnat_date_format)

# Experiments to check from last run - these should be the ones we flagged last
# time and stored on the server for reconsideration
experiments_to_check = []

# Date (and time) when we last checked things
# By default 1969 
date_last_checked = time.localtime(0)

config_uri = '/data/config/pyxnat/check_new_sessions'
if not args.check_all:
    try:
        # Retrieve script config from XNAT server
        content = ifc._get_json('%s' % config_uri)

        # Extract date this script was last run
        creation_date = content[0]['create_date']
        date_last_checked = time.strptime(creation_date[0:19], xnat_date_format)
        if args.verbose:
            print 'Script was last run %s' % creation_date

        # Get list of previously flagged experiments that need to be checked
        # again
        if args.eid:
            experiments_to_check = [args.eid]
        else:
            experiments_to_check = set(content[0]['contents'].split(','))
        if args.verbose:
            print 'Re-checking %d previously flagged experiments' % \
                  len(experiments_to_check)
    except:
        # If we cannot get last script run date from server, leave at epoch
        # (Jan 1, 1970)
        if args.verbose:
            print 'Unable to retrieve date of last script run and list of ' \
                  'flagged projects from server.'

        ifc = pyxnat.Interface(config=os.path.join(os.path.expanduser("~"),
                                                   '.server_config/ncanda.cfg'))
        ifc._memtimeout = 0


# If "last week" option is used, override last checked date
if args.last_week:
    date_last_checked = (datetime.datetime.now() -
                         datetime.timedelta(7)).timetuple()

# If "last month" option is used, override last checked date
if args.last_month:
    date_last_checked = (datetime.datetime.now() -
                         datetime.timedelta(31)).timetuple()

# For comparison - convert time of last check to string in XNAT date format
str_date_last_checked = time.strftime(xnat_date_format, date_last_checked)
if args.verbose:
    print "Checking sessions modified after", str_date_last_checked

# Get list of all sessions after the chosen date
# Adding fields such as 'xnat:mrSessionData/scanner/manufacturer' does not work for some reason 
fields_per_session = ['xnat:mrSessionData/SESSION_ID',
                      'xnat:mrSessionData/PROJECT',
                      'xnat:mrSessionData/SUBJECT_ID',
                      'xnat:mrSessionData/INSERT_DATE',
                      'xnat:mrSessionData/LABEL',
                      'xnat:mrSessionData/LAST_MODIFIED']

new_sessions = []
if not args.eid:
    criteria = [('xnat:mrSessionData/LAST_MODIFIED',
                 '>=',
                 str_date_last_checked)]
    new_sessions = ifc.select('xnat:mrSessionData',
                              fields_per_session).where(criteria).items()
    if args.verbose:
        print '%d experiments have been modified since last run' % \
              len(new_sessions)

# Also get necessary data for all sessions flagged during previous run of this
# script
previous_sessions = []
for eid in experiments_to_check:
    criteria = [('xnat:mrSessionData/ID', 'LIKE', eid.strip())]
    this_session = ifc.select('xnat:mrSessionData',
                              fields_per_session).where(criteria).items()
    if len(this_session):
        previous_sessions.append(this_session[0])
    else:
        error = 'WARNING: flagged session appears to have disappeared.'
        slog.info(eid, error)

# All sessions to check - previously flagged plus updated
sessions_to_check = sorted(list(set(new_sessions + previous_sessions)),
                           key=lambda tupl: tupl[0])
if args.verbose:
    print 'Checking a total of %d experiments' % len(sessions_to_check)

# Dictionaries of required series (and counts) for Siemens and GE subject
# sessions
required_siemens = {'ncanda-mprage-v1': 1,
                    'ncanda-t2fse-v1': 1,
                    'ncanda-dti6b500pepolar-v1': 1,
                    'ncanda-dti60b1000-v1': 1,
                    'ncanda-grefieldmap-v1': 2,
                    'ncanda-rsfmri-v1': 1}
required_ge = {'ncanda-t1spgr-v1': 1,
               'ncanda-t2fse-v1': 1,
               'ncanda-dti6b500pepolar-v1': 1,
               'ncanda-dti60b1000-v1': 1,
               'ncanda-grefieldmap-v1': 1,
               'ncanda-rsfmri-v1': 1}

# Dictionaries of required series for ADNI (separate for GE and Siemens) and
# fBIRN phantom sessions
required_adni_siemens = {'ncanda-mprage-v1': 1}
required_adni_ge = {'ncanda-t1spgr-v1': 1}
required_fbirn = {'ncanda-rsfmri-v1': 1}

# Get list of fBIRN phantom subject IDs
criteria = [('xnat:subjectData/SUBJECT_LABEL', 'LIKE', '%-00000-P-0')]
fbirn_ids_search = ifc.select('xnat:subjectData',
                              ['xnat:subjectData/SUBJECT_ID']).where(criteria)
fbirn_ids = fbirn_ids_search.get('subject_id')

# Get list of ADNI phantom subject IDs
criteria = [('xnat:subjectData/SUBJECT_LABEL', 'LIKE', '%-99999-P-9')]
adni_ids_search = ifc.select('xnat:subjectData',
                             ['xnat:subjectData/SUBJECT_ID']).where(criteria)
adni_ids = adni_ids_search.get('subject_id')


# Make a direct link to XNAT session
def make_session_link(eid, project, label):
    html_list = ['<li>',
                 '<a href=',
                 'https://ncanda.sri.com/xnat/app/action/DisplayItemAction/',
                 'search_value/',
                 eid,
                 '/search_element/xnat:mrSessionData/search_field/',
                 'xnat:mrSessionData.ID/project/',
                 project,
                 '>',
                 project,
                 '/',
                 eid,
                 '/',
                 label,
                 '</a></li>\n']
    html_link = ''.join(html_list)
    file_list = ['/fs/ncanda-xnat/archive/',
                 project,
                 '/arc001/',
                 label,
                 '/RESOURCES/nifti<BR>\n']
    file_link = ''.join(file_list)
    return html_link, file_link


# Get a custom variable from XML representation of experiment
def get_custom_variable(experiment, field_name):
    field_regex = '.*<xnat:field name="%s">(.*?)</xnat:field>' % field_name
    match = re.match(field_regex, experiment.get(), flags=re.DOTALL)
    if match:
        return re.sub('\s*<!--.*?-->\s*',
                      '',
                      match.group(1),
                      flags=re.DOTALL)
    else:
        return None

# calculating unseen, duplicated, missing, and questionable scans
htmln = []
htmlu = []
htmld = []
htmlq = []
htmldt = []
htmlphys = []
scans_to_qc = []  # used to create a csv of scans to qc

experiments_for_next_run = []
physio = ['PPGData_epiRT', 'PPGTrig_epiRT','RESPData_epiRT', 'RESPTrig_epiRT',
          'PPGData_fmri_ucsd', 'PPGTrig_fmri_ucsd', 'RESPData_fmri_ucsd',
          'RESPTrig_fmri_ucsd', '.ecg', '.ext', '.puls', '.res', '.txt',
          'RESPData_sprlio', 'PPGTrig_sprlio', 'PPGData_sprlio']


# checking if the sites have sent physiology data
def check_physio(ifc, eid):
    experiment = ifc.select.experiment(eid)
    if get_custom_variable(experiment, 'physioproblemoverride') == 'true':
        return True

    for resource in experiment.resources().get():
        json_path = '/data/experiments/{}/resources/{}/files?format=json'
        files = ifc._get_json(json_path.format(eid, resource))
        for fl in files:
            for ph in physio:
                if ph in fl['Name']:
                    return True
    return False


# checking if both dti scans have proper imaging parameters
def check_dti(ifc, eid, dti_scans):
    errors = []

    experiment = ifc.select.experiment(eid)
    if get_custom_variable(experiment, 'dtimismatchoverride') == 'true':
        return errors

    parameters = []
    for scan, scantype in dti_scans:
        scan_attrs = ['xnat:mrScanData/parameters/te',
                      'xnat:mrScanData/parameters/fov/x',
                      'xnat:mrScanData/parameters/fov/y',
                      'xnat:mrScanData/parameters/voxelRes/x',
                      'xnat:mrScanData/parameters/voxelRes/y']
        parameters += [experiment.scan(scan).attrs.mget(scan_attrs)]

    if len(parameters):
        te0, fovx0, fovy0, pixx0, pixy0 = parameters[0]
        for te, fovx, fovy, pixx, pixy in parameters:
            if te != te0:
                errors.append('TE mismatch (%s/%s)' % (te0, te))

            if fovx != fovx0 or fovy != fovy0:
                errors.append('FOV mismatch (%s,%s/%s,%s)' % (fovx0,
                                                              fovy0,
                                                              fovx,
                                                              fovy))

            if pixx != pixx0 or pixy != pixy0:
                errors.append('Pixel size mismatch (%s,%s/%s,%s)' % (pixx0,
                                                                     pixy0,
                                                                     pixx,
                                                                     pixy))

    return errors

scan_type_dictionary = {'GE MEDICAL SYSTEMS': required_ge.keys(),
                        'SIEMENS': required_siemens.keys()}


def label_check(label):
    phantom = ['.-9999\d', '.-00000']
    match = re.match(phantom[0], label, flags=re.DOTALL)
    if match:
        return match
    else:
        match = re.match(phantom[1], label, flags=re.DOTALL)
        if match:
            return match


def incomplete_scan_check(eid, manufacturer, label, missing_scan_map):
    missing_scans = []
    sess_type = 'xnat:mrSessionData/scans/scan/type'
    scan_types = ifc.select.experiment(eid).attrs.get(sess_type)
    scan_types_set = set(scan_types)
    ge_scan_types = set(scan_type_dictionary['GE MEDICAL SYSTEMS'])
    siemens_scan_types = set(scan_type_dictionary['SIEMENS'])
    siemens_gradient_flag = False

    if manufacturer == 'GE MEDICAL SYSTEMS':
        if ge_scan_types.issubset(scan_types_set):
            return False
        else:
            missing_scans = ge_scan_types.difference(scan_types_set)

    elif manufacturer == 'SIEMENS':
        if siemens_scan_types.issubset(scan_types_set) \
                and scan_types.count('ncanda-grefieldmap-v1') == 2:
            return False
        else: 
            missing_scans = list(siemens_scan_types.difference(scan_types_set))
            if scan_types.count('ncanda-grefieldmap-v1') < 2:
               # If field was present 0 times, it's already included once in
               # missing_scans, and we want it to appear twice.
               # if field was present 1 time, we want to mark it as one more
               # field with same name is missing
               missing_scans.append('ncanda-grefieldmap-v1')
               siemens_gradient_flag = True
    else:
        slog.info(eid,'Do not support manufacturer {}'.format(manufacturer))
        return True

    if missing_scans:
        # Lets see if missing_scans are part of exception  
        missing_scans_exception = missing_scan_map.get(label)
        if missing_scans_exception:
            missing_scans_exception_list = missing_scans_exception.split(',')
            missing_scans = list(set(missing_scans).difference(missing_scans_exception_list))
            if missing_scans == [] : 
                if args.verbose:
                    print label, ": All missing scans are excepted!" 
                return False
 
        err_msg = 'ERROR: Missing scans from Session!'
        if siemens_gradient_flag :
            err_msg += "Note, Siemens scans require two 'ncanda-grefieldmap-v1'" 

        slog.info(eid,
                      err_msg,
                      scan_session_label=label,
                      manufacturer=manufacturer,
                      missing_scans=', '.join(missing_scans))
        return True

def voxelres_get(eid, scan):
        scan_info = ifc.select.experiment(eid).scan(scan).get()
        field_regex = '.*<xnat:voxelRes (.*?)/>'
        match = re.match(field_regex, scan_info, flags=re.DOTALL)
        if match:
            return re.sub('\s*<!--.*?-->\s*',
                          '',
                          match.group(1),
                          flags=re.DOTALL)

voxelres_siemens = {
    'ncanda-mprage-v1': 'x="0.9375\d*" y="0.9375\d*" z="1.2\d*"',
    'ncanda-t2fse-v1': 'x="0.46875\d*" y="0.46875\d*" z="1.2\d*"',
    'ncanda-dti6b500pepolar-v1': 'x="2.5\d*" y="2.5\d*" z="2.5\d*"',
    'ncanda-dti60b1000-v1': 'x="2.5\d*" y="2.5\d*" z="2.5\d*"',
    'ncanda-grefieldmap-v1': 'x="2.5\d*" y="2.5\d*" z="2.5\d*"',
    'ncanda-rsfmri-v1': 'x="3.75\d*" y="3.75\d*" z="5.0\d*"'
}

voxelres_ge = {
    'ncanda-t1spgr-v1': 'x="0.9375\d*" y="0.9375\d*" z="1.2\d*"',
    'ncanda-t2fse-v1': 'x="0.4688\d*" y="0.4688\d*" z="1.2\d*"',
    'ncanda-dti6b500pepolar-v1': 'x="1.875\d*" y="1.875\d*" z="2.5\d*"',
    'ncanda-dti60b1000-v1': 'x="1.875\d*" y="1.875\d*" z="2.5\d*"',
    'ncanda-grefieldmap-v1': 'x="1.875\d*" y="1.875\d*" z="2.5\d*"',
    'ncanda-rsfmri-v1': 'x="3.75\d*" y="3.75\d*" z="5.0\d*"'
}


def voxelRes_check(eid, manufacturer, scan_list):
    voxel_res = []
    error = []
    for scan in scan_list:
        scan_res = [ifc.select.experiment(eid).scan(scan).attrs.get('type'),
                    voxelres_get(eid, scan),scan]
        voxel_res.append(scan_res)

    if manufacturer == 'GE MEDICAL SYSTEMS':
        for v in voxel_res:
            if v[0] in scan_type_dictionary['GE MEDICAL SYSTEMS']:
                try: 
                    match = re.match(voxelres_ge[v[0]], v[1], flags=re.DOTALL)
                    if not match:
                        error.append({'field': 'Voxel Resolution',
                                      'scan_type': v[0],
                                      'voxel_res': v[1],
                                      'expected_voxel_res': voxelres_ge[v[0]],
                                      'scan_id': v[2]})
                except Exception as err_msg: 
                    error.append({'field': 'Could not check voxel resolution',
                                  'scan_type': str(v[0]),
                                  'voxel_res': str(v[1]),
                                  'expected_voxel_res': voxelres_ge[v[0]],
                                  'scan_id': str(v[2]),
                                  'err_msg' : str(err_msg)})

    elif manufacturer == 'SIEMENS':
        for v in voxel_res:
            if v[0] in scan_type_dictionary['SIEMENS']:
                try :
                    match = re.match(voxelres_siemens[v[0]], v[1], flags=re.DOTALL)
                    if not match:
                        error.append({'field': 'Voxel Resolution',
                                      'scan_type': v[0],
                                      'voxel_res': v[1],
                                      'expected_voxel_res': voxelres_siemens[v[0]],
                                      'scan_id': v[2]})
                except Exception as err_msg: 
                    error.append({'field': 'Could not check voxel resolution',
                                  'scan_type': str(v[0]),
                                  'voxel_res': str(v[1]),
                                  'expected_voxel_res': voxelres_ge[v[0]],
                                  'scan_id': str(v[2]),
                                  'err_msg' : str(err_msg)})

    return error

frame_check_siemens = {'ncanda-mprage-v1': '160',
                       'ncanda-t2fse-v1': '160',
                       'ncanda-dti6b500pepolar-v1': '7',
                       'ncanda-dti60b1000-v1': '62',
                       'ncanda-grefieldmap-v1': ['64', '128'],
                       'ncanda-rsfmri-v1': '275'}

frame_check_ge = {'ncanda-t1spgr-v1': '146',
                  'ncanda-t2fse-v1': '292',
                  'ncanda-dti6b500pepolar-v1': '512',
                  'ncanda-dti60b1000-v1': '3968',
                  'ncanda-grefieldmap-v1': '384',
                  'ncanda-rsfmri-v1': '8768'}

def frame_check(eid, manufacturer, scan_list):
    frames = []
    error = []

    for scan in scan_list:
        frame = ifc.select.experiment(eid).scan(scan).attrs.mget(['type','frames'])
        frame.append(scan)
        frames.append(frame)

    if manufacturer == 'GE MEDICAL SYSTEMS':
        for f in frames:
            if f[0] in scan_type_dictionary['GE MEDICAL SYSTEMS']:
                if frame_check_ge[f[0]] != f[1]:
                    error.append({'scan_type': f[0],
                                  'frames': f[1],
                                  'expected_frames': frame_check_ge[f[0]],
                                  'scan_id': f[2]})
    elif manufacturer == 'SIEMENS':
        # Variable frames has two grefieldmap keys, change to one key and list of values.
        # Extract values list -> ['64', '128']

        grefieldmap_list = ['ncanda-grefieldmap-v1', [v for (k, v, z) in frames if k == 'ncanda-grefieldmap-v1']]
        if grefieldmap_list[1] : 
            # Sort number of frames for later comparison
            grefieldmap_list[1].sort(lambda x, y: int(x) - int(y))
            # Change all frames with fixed grefieldmap
            frames = filter(lambda x: x[0] != 'ncanda-grefieldmap-v1', frames) + [grefieldmap_list]

        for f in frames:
            if f[0] not in scan_type_dictionary['SIEMENS']:
                continue 
            if f[0] == 'ncanda-dti6b500pepolar-v1':
                # Tim Trio contains '7' and prisma '8' frames 
                if not f[1] in ('7', '8'):
                    error.append({'scan_type': f[0],
                                  'frames': f[1],
                                  'expected_frames': frame_check_siemens[f[0]],
                                  'scan_id': f[2]})
            elif f[1] != frame_check_siemens[f[0]]:
                # Some of the required frames are missing
                error.append({'scan_type': f[0],
                              'frames': f[1],
                              'expected_frames': frame_check_siemens[f[0]],
                              'scan_id': f[2]})
    return error


# Check dimension of each MRI scan potentially ported to the pipeline folder:  
def mri_quality_check(eid, manufacturer, label, incorrect_formatting_map):
    errors = []

    # get scan list
    scan_id = 'xnat:mrSessionData/scans/scan/id'
    scan_list = ifc.select.experiment(eid).attrs.get(scan_id)

    # filter out all files that have an exception
    if incorrect_formatting_map:
        incorrect_formatting_exception = incorrect_formatting_map.get(label)
    else : 
        incorrect_formatting_exception = None

    if incorrect_formatting_exception:
        incorrect_formatting_list = str(incorrect_formatting_exception).split(',')
        if args.verbose:
            print label, ": The following scans will not be checked : ", str(incorrect_formatting_list) 

        no_exception_list = list(set(scan_list).difference(incorrect_formatting_list))
    else :
        no_exception_list = scan_list

    for e in frame_check(eid, manufacturer, no_exception_list):
        if e:
            errors.append(e)
        
    for e in voxelRes_check(eid, manufacturer,  no_exception_list):
        if e:
            errors.append(e)

    if errors:
        slog.info(eid,
                      'ERROR: Failed to match standard frames',
                      scan_session_label=label,
                      violations=str(errors))
        return False

    return True

def remove_file(fileName): 
    # nothing to do 
    if not os.path.isfile(fileName):
        return
    try :  
        os.remove(fileName)
    except Exception as err_msg: 
        slog.info(eid,'ERROR: Could not remove file - please check access rights! - stopped processing',
                  fileName = fileName,
                  error_msg=str(err_msg))
        sys.exit("Stopped due to access file issues!")


def rename_file(oldFileName,newFileName): 
    # nothing to do 
    if not os.path.isfile(oldFileName):
        return 
    try :  
        os.rename(oldFileName,newFileName)
    except Exception as err_msg: 
        slog.info(eid,'ERROR: Could not rename file - please check access rights! Processing stopped',
                  oldFileName = oldFileName,
                  newFileName = newFileName,
                  error_msg=str(err_msg))
        sys.exit("Stopped due to access file issues!")



#
# Main loop
#

# For debugging
# Start from where session last broke down 
if False: 
    index = 0 
    for session  in sessions_to_check:
        if session[0] == 'NCANDA_E03897' :
            break
        index += 1
    sessions_to_check = sessions_to_check[4000:]
    print "DEBUG: Checking " + str(len(sessions_to_check)) + " sessions." 

index = -1
for (eid, project, subject, insert_date,
     session_label, last_modified) in sessions_to_check:
    index +=1 
    #if index < 3517 :
    #    continue
    #if index == 3519:
    #    sys.exit()
    # print "==== ", index, eid
    if args.verbose:
        sys.stdout.write("Checking experiment %s/%s SID:%s EID:%s, insert date "
                         "%s, modified date %s...\n" % (project, session_label,
                                                      subject, eid, insert_date,
                                                      last_modified))
        sys.stdout.flush()

    # if anything goes wrong just run it again 
    qc_file = os.path.join(log_dir,eid + "_passed_qc")
    qc_file_tmp = qc_file + "_"

    remove_file(qc_file_tmp)
    if args.force_qc_check:
        remove_file(qc_file)
    elif os.path.isfile(qc_file):
        rename_file(qc_file,qc_file_tmp)

    try :
        manufacturer = 'xnat:mrSessionData/scanner/manufacturer'
        manufacturer = ifc.select.experiment(eid).attrs.get(manufacturer)
        scanner_model_str = 'xnat:mrSessionData/scanner/model'
        scanner_model = ifc.select.experiment(eid).attrs.get(scanner_model_str)
    except Exception as err_msg: 
        slog.info(eid,'ERROR: Could not retrieve scanner model or manufacturer from xnat - skipping session',
                  info = "Most likely another app is trying to access xnat at the same time",
                  error=str(err_msg))
        continue

    # Link to the session
    session_html_link, session_file_link = make_session_link(eid,
                                                             project,
                                                             session_label)

    # figure out what scans are required for this subject (or phantom) on this
    # platform
    isPhantom = False
    if subject in fbirn_ids:
        required_series = required_fbirn
        isPhantom = True
    elif 'GE' in manufacturer:
        if subject in adni_ids:
            required_series = required_adni_ge
            isPhantom = True
        else:
            required_series = required_ge
    else:
        if subject in adni_ids:
            required_series = required_adni_siemens
            isPhantom = True
        else:
            required_series = required_siemens

    # Get quality rating for each scan type
    scantype_and_quality = [
        [scan] + ifc.select.experiment(eid).scan(scan).attrs.mget(['type',
                                                                   'quality'])
        for scan in ifc.select.experiment(eid).scans('*').get()]
    final = [
        scantype for (scan, scantype, quality) in scantype_and_quality
        if scantype in required_series.keys() and quality in ['usable',
                                                              'unusable']]
    usable = [
        scantype for (scan, scantype, quality) in scantype_and_quality
        if scantype in required_series.keys() and quality == 'usable']
    questionable = [
        scantype for (scan, scantype, quality) in scantype_and_quality
        if scantype in required_series.keys() and quality == 'questionable']
    unseen_scans = [
        scantype for (scan, scantype, quality) in scantype_and_quality
        if scantype in required_series.keys() and quality in ['unset',
                                                              'unknown']]

    dti_scans = [
        (scan, scantype) for (scan, scantype, quality) in scantype_and_quality
        if re.match('^ncanda-dti.*-v1$', scantype) and quality != 'unusable']
    fmri_scans = [
        (scan, scantype) for (scan, scantype, quality) in scantype_and_quality
        if re.match('^ncanda-.*fmri.*-v1$', scantype) and quality != 'unusable']

    # define QC tag so that scans that passed qc are not checked again 
    # this is done to speed up execution of the script - decided to do 
    # it this way instead of writing file to xnat so that multiple scripts of the session can exist

    # Export scans to NIFTI
    nifti_export_ok = True
    for (scan, scantype, quality) in scantype_and_quality:
        if re.match('^ncanda-.*-v[0-9]$', scantype):
            error_msg, niftisWereCreatedFlag = make_session_niftis.export_to_nifti(
                ifc,
                project,
                subject,
                eid,
                session_label,
                manufacturer,
                scanner_model,
                scan,
                scantype,
                verbose=args.verbose)
            if len(error_msg) or niftisWereCreatedFlag:
                # Remove qc_file as session has to be checked again 
                remove_file(qc_file_tmp)

                if len(error_msg) :
                    nifti_export_ok = False
                    htmln.append(''.join([session_html_link,
                                      session_file_link,
                                      ', '.join([scan, scantype, 'ERROR:']),
                                      ', ERROR:'.join(error_msg)]))

    # MRI Session Quality Checks
    if args.verbose:
        sys.stdout.write("Beginning QC...")
        sys.stdout.flush()

    # ignore phantom Scans 
    # ncanda-rsfmri-v1 for adni phantom has 8800 frames on GE instead of 8768
    # ncanda-t1spgr-v1 of phantom has 186 instead of 146 frames

    errorFlag = False
    if not os.path.exists(qc_file_tmp): 
        # not sure why this was done
        # scanner_label = 'xnat:mrSessionData/scanner/label'
        #label = ifc.select.experiment(eid).attrs.get(scanner_label)
        # print "label", label, "session label", session_label  
        if not label_check(session_label):
            errorFlag = incomplete_scan_check(eid, manufacturer, session_label, missing_scan_map)
            errorFlag = errorFlag or not mri_quality_check(eid, manufacturer, session_label, incorrect_formatting_map)

        # failed dti te comparison
        failed_dti = check_dti(ifc, eid, dti_scans)
        if len(failed_dti):
            errorFlag = True
            htmldt.append(''.join([session_html_link,
                                   session_file_link,
                                   ', '.join(failed_dti)]))
        
        # missing physio data
        physio_ok = True
        if not isPhantom and len(fmri_scans):
            physio_ok = check_physio(ifc, eid)
            if not physio_ok:
                errorFlag = True
                htmlphys.append(session_html_link)
            
        # If no error is detected write flag to data drive
        if not errorFlag:
            with open(qc_file, 'a'):
                os.utime(qc_file, None)

    else:
        failed_dti = ""
        physio_ok = True
        rename_file(qc_file_tmp,qc_file)

        if args.verbose:
            sys.stdout.write("Skipping QC...")
            sys.stdout.flush()

    # "unset" (i.e., uninspected) mandatory scantypes
    unset = [scantype for scantype in required_series.keys()
             if scantype in unseen_scans]
    if len(unset):
        htmlu.append(''.join([session_html_link,
                              session_file_link,
                              ', '.join(unset)]))
        # add to qc csv
        unseen_scans.insert(0, session_file_link[:-5])
        row = ','.join(unseen_scans)
        row += '\n'
        scans_to_qc.append(row)

    # duplicated scantypes
    dupl =[scantype for scantype in usable
           if (scantype in required_series.keys()) and
           (usable.count(scantype) > required_series[scantype])]
    if len(dupl):
        htmld.append(''.join([session_html_link,
                              session_file_link,
                              ', '.join(dupl)]))

    # questionable scantypes
    if len(questionable):
        htmlq.append(''.join([session_html_link,
                              session_file_link,
                              ', '.join(questionable)]))

    if (errorFlag + len(questionable) + len(unset) + len(dupl) + len(failed_dti)) \
            or (not physio_ok) or (not nifti_export_ok):
        experiments_for_next_run.append(eid)
        if args.verbose:
            print "RECHECK"
    else:
        if args.verbose:
            print "OK"

# Make links for all "new" sessions, i.e., those inserted after the
# "last checked" date
new_session_links = [
    make_session_link(eid, project, label)
    for (eid, project, subject,
         insert_date, label, last_modified) in new_sessions
    if insert_date >= str_date_last_checked]

html_summary = ''
html = ''
if len(new_session_links) > 0:
    temp = '<li>New Sessions: <a href="#newsessions">&nbsp;%d&nbsp;</a></li>\n'
    html_summary += temp % len(new_session_links)
    html += ''.join(['<b><a id="newsessions">New Sessions Since %s' %
                     str_date_last_checked,
                     '</a></b>\n<ol>',
                     ''.join("%s%s" % (session_link[0], session_link[1])
                             for session_link in new_session_links), '</ol>'])

if len(htmlu) > 0:
    html_summary += '<li>Sessions with Scans to Inspect: ' \
                    '<a href="#toinspect">&nbsp;%d&nbsp;</a>' \
                    '</li>\n' % len(htmlu)
    html += ''.join(['<b><a id="toinspect">Sessions with Mandatory '
                     'Scans to Inspect',
                     '</a></b>\n<ol>', ''.join(htmlu), '</ol>'])

if len(htmlq) > 0:
    html_summary += '<li>Sessions with Questionable Scans: ' \
                    '<a href="#questionable">&nbsp;%d&nbsp;</a>' \
                    '</li>\n' % len(htmlq)
    html += ''.join(['<b><a id="questionable">Sessions with Questionable Scans',
                     '</a></b>\n<ol>', ''.join(htmlq), '</ol>'])

if len(htmld) > 0:
    html_summary += '<li>Sessions with Duplicated Scans: ' \
                    '<a href="#dupes">&nbsp;%d&nbsp;</a></li>\n' % len(htmld)
    html += ''.join(['<b><a id="dupes">Sessions with Duplicated Scans',
                     '</a></b>\n<ol>', ''.join(htmld), '</ol>'])

if len(htmln) > 0:
    html_summary += '<li>Unparsable Dicoms: <a href="#niftifailed">' \
                    '&nbsp;%d&nbsp;</a></li>\n' % len(htmln)
    html += ''.join(['<b><a id="niftifailed">Sessions with Unparsable Dicoms ',
                     '</a></b>\n<ol>', ''.join(htmln), '</ol>'])

if len(htmldt) > 0:
    html_summary += '<li>Sessions with Mismatched DTI Parameters: <a href=' \
                    '"#dtimismatch">&nbsp;%d&nbsp;</a></li>\n' % len(htmldt)
    html += ''.join([
        '<b><a id="dtimismatch">Sessions with Mismatched DTI Parameters',
        '</a></b>\n<ol>', ''.join(htmldt), '</ol>'])

if len(htmlphys) > 0:
    html_summary += '<li>Sessions with Missing Physiological Data: <a ' \
                    'href="#physio">&nbsp;%d&nbsp;</a></li>\n' % len(htmlphys)
    html += ''.join([
        '<b><a id="physio">Sessions with Missing Physiological Data',
        '</a></b>\n<ol>', ''.join(htmlphys), '</ol>'])

if html_summary != '':
    html = '<b>Summary</b>\n<ol>\n' + html_summary + '</ol>\n' + html

# Are we supposed to send emails?
if args.send_mail_to:
    from xnat_email import XnatEmail
    email = XnatEmail( ifc )
    email.send('NCANDA XNAT - MRI Session Report',
               email._admin_email,
               args.send_mail_to.split(','),
               html)
elif args.verbose:
    print html

# Write the scans to QC csv file.
if scans_to_qc:
    with open(args.qc_csv, 'wb') as fi:
        fi.writelines(scans_to_qc)

# Finally, update config stored on the server to have current date/time as the
# time that this script was last run
if not args.no_update:
    if args.verbose:
        print "Flagging %d series for re-inspection during next script run" % \
              len(experiments_for_next_run)
    content = ifc._exec(uri='%s?inbody=true' % config_uri,
                        method='PUT',
                        body=','.join(set(experiments_for_next_run)),
                        headers={'content-type': 'text/plain'})
