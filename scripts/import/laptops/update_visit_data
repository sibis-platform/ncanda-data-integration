#!/usr/bin/env python

##
##  See COPYING file distributed along with the ncanda-data-integration package
##  for the copyright and license terms
##

"""
Purpose of update_visit_data is to transfer the data from the
Imported from Laptops REDCap project to the Data Entry project.
"""

from __future__ import print_function
from __future__ import division
from builtins import zip
from builtins import str
from builtins import range
from past.utils import old_div
import os
import re
import sys
import yaml
import time
import datetime
import argparse

import pandas
import redcap
import requests
import hashlib
from tqdm import tqdm

import sibispy
from sibispy import sibislogger as slog

#
# Variables
#
date_format_ymd = "%Y-%m-%d"

# List of forms imported from the laptops
all_forms = {
    # Forms for Arm 1: Standard Protocol
    "dd100": "delayed_discounting_100",
    "dd1000": "delayed_discounting_1000",
    "pasat": "paced_auditory_serial_addition_test_pasat",
    "stroop": "stroop",
    "ssaga_youth": "ssaga_youth",
    "ssaga_parent": "ssaga_parent",
    "youthreport1": "youth_report_1",
    "youthreport1b": "youth_report_1b",
    "youthreport2": "youth_report_2",
    "parentreport": "parent_report",
    "mrireport": "mri_report",
    "plus": "participant_last_use_summary",
    "myy": "midyear_youth_interview",
    "lssaga1_youth": "limesurvey_ssaga_part_1_youth",
    "lssaga2_youth": "limesurvey_ssaga_part_2_youth",
    "lssaga3_youth": "limesurvey_ssaga_part_3_youth",
    "lssaga4_youth": "limesurvey_ssaga_part_4_youth",
    "lssaga1_parent": "limesurvey_ssaga_part_1_parent",
    "lssaga2_parent": "limesurvey_ssaga_part_2_parent",
    "lssaga3_parent": "limesurvey_ssaga_part_3_parent",
    "lssaga4_parent": "limesurvey_ssaga_part_4_parent",
    # Forms for Arm 3: Sleep Studies
    "sleepeve": "sleep_study_evening_questionnaire",
    "sleeppre": "sleep_study_presleep_questionnaire",
    "sleepmor": "sleep_study_morning_questionnaire",
    # Forms for Recovery project
    "recq": "recovery_questionnaire",
}

# Define the name of the Recovery baseline event - this receives special
# treatment to catch records from BEFORE its visit date (supposedly from the
# corresponding Standard visit)
recovery_baseline_event = "recovery_baseline_arm_2"

# Only right now relavent for sleep arm
forms_date_increments = {
    # PLUS, Evening and Presleep forms same date as entered, Morning form next
    # day
    "plus": 0,
    "sleepeve": 0,
    "sleeppre": 0,
    "sleepmor": 1,
}

#
# Functions
#

# Convert to string, or empty if nan.
def nan_to_empty(x):
    try:
        s = x.decode("utf-8")
    except:
        s = str(x)

    if s != "nan":
        return s
    else:
        return ""


# Upload new data to REDCap
def to_redcap(
    session,
    form_name,
    subject_id,
    event,
    timelabel,
    upload_records,
    record_id=None,
    verbose=False,
):
    if args.no_upload:
        return 0

    if verbose:
        print("to_redcap: ", form_name, subject_id, event, timelabel, record_id)
        id_label = "%s_missing" % form_name

    error_label = subject_id + "-" + event + "-" + form_name
    import_response = session.redcap_import_record(
        error_label, subject_id, event, timelabel, [upload_records], record_id, import_format="json",
    )

    if verbose:
        print("... done")

    # If there were any errors, try to print them as well as possible
    if import_response:
        if "error" in list(import_response.keys()):
            slog.info(
                error_label
                + "-"
                + hashlib.sha1(str(import_response["error"]).encode()).hexdigest()[0:6],
                "ERROR: Uploading Data",
                error_msg=str(import_response["error"]),
            )
        if "fields" in list(import_response.keys()):
            slog.info(
                error_label
                + "-"
                + hashlib.sha1(str(import_response["fields"]).encode()).hexdigest()[
                    0:6
                ],
                "Info: something wrong with fields ! Not sure what to do !",
                fields=str(import_response["fields"]),
            )
        if "records" in list(import_response.keys()):
            slog.info(
                error_label
                + "-"
                + hashlib.sha1(str(import_response["records"]).encode()).hexdigest()[
                    0:6
                ],
                "Info: something wrong with redcords ! Not sure what to do !",
                records=str(import_response["records"]),
            )
        # Finally, print upload status if so desired
        if "count" in list(import_response.keys()):
            return import_response["count"]

    return 0


# Map 'Y' and '1' to '1', map 'N', '2', and '0' to '0', and everything else to
# 'undefined'
def map_yn_to_binary(yn):
    if (yn == "Y") or (yn == "1"):
        return "1"
    elif (yn == "N") or (yn == "2") or (yn == "0"):
        return "0"
    else:
        return ""


# Number of days between two dates (signed value is returned - negative if
# second date is before first)
def days_between_dates(date_from_str, date_to_str, date_format=date_format_ymd):
    result = (
        datetime.datetime.strptime(date_to_str, date_format)
        - datetime.datetime.strptime(date_from_str, date_format)
    ).days
    return result


# Get subject age at a given date
def get_subject_age(subject_id, at_date):
    # Get subject Date of Birth
    try:
        date_of_birth = subject_dates_of_birth[subject_id]
    except KeyError as e:
        error = "ERROR: no birth date for subject"
        slog.info(subject_id, error, e=e)
        return ""
    # Set actual age - do this after everything else, because some surveys have
    # "age" fields; we want to overwrite those
    try:
        return str(round(days_between_dates(date_of_birth, at_date) / 365.242, 10))
    except:
        if at_date != "nan":
            error = "ERROR: could not parse visit date"
            slog.info(subject_id, error, date=at_date)
        return ""


# Function to get a subject's next visit - this is so we can exclude MRI
# collected after the next visit date, but still within N days
def get_subject_next_visit_date(subject, after_visit_date, form):
    subject_visit_dates = entry_data.xs(subject, level=0)["visit_date"].dropna()
    # Exclude "Recovery" baseline from list - this will usually be the MR day of a normal visit
    subject_visit_dates = subject_visit_dates[
        subject_visit_dates.index.map(lambda key: key[1] != recovery_baseline_event)
    ]

    events_this_form = form_event_mapping[form_event_mapping[form_key] == form][
        "unique_event_name"
    ].tolist()
    # Filter by events that have this form
    subject_visit_dates = subject_visit_dates[
        subject_visit_dates.index.map(lambda key: key[1] in events_this_form)
    ]

    later_visits_this_subject = sorted(
        [date for date in subject_visit_dates.tolist() if date > after_visit_date]
    )
    if len(later_visits_this_subject) > 0:
        return later_visits_this_subject[0]
    else:
        return None


# Add one record to upload
def add_to_upload(
    session,
    form_prefix,
    form_name,
    subject_id,
    event_name,
    data,
    subject_age,
    verbose=False,
):
    record = {
        "study_id": subject_id,
        "redcap_event_name": event_name,
        "%s_record_id" % form_prefix: data.name,
        "%s_missing" % form_prefix: "0",
        "%s_missing_why" % form_prefix: "",
    }

    for key, value in dict(data).items():
        if (key in summary_field_names) or (key == "%s_complete" % form_name):
            strval = str(value).strip()  # <-- strip whitespace
            if strval == "nan":
                record[key] = ""
            else:
                if key in summary_fields_yn:
                    strval = map_yn_to_binary(strval)
                strval = re.sub(r"&quot;", '"', re.sub(r"\.0$", "", strval))
                record[key] = strval.strip()  # <-- ensure final value is stripped

    # Set actual age - do this after everything else, because some surveys have "age" fields; we want to overwrite those
    record["%s_age" % form_prefix] = subject_age

    return to_redcap(
        session,
        form_name,
        subject_id,
        event_name,
        "add_to_upload",
        record,
        data.name,
        verbose,
    )


# Add an empty record to upload - this is done to reset "disappeared" records
def add_empty_to_upload(session, form_prefix, form_name, subject_id, event_name):
    return to_redcap(
        session,
        form_name,
        subject_id,
        event_name,
        "add_empty_to_upload",
        {
            "study_id": subject_id,
            "redcap_event_name": event_name,
            "%s_record_id" % form_prefix: "",
            "%s_complete" % form_name: "",
        },
    )


# Add a record to upload that labels it "missing permanently" for parent surveys of an over-18 participant
def add_over18_to_upload(session, form_prefix, form_name, subject_id, event_name):
    return to_redcap(
        session,
        form_name,
        subject_id,
        event_name,
        "add_over18_to_upload",
        {
            "study_id": subject_id,
            "redcap_event_name": event_name,
            "%s_missing" % form_prefix: "1",
            "%s_missing_why" % form_prefix: "OVER_18",
            "%s_complete" % form_name: "1",
        },
    )


def batch(iterable, n=1):
    """
    For batch processing of records

    :param iterable:
    :param n: batch size
    :return: generator
    """
    l = len(iterable)
    for ndx in range(0, l, n):
        yield iterable[ndx : min(ndx + n, l)]


#
# Check why form is missing
#
def MissingFormChecks(
    vdate,
    date_on_or_after,
    date_before,
    subject_id,
    event_id,
    import_complete_records,
    form_name,
    incomplete_records_list,
    redcap_url
):
    # Note the first part of the session_id can be different from the subject_id - subject_id is what to go by if defined
    session_id = "{}-{}".format(subject_id, vdate)
    if session_id in import_complete_records.index:
        # record only exists in import_complete_records but not in records_this_subject.
        if not import_complete_records[complete_label][session_id]:
            # the form exists but is incomplete
            slog.info(
                session_id,
                "Error: The status of the form '%s' in the Import project is incomplete while it is unverified or complete in the Entry project!"
                % (form_name),
                explanation=(
                    "The most common causes of this error: (1) the site "
                    "shifted the visit date forward, which caused the form"
                    " collected between the original visit date and the "
                    "new visit date to dissociate, or (2) site manually "
                    "edited `[form]_record_id` without reference to any "
                    "actual Import record. **Before all else, check the "
                    "history of the visit date field.**"
                ),
                entry_subject_id=subject_id,
                form_name=form_name,
                event_id=event_id,
                redcap_url=redcap_url,
                import_visit_dates_of_not_incomplete_records=incomplete_records_list.to_string(),
                target_visit_date=vdate,
                date_range=str([date_on_or_after, date_before]),
                info="The experiment_site_id is the id of the form in the Import project this error message refers to",
                cmd=" ".join(sys.argv),
            )
            return

        if import_complete_records[exclude_label][session_id]:
            slog.info(
                session_id,
                "Error: The form '"
                + form_name
                + "' in the Import project is excluded while it is not excluded in the entry project!",
                entry_subject_id=subject_id,
                form_name=form_name,
                event_id=event_id,
                redcap_url=redcap_url,
                import_visit_dates=records_this_subject[date_label].to_string(),
                info="If that is on purpose and 'Manually Entered' flag exists in the form, please set it to 'yes' in the record of the entry project",
                target_visit_date=vdate,
                date_range=str([date_on_or_after, date_before]),
            )
            return

    slog.info(
        session_id,
        "WARNING: Previously assigned form '"
        + form_name
        + "' seems to have disappered due to difference between Data Entry and Import form status.",
        entry_subject_id=subject_id,
        form_name=form_name,
        event_id=event_id,
        redcap_url=redcap_url,
        import_visit_dates=records_this_subject[date_label].to_string(),
        info="There are two common causes, either the visit date has changed so that entry isn't in window anymore or form was hand entered in D.E. and doesn't exist in Import!",
        target_visit_date=vdate,
    )


#
# MAIN
#


# Setup command line parser
parser = argparse.ArgumentParser(
    description="Update longitudinal project forms (i.e., data_entry) from the data capture laptops (i.e. import_labtops)",
    formatter_class=argparse.ArgumentDefaultsHelpFormatter,
)
parser.add_argument("-v", "--verbose", help="Verbose operation", action="store_true")
parser.add_argument(
    "-n",
    "--no-upload",
    help="Do not upload any data back to the REDCap server",
    action="store_true",
)
parser.add_argument(
    "--max-days-after-visit",
    help="Maximum number of days the scan session can be after the entered "
    "'visit date' in REDCap to be assigned to a given event. This applies"
    " ONLY to Arm 1: Standard Protocol. Other arms (e.g., Arm 3: Sleep) "
    "require EXACT date matches.",
    action="store",
    default=120,
    type=int,
)
parser.add_argument(
    "--forms",
    help="Select specific forms to update. Separate multiple forms with commas.",
    action="store",
    default=None,
)
parser.add_argument(
    "-m",
    "--missing-only",
    help="Only look for missing data, but do not update existing records in the netry project. This"
    " significantly speeds up processing, but edits made to imported data "
    "will not propagate.",
    action="store_true",
)
parser.add_argument(
    "-a",
    "--update-all",
    help="Update all forms in data entry, regardless of current completion status "
    "(otherwise, only update records where data completion status in import_labtops "
    "exceeds form status in data_entry)",
    action="store_true",
)
parser.add_argument(
    "-x",
    "--no-excluded",
    help="Do not process any subjects marked as 'excluded' in REDCap.",
    action="store_true",
)
parser.add_argument(
    "--reset-disappeared",
    help="Reset form status of records that have 'disappeared', i.e., an imported"
    " record was previously assigned but can no longer be found.",
    action="store_true",
)
parser.add_argument(
    "--study-id",
    help="Limit processing to subject id (e.g., A-00000-F-1) - multiple ones seperate them by ',' (e.g., 'A-00000-F-1,A-00002-F-2') ",
    action="store",
    default=None,
)
parser.add_argument(
    "-p",
    "--post-to-github",
    help="Post all issues to GitHub instead of std out.",
    action="store_true",
)

parser.add_argument(
    "-t",
    "--time-log-dir",
    help="If set then time logs are written to that directory",
    action="store",
    default=None,
)

parser.add_argument(
    "--progress-bar", help="Show TQDM progress bar", action="store_true"
)

args = parser.parse_args()


slog.init_log(
    args.verbose,
    args.post_to_github,
    "NCANDA Import-Laptops: Update Form Status",
    "update_visit_data",
    args.time_log_dir,
)
slog.startTimer1()

# Create a session object to connect to different projects
# TO-DO: Submit it under try-except ??
session = sibispy.Session()

if not session.configure():
    if args.verbose:
        print("Error: session configure file was not found")

    sys.exit()

sibis_config = session.get_operations_dir()
special_cases_file = os.path.join(sibis_config, "special_cases.yml")
if not os.path.isfile(special_cases_file):
    slog.info(
        "update_visit_data",
        "Error: The following file does not exist :" + special_cases_file,
    )
    sys.exit(1)

# Get a list of cases outside the visit window that should be included.
with open(os.path.join(sibis_config, "special_cases.yml")) as fi:
    special_cases = yaml.safe_load(fi)
    exceptions_data = special_cases.get("update_visit_data", {})

if args.forms:
    forms = dict()
    for f in args.forms.split(","):
        if f in list(all_forms.keys()):
            forms[f] = all_forms[f]
        elif f in list(all_forms.values()):
            lookup = [k for (k, v) in all_forms.items() if v == f]
            forms[lookup[0]] = f
        else:
            print("WARNING: no form with name or prefix '%s' defined.\n" % f)
else:
    forms = all_forms

if args.verbose:
    print("Processing the following forms:\n\t", "\n\t".join(sorted(forms.values())))

form_prefixes = list(forms.keys())
form_names = list(forms.values())

# Open connection with REDCap server - Import Project
import_project = session.connect_server("import_laptops", True)
if not import_project:
    if args.verbose:
        print("Error: Could not connect to Redcap for Import Project")

    sys.exit()

# Open connection with REDCap server - Data Entry
redcap_project = session.connect_server("data_entry", True)
if not redcap_project:
    if args.verbose:
        print("Error: Could not connect to Redcap for Data Entry")

    sys.exit()


# Get list of all field names in the summary project - this is to figure out which fields to copy
summary_field_names = [field["field_name"] for field in redcap_project.metadata]

# Get list of all 0/1 encoded Yes/No fields (either radio or dropdown) - these
# need to be recoded by map_yn_to_binary when copied.
#
# For legacy reasons, we're also recoding "2, Not sure" to 0, even though in
# other non-responses (1717, ...) we're letting the value come through.
#
# NOTE: Regex altered to work with explicitly enumerated Yes/No/Not
#       selected/Not Sure options; it will not work when other options are
#       present, or when option text has a different phrasing.
yesno_regex = r"^( *0, *No(t selected)? *\| *1, *Yes| *1, *Yes *\| *0, *No(t selected)? *)( *\| *2, *Not Sure *)?$"
summary_fields_yn = [
    field["field_name"]
    for field in redcap_project.metadata
    if (
        (field["field_type"] == "yesno")
        or (
            field["field_type"] in ["radio", "dropdown"]
            and re.match(yesno_regex, field["select_choices_or_calculations"])
        )
    )
]

# What forms are at what event?
form_event_mapping = redcap_project.export_instrument_event_mappings(format_type="df")

# What "form_name" is form_event_mapping using?
form_key = session.get_redcap_form_key()

# Get record IDs, visit labels, visit dates, and completion status for all laptop forms
entry_data_fields = (
    [("%s_complete" % form) for form in form_names]
    + [("%s_missing" % form) for form in form_prefixes]
    + [("%s_record_id" % form) for form in form_prefixes]
    + [("%s_date" % form) for form in form_prefixes]
)
entry_data_fields += ["study_id", "dob", "visit_date", "exclude"]

for form_id in forms_date_increments:
    if all_forms[form_id] in form_names:
        entry_data_fields += ["sleep_date"]
        break

if "parent_report" in form_names:
    entry_data_fields += ["parentreport_manual"]

# Not needed - automatically filled in later

# Get list of existing records
if args.study_id:
    entry_data = session.redcap_export_records_from_api(
        time_label=None,
        api_type="data_entry",
        records=args.study_id.split(","),
        fields=entry_data_fields,
        event_name="unique",
        format_type="df",
        export_data_access_groups=True,
    )
else:
    entry_data = session.redcap_export_records_from_api(
        time_label=None,
        api_type="data_entry",
        fields=entry_data_fields,
        event_name="unique",
        format_type="df",
        export_data_access_groups=True,
    )


# Save dates of birth for later (these only exist for the 'baseline_visit_arm_1'
# event, but we need them for other arms as well
try:
    concat = [
        entry_data.xs(event, level=1)["dob"].dropna()
        for event in ["baseline_visit_arm_1"] #, "baseline_visit_arm_4"]
    ]
except:
    concat = [
        entry_data.xs(event, level=1)["dob"].dropna()
        for event in ["baseline_visit_arm_1"]
    ]

subject_dates_of_birth = pandas.concat(concat)

# Remove "excluded" cases - need to do that after getting birth dates, just in
# case.
if args.no_excluded:
    entry_data = entry_data[entry_data["exclude"] != 1]

#
# MAIN LOOP
#
# For each form, get imported data
all_records = 0
all_uploaded = 0

for form_prefix, form_name in forms.items():
    if args.verbose:
        print("Processing form", form_prefix, "/", form_name)

    total_records = 0
    total_uploaded = 0

    complete_label = "%s_complete" % form_name
    exclude_label = "%s_exclude" % form_prefix
    fields_list = [complete_label, exclude_label]

    if args.study_id:
        subject_id_label = "%s_subject_id" % form_prefix
        fields_list.append(subject_id_label)

    # ==> Export data from laptops for this form from REDCap.
    import_complete_records = session.redcap_export_records_from_api(
        time_label=None, api_type="import_laptops", fields=fields_list, format_type="df"
    )

    # First, get "complete" and "exclude" fields for this form for all records to
    # find which ones actually have data and are not excluded.
    # Drop all empty form records (labelled 'incomplete')
    if import_complete_records is None or not isinstance(import_complete_records, pandas.DataFrame):
        error_id = f"{form_prefix}_{form_name}-export-records-failed"
        slog.info(
            error_id,
            "Warning: stop processing as no records in import project for this form",
            info="Was unable to get any records from import_laptops api for form. Check REDCap connection.",
            study_id_list=args.study_id,
        )
        continue

    complete_records = import_complete_records[
        import_complete_records[complete_label] > 0
    ]
    # Drop "excluded" records for speed
    complete_records = complete_records[complete_records[exclude_label] != 1]

    if args.study_id:
        # only works if record_id is correctly labelled which is not always the case
        s_records = pandas.DataFrame(columns=complete_records.columns)
        for sid in args.study_id.split(","):
            sids = sid.strip()
            sidr = complete_records[
                [
                    sids in record_id_record_subject_id[0]
                    or sids == str(record_id_record_subject_id[1]).strip()
                    for record_id_record_subject_id in zip(
                        complete_records.index.tolist(),
                        complete_records[subject_id_label].tolist(),
                    )
                ]
            ]
            if len(sidr):
                s_records = pandas.concat([s_records, sidr])

        complete_records = s_records
        if args.verbose:
            print(
                "Record list from Import project:", str(complete_records.index.tolist())
            )

    records = complete_records.index.tolist()
    if len(records) == 0:
        error_id = form_name
        if args.study_id:
            error_id += "-" + hashlib.sha1(str(args.study_id).encode()).hexdigest()[0:6]

        # if you stop here then missing data might be not discovered
        slog.info(
            error_id,
            "Warning: stop processing as no records in import project for this form",
            info="If study_id_list is not empty then define for the option '--study-id' of 'update_visit_data' a list of study_ids that contains at least one subject with a record of that form so that all study_ids are fully processed, i.e., checked for missing data!",
            study_id_list=args.study_id,
        )
        continue

    # Next, export actual records, making sure we get everything as string,
    # and replace all "nan"s with empty strings, "" using batches of 100 records.

    forms = [form_name]
    return_format = "df"
    df_kwargs = {"index_col": import_project.def_field, "dtype": "object"}
    returned_records = []

    for record_batch in batch(records, n=100):
        # First attempt
        df = session.redcap_export_records_from_api(
            time_label=None,
            api_type="import_laptops",
            records=record_batch,
            forms=forms,
            format_type=return_format,
            df_kwargs=df_kwargs,
        )

        if df is None or df.empty:
            if args.verbose:
                print("No REDCap data records found from export, retrying in one minute")
            time.sleep(60)  # Wait 1 minute and try again
            df = session.redcap_export_records_from_api(
                time_label=None,
                api_type="import_laptops",
                records=record_batch,
                forms=forms,
                format_type=return_format,
                df_kwargs=df_kwargs,
            )

            if df is None or df.empty:
                error_id = f"{form_name}_{datetime.datetime.now().strftime('%m/%d/%Y')}"
                
                slog.info(
                    error_id,
                    "ERROR: REDCap connection issue or no data returned after retry",
                    info="Tried twice to fetch data from REDCap and failed. Please verify connectivity.",
                )
                sys.exit(1)

        returned_records.append(df.map(nan_to_empty))
        imported_records = pandas.concat(returned_records)

    if args.verbose:
        print(
            "Form {} has {} records in import project.".format(
                forms, len(imported_records)
            )
        )

    # From the index, extract the original subject ID and date from each imported
    # record IO and use these wherever not overridden by manually-entered values
    subject_label = "%s_subject_id" % form_prefix
    date_label = "%s_date" % form_prefix
    if len(imported_records) > 0:
        # Get rid of empty spaces - causes issues
        imported_records[subject_label] = imported_records[subject_label].str.strip()

        # subject_id field not filled in will read it from index name (e.g. C-70109-F-0-2015-12-07) minus the last 11 letters) - see sleep_study_morning_questionnaire of A-00068-M-4-2016-08-29 as example
        imported_records[subject_label] = imported_records.apply(
            lambda row: row[subject_label].upper()
            if row[subject_label] != ""
            else row.name[0:-11].upper(),
            axis=1,
        )

        # if the date field is not filled in will read it from index name (e.g. C-70109-F-0-2015-12-07) only the last 11 letters
        imported_records[date_label] = imported_records.apply(
            lambda row: row[date_label] if row[date_label] != "" else row.name[-10:],
            axis=1,
        )

    # Select the events that actually have this form (first, to handle summary forms,
    # figure out what actual form the "FORM_complete" field is in)
    try:
        summary_form_name = [
            field["form_name"]
            for field in redcap_project.metadata
            if field["field_name"] == complete_label
        ][0]
    except:
        # If the above failed (due to empty list, presumably), then this is not a
        # hierarchical form and we should just use the given form name
        summary_form_name = form_name
    instrument_events_list = form_event_mapping[
        form_event_mapping[form_key] == summary_form_name
    ]["unique_event_name"].tolist()

    entry_form_data = entry_data[
        entry_data.index.map(lambda x: x[1] in instrument_events_list)
    ]

    # Drop all records that have been marked as permanently missing
    missing_label = "%s_missing" % form_prefix
    entry_form_data = entry_form_data[entry_form_data[missing_label] != 1]

    # Drop all forms that have been manually entered
    manual_label = "%s_manual" % form_prefix
    if manual_label in entry_form_data.columns:
        entry_form_data = entry_form_data[entry_form_data[manual_label] != 1]

    # Drop all entry project records when doing "missing only", or else unless "update all",
    # drop records where this form is already marked "Completed"
    if args.missing_only:
        entry_form_data = entry_form_data[~(entry_form_data[complete_label] > 0)]
    elif not args.update_all:
        entry_form_data = entry_form_data[~(entry_form_data[complete_label] > 1)]

    # Go over all summary records (i.e., the visit log) from entry project and find corresponding imported records
    #TODO: See how to make this chunk more efficient
    index = 0
    
    project_id = redcap_project.export_project_info(format_type="json")['project_id']

    for key, row in tqdm(
        entry_form_data.iterrows(),  # the actual iterator
        total=entry_form_data.shape[0],  # progress bar meta
        desc=form_prefix,
        disable=not args.progress_bar,
    ):
        study_id = key[0]
        redcap_event_name = key[1]
        
        redcap_url = session.get_formattable_redcap_form_address(project_id, redcap_event_name, study_id, form_name)
        
        if args.verbose:
            print("Processing", key)
        # Select imported records for this subject
        records_this_subject = imported_records[
            imported_records[subject_label] == key[0]
        ].drop([subject_label], axis=1)

        # Arm 3 - For sleep data, get the visit date for this record
        if key[1].endswith("arm_3"):
            sleep_date = str(row["sleep_date"])
            subject_age = get_subject_age(key[0], sleep_date)
            if (sleep_date != "nan") and (subject_age != ""):
                total_records += 1
                # Select all records within given maximum number of days after visit date
                form_target_date = (
                    datetime.datetime.strptime(sleep_date, date_format_ymd)
                    + datetime.timedelta(forms_date_increments[form_prefix])
                ).strftime(date_format_ymd)
                records_this_visit = records_this_subject[
                    records_this_subject[date_label] == form_target_date
                ]
                # Make sure there is only one, unique record
                if len(records_this_visit) > 1:
                    # Not unique - bail
                    site_forward = entry_data.loc[key, "redcap_data_access_group"]
                    site_resolution = (
                        "Please label one of the two colliding "
                        "records as 'Excluded' in the 'Imported' "
                        "project.  The remaining record will then "
                        "be assigned when the script runs the next time."
                    )
                    error = "More than one record found for subject on event with same visit date"
                    slog.info(
                        "{}-{}".format(key[0], form_target_date),
                        error,
                        subject_id=key[0],
                        form_name=form_name,
                        event_id=key[1],
                        redcap_url=redcap_url,
                        visit_date=form_target_date,
                        site_forward=site_forward,
                        site_resolution=site_resolution,
                    )
                    if args.verbose:
                        print(records_this_visit)
                elif len(records_this_visit) == 1:
                    total_uploaded += add_to_upload(
                        session,
                        form_prefix,
                        form_name,
                        key[0],
                        key[1],
                        records_this_visit.iloc[0],
                        subject_age,
                        args.verbose,
                    )
                elif (entry_form_data[complete_label][key] > 0) and (
                    entry_form_data[missing_label][key] != 1
                ):
                    errorMSG = (
                        "WARNING: Previously assigned form '"
                        + form_name
                        + "' seems to have disappered."
                    )
                    if form_target_date != entry_form_data[date_label][key]:
                        slog.info(
                            "{}-{}".format(key[0], form_target_date),
                            errorMSG,
                            subject_id=key[0],
                            form_name=form_name,
                            event_id=key[1],
                            redcap_url=redcap_url,
                            info="'Form target date' does not match anymore the administration date on the form! If the visit date of the sleep study was changed contact site if it is ok to change the date of form in import project!",
                            form_target_date=form_target_date,
                            form_date=entry_form_data[date_label][key],
                        )

                    else:
                        slog.info(
                            "{}-{}".format(key[0], form_target_date),
                            errorMSG,
                            subject_id=key[0],
                            form_name=form_name,
                            event_id=key[1],
                            redcap_url=redcap_url,
                            info="Not sure what happened - it is not a date problem !",
                            form_target_date=form_target_date,
                            form_date=entry_form_data[date_label][key],
                        )

                    if args.reset_disappeared:
                        total_uploaded += add_empty_to_upload(
                            session, form_prefix, form_name, key[0], key[1]
                        )
            continue

        # Process everything but sleep arm
        visit_date = str(row["visit_date"])
        subject_age = get_subject_age(key[0], visit_date)
        if (visit_date != "nan") and (subject_age != ""):
            total_records += 1

            # Kilian : Change this later for plus so assigned according to webcnp or mri_report depending which one of them was not acquired on visit_date
            
            #TODO: Move all of this date window finding for list of applicable forms to a 
            #   separate function

            # For Recovery Baseline, extend search window back in time to capture and
            # duplicate data from most recent standard visit
            if key[1] == recovery_baseline_event:
                date_on_or_after = (
                    datetime.datetime.strptime(visit_date, date_format_ymd)
                    - datetime.timedelta(args.max_days_after_visit)
                ).strftime(date_format_ymd)
            else:
                date_on_or_after = visit_date

            date_before = (
                datetime.datetime.strptime(visit_date, date_format_ymd)
                + datetime.timedelta(args.max_days_after_visit)
            ).strftime(date_format_ymd)
            # If we have a next visit date that also has this form, and it's before N days,
            # use that instead as the upper bound for the search window
            next_visit_date = get_subject_next_visit_date(key[0], visit_date, form_name)
            if next_visit_date and next_visit_date < date_before:
                date_before = next_visit_date

            # Select records in permissible range
            records_this_visit = records_this_subject[
                records_this_subject[date_label] >= date_on_or_after
            ]
            records_this_visit = records_this_visit[
                records_this_visit[date_label] < date_before
            ]

            subject_visit_id = "{}-{}".format(key[0], visit_date)
            exception_list = exceptions_data.get(subject_visit_id)
            if exception_list:
                if args.verbose:
                    print("Exception:", exception_list)
                for excep_date in exception_list.split(","):
                    records_this_visit = pandas.concat (
                        [
                            records_this_visit,
                            records_this_subject[
                                records_this_subject[date_label] == excep_date
                            ],
                        ]
                    )

            # First, treat the case where we have MORE THAN ONE record in the search window
            if len(records_this_visit) > 1:
                # Sort records by date difference from visit date
                records_this_visit["days_from_visit"] = records_this_visit[
                    date_label
                ].map(lambda d: abs(days_between_dates(visit_date, d)))
                records_this_visit.sort_values(by="days_from_visit", inplace=True)
                records_this_visit_samedays = records_this_visit[
                    records_this_visit["days_from_visit"]
                    == records_this_visit.iloc[0]["days_from_visit"]
                ]

                if len(records_this_visit_samedays) > 1:
                    error = "ERROR: more than one closest record"
                    site_forward = entry_data.loc[key, "redcap_data_access_group"]
                    site_resolution = (
                        "Please label one of the two colliding records "
                        "as 'Excluded' in the 'Imported' project.  The "
                        "remaining record will then be assigned when the "
                        "script runs the next time."
                    )
                    slog.info(
                        "{}-{}".format(key[0], visit_date),
                        error,
                        subject_id=key[0],
                        form_name=form_name,
                        event_id=key[1],
                        redcap_url=redcap_url,
                        visit_date=visit_date,
                        serach_range="["
                        + str(date_on_or_after)
                        + ","
                        + str(date_before)
                        + ")",
                        records=str(records_this_visit_samedays.index.tolist()),
                        site_forward=site_forward,
                        site_resolution=site_resolution,
                    )
                else:
                    # Unique by proximity to visit_date - upload record that is closest
                    records_this_visit.drop(["days_from_visit"], axis=1)
                    total_uploaded += add_to_upload(
                        session,
                        form_prefix,
                        form_name,
                        key[0],
                        key[1],
                        records_this_visit.iloc[0],
                        subject_age,
                        args.verbose,
                    )
            # Upload record if we have EXACTLY one
            elif len(records_this_visit) > 0:
                total_uploaded += add_to_upload(
                    session,
                    form_prefix,
                    form_name,
                    key[0],
                    key[1],
                    records_this_visit.iloc[0],
                    subject_age,
                    args.verbose,
                )
            # Treat cases where we found NO records in given window
            elif (
                ("ssaga" in form_prefix)
                and ("parent" in form_prefix)
                and float(subject_age) > 18
            ):
                # For over-18 subjects, we do not require Parent SSAGA
                if args.verbose:
                    print(
                        "Marking over-18",
                        form_name,
                        "as missing for",
                        key[0],
                        "/",
                        key[1],
                    )
                total_uploaded += add_over18_to_upload(
                    session, form_prefix, form_name, key[0], key[1]
                )
            # We absolutely have no records to assign - check now if one had been assigned
            # previously and somehow disappeared
            elif (entry_form_data[complete_label][key] > 0) and (
                entry_form_data[missing_label][key] != 1
            ):
                MissingFormChecks(
                    visit_date,
                    date_on_or_after,
                    date_before,
                    study_id,
                    redcap_event_name,
                    import_complete_records,
                    form_name,
                    records_this_subject[date_label],
                    redcap_url
                )

                if args.reset_disappeared:
                    total_uploaded += add_empty_to_upload(
                        session, form_prefix, form_name, key[0], key[1]
                    )

    # Anything to upload?
    if args.verbose:
        print(
            "Uploaded",
            total_uploaded,
            "of",
            total_records,
            "records to form",
            form_name,
        )

    all_uploaded += total_uploaded
    all_records += total_records

slog.takeTimer1(
    "script_time",
    "{'records': " + str(all_records) + ", 'uploads': " + str(all_uploaded) + "}",
)
