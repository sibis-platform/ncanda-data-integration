#!/usr/bin/env python

##
##  See COPYING file distributed along with the ncanda-data-integration package
##  for the copyright and license terms
##
from __future__ import print_function
from __future__ import division
from builtins import str
from builtins import range
from past.utils import old_div
import os
import argparse
import cnp
import datetime
import numpy as np
import pandas
import sys 
import hashlib
import numbers
import re

import sibispy
from sibispy import sibislogger as slog

# Convert to string, or empty if nan.
def nan_to_empty( x ):
    s = str(x)
    if s != 'nan':
        return s
    else:
        return ''

def df_rounding(row): 
    for ind in row.index:
        if isinstance(row[ind], numbers.Number): 
            row[ind]= round(row[ind],6) 
    return row

# Setup command line parser
parser = argparse.ArgumentParser( description="Update WebCNP summary forms from imported data ", formatter_class=argparse.ArgumentDefaultsHelpFormatter )
parser.add_argument( "-v", "--verbose", help="Verbose operation", action="store_true")
parser.add_argument( "--max-days-after-visit", help="Maximum number of days the scan session can be after the entered 'visit date' in REDCap to be assigned to a given event.", action="store", default=120, type=int)
parser.add_argument( "-a", "--update-all", help="Update all summary records, regardless of current completion status (otherwise, only update records where cnp_datasetid is empty)",
                     action="store_true")
parser.add_argument( "-f", "--force", help="Force update up of everything from import, including overwriting summary score status (otherwise only max score between the two is used)", action="store_true")
parser.add_argument( "--records-per-upload", help="Maximum number of records to upload to REDCap using a single HTTP request. This limits the request size and prevents upload problems.", action="store", default=30, type=int)
parser.add_argument( "-n", "--no-upload", help="Do not upload any data to REDCap server; instead write to CSV file with given path.", action="store")
parser.add_argument("-p", "--post-to-github", help="Post all issues to GitHub instead of std out.", action="store_true")
parser.add_argument("-t","--time-log-dir",
                    help="If set then time logs are written to that directory",
                    action="store",
                    default=None)
parser.add_argument( "--study-id", help="Limit export by subject site id (e.g., 'X-12345-X-9').", action="store", default=None )
parser.add_argument( "--event", help="Limit export by event id (e.g., '8y_visit_arm_1')", action="store", default=None )
args = parser.parse_args()

# Open connection with REDCap server - first for the Penn import project (data source)
slog.init_log(args.verbose, args.post_to_github,'NCANDA Import', 'update_summary_forms', args.time_log_dir)
slog.startTimer1()

session = sibispy.Session()
if not session.configure():
    if args.verbose:
        print("Error: session configure file was not found")

    sys.exit()

rc_import = session.connect_server('import_webcnp', True)
if not rc_import : 
    if args.verbose:
        print("Error: Could not connect to the REDCap project 'import_webcnp'") 

    sys.exit(1)


# Second connection for the Summary project (this is where we put data)
rc_summary = session.connect_server('data_entry', True)
if not rc_summary : 
    if args.verbose:
        print("Error: Could not connect to the REDCap project 'data_entry'") 

    sys.exit(1)

# Get list of variables common to import and summary projects (minus 'cnp_' prefix in the latter)
cnp_copy_variables = cnp.get_copy_variables( rc_import, rc_summary )

# Get the event-form mapping so we can select the events that should have CNP data
form_event_mapping = rc_summary.export_fem( format='df' )
form_key = session.get_redcap_form_key()
cnp_events_list = form_event_mapping[form_event_mapping[form_key] == 'cnp_summary' ]['unique_event_name'].tolist()

# Retrieve subject IDs, events, exclusions, visit dates, and current CNP summary data
fields_summary = ['study_id', 'dob', 'exclude', 'visit_date', 'cnp_summary_complete', 'cnp_missing', 'cnp_datasetid', 'cnp_age', 'cnp_instruments']
fields_summary+= [ 'cnp_%s' % v for v in cnp_copy_variables ]
fields_summary+= [ 'cnp_%s_zscore' % v for v in list(cnp.mean_sdev_by_field_dict.keys()) ]
baseline_events = ['baseline_visit_arm_1','baseline_visit_arm_4'] # these are the "baseline" events of the study arms that have them

summary_records = rc_summary.export_records(
    fields=fields_summary,
    event_name='unique',
    format='df',
    export_data_access_groups=True,
    df_kwargs={'low_memory': False})
summary_records = summary_records.set_index(['study_id', 'redcap_event_name'])
# Drop all records that don't have "visit_date", i.e., all events from arms other than Arm 1 (Standard Protocol)
summary_records = summary_records[ summary_records['visit_date'].map( lambda x: str(x) != 'nan' ) ]

# Now drop all records from events that don't have CNP data collected
summary_records = summary_records[ summary_records.index.map( lambda x: x[1] in cnp_events_list ) ]

# Now select ids 
if args.study_id : 
    if args.study_id in summary_records.index : 
        summary_records = summary_records.xs(args.study_id)
        summary_records.reset_index(inplace=True)
        summary_records['study_id'] = args.study_id

        baseline_events_tmp = [] 
        for event in baseline_events :
            if event in summary_records['redcap_event_name'].unique() :
                baseline_events_tmp += [event] 

        baseline_events = baseline_events_tmp 

        summary_records.set_index(['study_id', 'redcap_event_name'],inplace=True)

    else :
        print("ERROR: No record found for",  args.study_id) 
        sys.exit(1)

# Have to do it as otherwise int values are changed to float if NA included in colums and that creates problems  
summary_records['cnp_missing'] = summary_records['cnp_missing'].fillna(0).astype(int)

# Save dates of birth for later (these only exist for the 'baseline_visit_arm_1' and  'baseline_visit_arm_4' events, but we need them for other arms as well
subject_dates_of_birth = pandas.concat( [ summary_records.xs( event, level=1 ) for event in baseline_events ] )['dob']

if args.event :
    summary_records = summary_records.xs(args.event,level=1,drop_level=False)
    
    if len(summary_records) == 0 :
        print("ERROR: No record found for",  args.event) 
        sys.exit(1)
                
# Convert all copied columns to strings to avoid issues with missing values being unable to convert to floats
summary_records['cnp_datasetid'] = summary_records['cnp_datasetid'].map( nan_to_empty )
summary_records['cnp_summary_complete'] = summary_records['cnp_summary_complete'].map( nan_to_empty )
for cnpvar in cnp_copy_variables:
    summary_records['cnp_%s' % cnpvar] = summary_records['cnp_%s' % cnpvar].map( str )

# If we update all records, make sure to reset everything, so stuff can be made disappear in the summary, if it was removed from the imported project
if args.update_all or args.force:
    summary_records['cnp_datasetid'] = ''

    for cnpvar in cnp_copy_variables:
        summary_records['cnp_%s' % cnpvar] = ''

    for cnpvar in list(cnp.mean_sdev_by_field_dict.keys()):
        summary_records['cnp_%s_zscore' % cnpvar] = ''

    for [k,v] in cnp.instruments.items():
        summary_records['cnp_instruments___%s' % k.replace('_','') ] = '0'
        
    summary_records_secondary=[]
else:
    summary_records_secondary = summary_records[ summary_records['cnp_datasetid'] != '' ]
    summary_records = summary_records[ summary_records['cnp_datasetid'] == '' ]

    # list all entries for which 'cnp_exam_location' or device is empty but the reset of the form is defined 
    summary_records_secondary =  summary_records_secondary[summary_records_secondary['cnp_test_sessions_dotest'] >= "2020-10-01"]
    summary_records_secondary =  summary_records_secondary[(summary_records_secondary['cnp_exam_location'] == 'nan')  | (summary_records_secondary['cnp_input_device'] == 'nan')  ]

# For now, get the "complete" fields for each instrument as well as record ID, subject ID, and date of test
fields_imported = ['record_id', 'test_sessions_subid', 'cnp_exclude'] + cnp_copy_variables
for i in list(cnp.instruments.values()):
    fields_imported.append( '%s_complete' % i )
imported_records = rc_import.export_records( fields=fields_imported, format='df', df_kwargs={'low_memory': False}).set_index('record_id')
for cnpvar in cnp_copy_variables:
    imported_records[cnpvar] = imported_records[cnpvar].map( nan_to_empty )

# Drop excluded records
exclude_idx = imported_records['cnp_exclude'] == 1
imported_records = imported_records.loc[~exclude_idx]
if args.verbose:
    print('Dropping {} records marked excluded in Imported from PennCNP'
          .format(exclude_idx.sum()))

# From the index, extract the original subject ID and date from each imported record IO and use these wherever not overridden by manually-entered values
imported_records['test_sessions_subid'] = imported_records['test_sessions_subid'].map( nan_to_empty )
imported_records['test_sessions_subid'] = imported_records.apply( lambda row: row['test_sessions_subid'] if row['test_sessions_subid']!='' else row.name[:11], axis=1 )

imported_records['test_sessions_dotest'] = imported_records['test_sessions_dotest'].map( nan_to_empty )
imported_records['test_sessions_dotest'] = imported_records.apply( lambda row: row['test_sessions_dotest'] if row['test_sessions_dotest']!='' else row.name[12:22], axis=1 )

#    
# Go over all summary records (i.e., the visit log) and find corresponding imported records
#
for key, row in summary_records.iterrows():
    event = key[1]
    arm_num = int(re.search('arm_(\d*)', event).group(1))

    # Select imported records for this subject
    records_this_subject = imported_records[ imported_records['test_sessions_subid'] == key[0] ]

    # Get the visit date for this record
    visit_date = row['visit_date']
    if not str(visit_date) == 'nan':
        # Select all records within given maximum number of days after visit date
        records_this_visit = records_this_subject[ records_this_subject['test_sessions_dotest'] >= visit_date ]
        visit_date_plusNd = (datetime.datetime.strptime( visit_date, '%Y-%m-%d') + datetime.timedelta(args.max_days_after_visit)).strftime('%Y-%m-%d')
        records_this_visit = records_this_visit[ records_this_visit['test_sessions_dotest'] <= visit_date_plusNd ]

        if len( records_this_visit ) > 0:
            # Make sure there is only one, unique record
            if len( records_this_visit ) > 1:
                # Not unique - warning
                error = 'WARNING: More than one CNP record found for subject %s, event %s, visit date %s - selecting the latest record' % (key[0],key[1],visit_date)

                import_project_id = rc_import.export_project_info()['project_id']
                formattable_redcap_address = session.get_formattable_redcap_subject_address(import_project_id,arm_num)
                
                records_list = records_this_visit.index.tolist()
                redcap_urls = list(map(lambda record_id: formattable_redcap_address % (record_id), records_list))
                
                slog.info("DuplicateRecords-" + hashlib.sha1(error.encode()).hexdigest()[0:6], error,
                          records_this_visit = str(records_list),
                          redcap_urls=redcap_urls,
                          site_forward=row.get('redcap_data_access_group'),
                          site_resolve="Determine which record should be "
                          "passed on to Data Entry project and mark the other "
                          "one excluded in the Imported from PennCNP project. ")

            # Unique record - copy data from imported project to summary form
            cnp_data = records_this_visit.iloc[len(records_this_visit) - 1]
            summary_records.at[key, 'cnp_datasetid'] = cnp_data.name

            date_of_birth = subject_dates_of_birth[key[0]]
            date_format_ymd = '%Y-%m-%d'
            age_in_years = old_div((datetime.datetime.strptime( cnp_data['test_sessions_dotest'], date_format_ymd ) - datetime.datetime.strptime( date_of_birth, date_format_ymd )).days, 365.242)
            summary_records.at[key, 'cnp_age'] = str( age_in_years )

            # Copy all variables that we want in the summary
            for cnpvar in cnp_copy_variables:
                column_name = 'cnp_%s' % cnpvar
                summary_records.at[key, column_name] = cnp_data[cnpvar]

            # Compute all z scores (only between 8 and 21 years)
            if age_in_years >= 8 and age_in_years < 22:
                age_group = int( old_div(age_in_years, 2) ) * 2
                for cnpvar in list(cnp.mean_sdev_by_field_dict.keys()):
                    if cnp_data[cnpvar] != '':
                        mean_sdev_col_label = cnp.mean_sdev_by_field_dict[cnpvar]
                        age_mean = cnp.mean_sdev_byage_table['%s_mean' % mean_sdev_col_label][age_group]
                        age_sdev = cnp.mean_sdev_byage_table['%s_sd' % mean_sdev_col_label][age_group]
                        age_normalization = old_div(( float( cnp_data[cnpvar] ) - age_mean ), age_sdev)
                        column_name = 'cnp_%s_zscore' % cnpvar
                        summary_records.at[key, column_name] = age_normalization

            # Check completion status of the CNP instruments
            for [k,v] in cnp.instruments.items():
                new_summary_complete = 1
                if cnp_data['%s_complete' % v] > 0:
                    column_name = 'cnp_instruments___%s' % k.replace('_','')
                    summary_records.at[key, column_name] = '1'
                else:
                    column_name = 'cnp_instruments___%s' % k.replace('_','')
                    summary_records.at[key, column_name] = '0'
                    new_summary_complete = 0
            
            try:
                curr_summary_complete = pandas.to_numeric(summary_records.at[key, 'cnp_summary_complete']).astype(int)
                
                if args.force:
                    summary_records.at[key, 'cnp_summary_complete'] = new_summary_complete
                elif args.update_all:
                    # only update summary complete score if new value is > old
                    if curr_summary_complete < new_summary_complete:
                        summary_records.at[key, 'cnp_summary_complete'] = new_summary_complete
                    else:
                        summary_records.at[key, 'cnp_summary_complete'] = curr_summary_complete
                else:
                    summary_records.at[key, 'cnp_summary_complete'] = curr_summary_complete
            except:
                # if fails, then assume current summary complete status is blank
                summary_records.at[key, 'cnp_summary_complete'] = new_summary_complete

        elif summary_records['cnp_summary_complete'][key] != '' and float( summary_records['cnp_summary_complete'][key] ) > 0 and ( summary_records['cnp_missing'][key] != 1 ):
            error = ("WARNING: Previously assigned WebCNP data for subject {}, "
                     "event {} appears to have disappeared.").format(key[0], key[1])
            data_entry_project_id = rc_summary.export_project_info()['project_id']
            study_id = key[0]
            redcap_url = session.get_formattable_redcap_subject_address(data_entry_project_id,arm_num, study_id)

            slog.info("MissingCNP-" + hashlib.sha1(error.encode()).hexdigest()[0:6],
                      error,
                      redcap_url=redcap_url,
                      description=(
                          "Either the data has been removed from Data Entry, "
                          "or the CNP has not made it through the pipeline "
                          "despite the site expecting it (and marking it "
                          "not-missing."))

# Drop all summary records for which there is no CNP data
summary_records = summary_records[ summary_records['cnp_datasetid'] != '' ]

# Drop all (logically) read-only columns from the summary data - these are the ones that are neither index-related (subject, event), nor part of the data imported from WebCNP
summary_records = summary_records.drop( [ 'dob', 'exclude', 'visit_date' ], axis=1 )


# Since redcap expects int values for this field
summary_records['cnp_exam_location'] = pandas.to_numeric(summary_records['cnp_exam_location']).astype('Int64')
summary_records['cnp_input_device'] = pandas.to_numeric(summary_records['cnp_input_device']).astype('Int64')
complete_vars = [val for val in summary_records.columns if 'cnp_instruments_' in val]
summary_records[complete_vars] = summary_records[complete_vars].apply(pandas.to_numeric).astype('Int64')

uploaded_count = 0

# round up age and z-scores as records as otherwise creates problems when writing to redcap 
# summary_records=summary_records['cnp_age'].astype(float).round(6)
rnd_list = ['cnp_age']
for col_name in summary_records.columns.values:
    if col_name.endswith('_zscore') :
        rnd_list += [col_name] 

summary_records[rnd_list] = summary_records[rnd_list].apply(df_rounding, axis=1) 

        # col = summary_records[col_name]
        # Did not work as there was a string somewhere still
        # summary_records.loc[col.notnull(),col_name] = col[col.notnull()].astype(float).round(6)
        #apply(rounding, axis=1 )

if args.no_upload:
    if args.verbose:
        print("Writing",len( summary_records ),"records to",args.no_upload)
    summary_records.to_csv( args.no_upload )
else:
    if args.verbose:
        print("Uploading",len(summary_records),"records.")

    error_label = "ImportToDataEntry" 
    for from_index in range(0,len(summary_records),args.records_per_upload):
        # Upload next block of records of new data to REDCap
        to_index = min( from_index + args.records_per_upload, len(summary_records) )
        if args.verbose:
            print("Uploading records",from_index,"to",to_index-1)
        
        import_response =  session.redcap_import_record(error_label, "", "", "UploadRecords", summary_records[from_index:to_index])
        if import_response :
            # Count uploaded records
            if 'count' in list(import_response.keys()):
                uploaded_count += import_response['count']
            if 'error' in list(import_response.keys()):
                slog.info(error_label + "-" + hashlib.sha1(str(import_response['error']).encode()).hexdigest()[0:6], "ERROR: Uploading Data", error_msg = str(import_response['error']))
            if 'fields' in list(import_response.keys()):
                slog.info(error_label + "-" + hashlib.sha1(str(import_response['fields']).encode()).hexdigest()[0:6], "Info: something wrong with fields ! Not sure what to do !", fields =  str(import_response['fields']))
            if 'records' in list(import_response.keys()):
                slog.info(error_label + "-" + hashlib.sha1(str(import_response['records']).encode()).hexdigest()[0:6], "Info: something wrong with redcords ! Not sure what to do !", records =  str(import_response['records']))
                
     # Finally, print upload status if so desired                    
    if args.verbose:
        print("Successfully uploaded %d/%d records to REDCap." % ( uploaded_count, len( summary_records ) ))

    # Update location and device as these are entered manually later 
    if isinstance(summary_records_secondary, pandas.DataFrame) and not summary_records_secondary.empty:
        update_record= imported_records.loc[summary_records_secondary['cnp_datasetid']]
        summary_records_secondary['cnp_exam_location']=update_record['exam_location'].tolist()
        summary_records_secondary['cnp_input_device']=update_record['input_device'].tolist()
        summary_records_secondary= summary_records_secondary[['cnp_input_device','cnp_exam_location']]
        summary_records_secondary=summary_records_secondary[summary_records_secondary['cnp_exam_location'] != '']
        summary_records_secondary=summary_records_secondary[summary_records_secondary['cnp_input_device'] != '']
        if len(summary_records_secondary):
            if args.verbose:
                print("Uploading records", summary_records_secondary)
                
            summary_records_secondary['cnp_exam_location'] = pandas.to_numeric(summary_records_secondary['cnp_exam_location']).astype(int)
            summary_records_secondary['cnp_input_device'] = pandas.to_numeric(summary_records_secondary['cnp_input_device']).astype(int)
            session.redcap_import_record(error_label, "", "", "UploadRecords",summary_records_secondary)

slog.takeTimer1("script_time","{'records': " + str(len(summary_records)) + ", 'uploads': " +  str(uploaded_count) + "}")
