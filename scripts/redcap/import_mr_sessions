#!/usr/bin/env python

##
##  See COPYING file distributed along with the ncanda-data-integration package
##  for the copyright and license terms
##

from __future__ import print_function
from __future__ import division
from builtins import str
from past.utils import old_div
import os
import re
import ast
import sys
import time
import hashlib
import datetime
import argparse
import operator

import yaml
import redcap
import pandas as pd

import sibispy
from sibispy import sibislogger as slog
from sibispy import utils as sutils
from sibispy import redcap_to_casesdir 
# import export_redcap_to_pipeline as rcpipeline

import import_mr_sessions_stroop as stroop
import export_mr_sessions_pipeline as mrpipeline


#
# GLOBAL VARIABLES 
# 
today = time.strftime(sutils.date_format_ymd)

# grefieldmap is not listed here as called dependent from  
ncanda_scan_types = [ 't1spgr', 'mprage', 't2fse', 'dti6b500pepolar', 'dti30b400', 'dti60b1000', 'rsfmri', 'pe1-dti6b3000','pe2-dti6b3000', 'dti96b3000', 'alcpic', 
                     'mlalcpic' ]

site_map = {
    'A': 'upmc',
    'B': 'sri',
    'C': 'duke',
    'D': 'ohsu',
    'E': 'ucsd',
}

#
# Local Variables
#

#
# Recovery arm helpers
#
RECOVERY_EVENTS = ("recovery_baseline_arm_2", "recovery_final_arm_2")
RECOVERY_FINAL_EVENT = "recovery_final_arm_2"
RECOVERY_DAYS_WINDOW = 3        # used to establish search window for recovery arm events

def is_recovery_event(event_label):
    return event_label in RECOVERY_EVENTS

def get_recovery_event_dates_for_subject(visit_log_redcap, subject_label):
    out = []
    for ev in RECOVERY_EVENTS:
        try:
            d = visit_log_redcap.loc[(subject_label, ev), "visit_date"]
        except Exception:
            continue
        if d is not None and str(d) != "nan":
            out.append((ev, str(d)))
    return out

def get_recovery_final_date_for_subject(visit_log_redcap, subject_label):
    """
    Treat subject as being in recovery arm iff recovery_final_arm_2
    exists and has a non-null visit_date in REDCap.
    Returns YYYY-MM-DD string or None.
    """
    try:
        d = visit_log_redcap.loc[(subject_label, RECOVERY_FINAL_EVENT), "visit_date"]
    except Exception:
        return None
    if d is None:
        return None
    d = str(d)
    return None if d == "nan" else d

def in_recovery_final_window(session_date, recovery_final_date, inclusive_end=True):
    """
    True iff session_date is within [recovery_final_date, recovery_final_date+RECOVERY_DAYS_WINDOW]
    (inclusive_end controls whether +RECOVERY_DAYS_WINDOW is inclusive).
    Dates are YYYY-MM-DD strings.
    """
    if not recovery_final_date:
        return False
    end = (datetime.datetime.strptime(recovery_final_date, sutils.date_format_ymd)
           + datetime.timedelta(RECOVERY_DAYS_WINDOW)).strftime(sutils.date_format_ymd)
    return (session_date >= recovery_final_date) and ((session_date <= end) if inclusive_end else (session_date < end))


#
# Functions 
# 
def get_sessions_in_range(redcap_visit_id,xnat, subject_label, project_id, subject_id, date_range_from, date_range_to, verbose, inclusive_end=True):
    #print "get_sessions_in_range", redcap_visit_id,xnat, subject_label, project_id, subject_id, date_range_from, date_range_to

    # Specify comparison function for the end date
    if inclusive_end:
        before_or_on = operator.le
    else:
        before_or_on = operator.lt
    sessions_in_range = []
    for session_id, session_subject_id, projects, date, scanner in xnat_sessions_list:
        if (subject_id == session_subject_id) and (date >= date_range_from) and before_or_on(date, date_range_to):
            sessions_in_range.append((session_id, projects, date))

    if not sessions_in_range:
        # handling special cases 
        if verbose: 
            print("  No session in range for ", subject_id, date_range_from, date_range_to)

        # Outside visit window
        exception_list = exceptions_window.get(subject_id)
        if exception_list:
            for except_entry in exception_list.split(';'):
                [e_eid,e_visit] = except_entry.split(',')
                if (e_visit >= date_range_from) and before_or_on(e_visit, date_range_to):
                    for eid, session_subject_id, projects, date, scanner in xnat_sessions_list:
                        if eid == e_eid : 
                            if subject_id != session_subject_id:
                                error='The eid defined in outside_visit_window of special_cases.yml is not correct as subject_id associated with eid in xnat does not match the subject id associated with the eid in special_cases.yml'
                                slog.info(redcap_visit_id,error,
                                          expected_subject_id=subject_id,
                                          xnat_subject_id=session_subject_id,
                                          xnat_visit_id = e_eid
                                )
                                return sessions_in_range

                            else:
                                if verbose: 
                                    print("  Exception: Adding session", e_eid, projects, date) 

                                sessions_in_range.append((e_eid, projects, date))

        # Session might have changed site - this is not necessary - bug in code 
        # if not sessions_in_range and subject_label in export_measures_map.iterkeys():
        #     orig_subject_id = export_measures_map.get(subject_label).get('default').get('xnat_subject_id')
        #     for session_id, session_subject_id, projects, date, scanner in xnat_sessions_list:
        #         if (orig_subject_id == session_subject_id) and (date >= date_range_from) and (date <= date_range_to):
        #             if verbose: 
        #                 print "  Exception: Session (", session_id, projects, date , ") changed site - used ", orig_subject_id ," to find session!"  
        #             sessions_in_range.append((session_id, projects, date))            

    return sessions_in_range


# Get URIs for spiral data (Stroop and resting state, where they exist)
def get_spiral_uris( xnat_eid_list ):
    spiral_uri = ''
    spiralrest_uri = ''
    for xnat_eid in xnat_eid_list:
        resource_dict_list = xnat._get_json( '/data/experiments/%s/resources/' %xnat_eid )
        for res in resource_dict_list:
            if 'spiral' in res['label'].lower():
                resource_id = res['xnat_abstractresource_id']
                eid = res['cat_id']
                obj = xnat._get_json('/data/experiments/%s/resources/%s/files' %(eid, resource_id))
                if len( obj ) > 0:
                    file_path = obj[0]['Name']
                    if 'rest' in res['label'].lower():
                        spiralrest_uri = "/".join([eid, resource_id, file_path])
                    else:
                        spiral_uri = "/".join([eid, resource_id, file_path])

    return (spiral_uri, spiralrest_uri)

def get_phantom_scans_for_date( date, scanner ):
    return [ session for (session,sscanner,sdate) in xnat_phantom_sessions_list if (sdate == date) and (sscanner == scanner) ]

def get_phantom_scans_for_date_24h( yesterday, tomorrow, scanner ):
    return [ session for (session,sscanner,sdate) in xnat_phantom_sessions_list if ((sdate == yesterday) or (sdate == tomorrow)) and (sscanner == scanner) ]


#
# Get list of all usable scans in the experiments listed
#
def get_usable_scans_list( session, xnat_eid_list, redcap_visit_id, xnat_sid):
    result = []

    for xnat_eid in xnat_eid_list:
        xnat_exp = session.xnat_get_experiment(xnat_eid)
        xnat_url = session.get_xnat_session_address(xnat_eid)
        if not xnat_exp : 
            slog.info(redcap_visit_id + "-" + hashlib.sha1(xnat_eid.encode()).hexdigest()[0:6],"ERROR: could not get experiment",
                      info="Most likely due to internet connection! Please rerun script for subject and visit", 
                      redcap_visit_id = redcap_visit_id,
                      xnat_sid = xnat_sid)
            return [None,True]  

        for scan in xnat_exp.scans.keys():
            try : 
                type = xnat_exp.scans[scan].type or ''
                quality = xnat_exp.scans[scan].quality or ''
            except Exception as err_msg:
                slog.info(redcap_visit_id + "-" + str(scan) + "-" + hashlib.sha1(str(err_msg).encode()).hexdigest()[0:6],
                          "ERROR: could not get type and quality of scan",
                          info="Most likely due to internet connection! Please rerun script for subject and visit", 
                          redcap_visit_id = redcap_visit_id,
                          xnat_sid = xnat_sid,
                          xnat_eid = xnat_eid,
                          xnat_url=xnat_url,
                          scan = scan,
                          err_msg = str(err_msg))

                return [None,True] 
 
            if quality == 'usable':
                result.append( ( type, xnat_eid, xnat_url, scan ) )

    return [result,False]

#
# Get scans from a list, selected by type
#

def get_scans_by_type(red2cas, usable_scans_list, visit_date, redcap_visit_id,
                      event_label=None, recovery_event_dates=None):

    result = {}
    for typ in ncanda_scan_types:
        pat = re.compile(rf'^ncanda-(?:pe\d-)?{re.escape(typ)}-v\d+$', re.IGNORECASE)

        scans = sorted(
            [
                (eid, xnat_url, scan,
                 red2cas.days_between_dates(visit_date, xnat_sessions_dict[eid][0]))
                for (scan_type, eid, xnat_url, scan) in usable_scans_list
                if pat.match(scan_type)
            ],
            key=lambda x: abs(x[3])  # closest to visit date
        )

        if not scans:
            continue

        # always take the closest
        result[typ] = scans[0]

        if len(scans) > 1:
            # Suppress "multiple usable scans" info if the only extras are on recovery event dates
            suppress = False
            if event_label and (not is_recovery_event(event_label)) and recovery_event_dates:
                cand_dates = [xnat_sessions_dict[eid][0] for (eid, _, _, _) in scans]
                nonrec = [d for d in cand_dates if d not in recovery_event_dates]
                rec    = [d for d in cand_dates if d in recovery_event_dates]

                # suppress iff there's exactly one non-recovery candidate and at least one recovery-dated extra
                suppress = (len(nonrec) == 1 and len(rec) >= 1)

            if not suppress:
                try:
                    shortlist = [(s[0], s[2], s[3]) for s in scans[:3]]
                except Exception:
                    shortlist = None
                slog.info(
                    redcap_visit_id,
                    f"INFO: multiple usable scans for type {typ}; choosing closest to visit date.",
                    eid_and_scan_number=str(shortlist) if shortlist else str(len(scans)),
                    type=str(typ),
                )
    return result


#
# Get fieldmap series for a given scan series (either DTI or rs-fMRI) - this can be more than one, because Siemens writes two under the same type
#
def get_fieldmap_scans( usable_scans_list, for_scan, scannerMfg,redcap_visit_id, exceptions_num_type):
    matched_fieldmaps = [ (eid,scan) for (type,eid,xnat_url,scan) in usable_scans_list if 'grefieldmap' in type and for_scan[0]==eid ]

    # only point out if we have more usable scans than needed so it is correctly labelled in xnat
    # if they are not enough scans it should have been cought before otherwise need to add another round of exception /get error message twice
    # as it is originally checked in check_new_sessions
    exception_list = exceptions_num_type.get(redcap_visit_id) 
    if exception_list and 'grefieldmap' in exception_list:
        return matched_fieldmaps
        
    if scannerMfg == "SIEMENS":
        if len(matched_fieldmaps) > 2 : 
            slog.info(redcap_visit_id,"Error: More than two usable grefieldmaps!",
                      number_of_scans = str(len(matched_fieldmaps)),
                      xnat_visit_id = for_scan[0], 
                      scanner_mfg = scannerMfg)

    elif scannerMfg == "GE":
        if len(matched_fieldmaps) > 1 : 
            slog.info(redcap_visit_id,"Error: More than one usable grefieldmaps!",
                      number_of_scans = str(len(matched_fieldmaps)),
                      xnat_visit_id = for_scan[0], 
                      scanner_mfg = scannerMfg)

    elif len(matched_fieldmaps) > 0 : 
            slog.info(redcap_visit_id,"Error: Scanner manufacturer not known even though usable grefieldmap exists!",
                      number_of_scans = str(len(matched_fieldmaps)),
                      xnat_visit_id = for_scan[0], 
                      scanner_mfg = scannerMfg)
            return []
        
    return matched_fieldmaps

def get_eid_from_scan_list(session_and_scan, sType):
    if sType in list(session_and_scan.keys()): 
        return session_and_scan[sType][0]
    return None

#
# Encode session and scan in a single string
#
def encode_session_and_scan(session_and_scan, type_list, match_eid = None ):
    # GE and siemens use different names for scans such as mprage and t1spgr
    for type in type_list:
        if type in list(session_and_scan.keys()): 
            type_id = session_and_scan[type][0]
            if not match_eid :
                return "%s/%s" % (type_id,session_and_scan[type][2])

            if type_id == match_eid:
                return "%s/%s" % (type_id,session_and_scan[type][2])

            id_list = [type_id,match_eid] if type_id < match_eid else [match_eid,type_id]
            exception_id = merge_xnat_sessions.get(id_list[0])
            if exception_id and exception_id  == id_list[1] :
                return "%s/%s" % (type_id,session_and_scan[type][2])

    return ""


# Get URIs for ALCPIC E-Prime files (edat2/txt) wherever they exist at the experiment level
def get_alcpic_uris(xnat_eid_list, redcap_key_str, xnat_pid, match_eid=None):
    """
    Mimics get_spiral_uris style; returns a single space-separated string of
    'EID/RESOURCE_ID/relative/path' tokens for ALCPIC files.
    - redcap_key_str: the prefix used in filenames (e.g., 'A-00140-M-9')
    - latest_only: if True, keep only the newest by date (YYYYMMDD) per EID

    Additional parameters for catching:
    - grabs if file is named alpic rather than alcpic.
    - 
    """
    # Edat file name pattern, will loosely grab anything close to alcpic (c optional)
    pat = re.compile(
        r'(?:(\d{8}).*)?al(?:c)?pic\.(?:edat\d+|txt)$', re.IGNORECASE
    )

    if match_eid is not None:
        xnat_eid_list = [eid for eid in xnat_eid_list if eid == match_eid]

    hits = []  # (eid, datestr, token)
    for eid in xnat_eid_list:
        # 1) list experiment-level resources
        resources = xnat._get_json(f'/data/experiments/{eid}/resources/') or []

        # Prefer resources that look relevant by tags/label/content first
        def _is_alcpic_res(r):
            lbl = (r.get('label') or '').lower()
            tags = (r.get('tags') or '').lower()
            cnt  = (r.get('content') or '').lower()
            return ('alcpic' in tags) or ('alpic' in tags) or \
                   ('alcpic' in lbl)  or ('alpic' in lbl)  or \
                   ('alcpic' in cnt)  or ('alpic' in cnt)

        prioritized = [r for r in resources if _is_alcpic_res(r)]
        to_scan = prioritized if prioritized else resources

        # 2) list files for each resource, filter by filename rule
        for r in to_scan:
            rid = r.get('xnat_abstractresource_id')
            if not rid:
                continue
            files = xnat._get_json(f'/data/experiments/{eid}/resources/{rid}/files') or []
            for f in files:
                uri = (f.get("URI") or "")
                if "/files/" in uri:
                    rel = uri.split("/files/", 1)[1].lstrip("/")
                else:
                    rel = (f.get("Name") or f.get("name") or "").lstrip("/")

                base = os.path.basename(rel)
                m = pat.search(base)
                if m:
                    datestr = m.group(1)  # YYYYMMDD
                    token = "/".join([eid, str(rid), rel])
                    hits.append((eid, datestr, token))

    if not hits:
        return ''
    elif len(hits) > 2:
        # Do not run import for when there are two instances of eprime files
        error = 'Multiple Eprime files found for task-fMRI in XNAT.'
        slog.info(
            eid, 
            error,
            number_eprime_files_found=len(hits),
            assumed_eprime_files_number=2,
            files_found=hits,
            subject_id=redcap_key_str,
            xnat_site=xnat_pid,
            error_description="There are more than the expected Eprime files found "
            "for the alcpic task-fMRI in XNAT. There should only be one .txt and one "
            ".edat2 eprime file.",
            site_resolution="Remove the duplicate/extra eprime files and inform datacore "
            "when done along with which files were removed as a comment below and note in XNAT."
        )
        return ''

    # Sort newest-first (string sort works on YYYYMMDD)
    hits.sort(key=lambda t: (t[1] or ""), reverse=True)
    
    # All matches (newest first)
    return " ".join(tok for _, _, tok in hits)

#
# Get data from XNAT for one subject/visit date
#
#  Returned result is a dictionary of keys and values to enter into the REDCap record for this subject/visit
#

def get_xnat_data(session,red2cas, redcap_key, xnat, xnat_sid, xnat_pid, pipe_id, visit_date, date_of_birth,
                  next_visit_date, mri_inspection_completed, mri_session_report_complete, 
                  mri_session_report_eid, verbose=None):
    subject = redcap_key[0]
    event = redcap_key[1]

    # normalize NaN/None to empty string
    if mri_session_report_eid is None or (isinstance(mri_session_report_eid, float) and pd.isna(mri_session_report_eid)):
        mri_session_report_eid = ''
    else:
        mri_session_report_eid = str(mri_session_report_eid)

    recovery_final_date = get_recovery_final_date_for_subject(visit_log_redcap, subject)

    result = dict()

    # Initialize result as "nothing there"
    result['mr_session_report_complete'] = ''
    result['mri_xnat_sid'] = ''
    result['mri_xnat_eids'] = ''
    result['mri_qa_completed'] = ''
    result['mri_t1_date'] = ''
    result['mri_t1_age'] = ''
    result['mri_dti_date'] = ''
    result['mri_dti_age'] = ''
    result['mri_rsfmri_date'] = ''
    result['mri_rsfmri_age'] = ''
    result['mri_notes'] = ''
    result['mri_adni_phantom'] = ''
    result['mri_adni_phantom_eid'] = ''

    result['mri_series_t1'] = ''
    result['mri_series_t2'] = ''
    result['mri_series_dti6b500pepolar'] = ''
    result['mri_series_dti30b400'] = ''
    result['mri_series_dti60b1000'] = ''
    result['mri_series_dti6b3000'] = ''
    result['mri_series_dti96b3000'] = ''
    result['mri_series_dti_fieldmap'] = ''
    result['mri_series_rsfmri'] = ''
    result['mri_series_rsfmri_fieldmap'] = ''
    result['mri_series_taskfmri_alcpic_scan'] = ''
    result['mri_series_taskfmri_alcpic_eprime'] = ''
    result['mri_scanner'] = ''
    result['mri_site'] = ''

    # First, see if this subject is in the XNAT database and has a scan session
    # for the given date or later
    max_after = RECOVERY_DAYS_WINDOW if is_recovery_event(event) else args.max_days_after_visit
    visit_date_plusNd = (
        datetime.datetime.strptime(visit_date, sutils.date_format_ymd)
        + datetime.timedelta(max_after)
    ).strftime(sutils.date_format_ymd)

    # only truncate by next visit for non-recovery events
    if (not is_recovery_event(event)) and next_visit_date and next_visit_date < visit_date_plusNd:
        visit_date_plusNd = next_visit_date
        if verbose:
            print("Due to next visit date being within visit date range, the visit date range is shortened to (", visit_date , ", " , visit_date_plusNd +").")  

    if verbose:
        print("Checking {} for {} with visit date {} to {}".format(subject,
                                                                   event,
                                                                   visit_date,
                                                                   visit_date_plusNd))

    # Get project and subject IDs for this subject by name
    redcap_visit_id=subject+"-"+visit_date

    if subject not in list(subject_project_dict.keys()):
        slog.info(redcap_visit_id,"Subject cannot be found in XNAT!",
                  subject = subject, 
                  xnat_subject_id=xnat_sid)
        return [None,True]

    # Get all experiments for this subject within the range of the visit date
    # First, exclude the end date; only include it if there are no hits.
    xnat_session_data = get_sessions_in_range(redcap_visit_id, xnat,
                                              subject,
                                              xnat_pid,
                                              xnat_sid,
                                              visit_date,
                                              visit_date_plusNd,
                                              verbose,
                                              inclusive_end=False)
    if not xnat_session_data:
        if verbose:
            print ("XNAT Session Data: No initial hits. Retrying with range"
                   " end-date {} now in the search".format(visit_date_plusNd))
        xnat_session_data = get_sessions_in_range(redcap_visit_id, xnat,
                                                  subject, xnat_pid, xnat_sid,
                                                  visit_date,
                                                  visit_date_plusNd, verbose,
                                                  inclusive_end=True)


    if verbose:
        print("XNAT Session Data:", xnat_session_data)

    # For standard-arm events, do NOT pull in sessions that fall within the recovery-final
    # [recovery_final_date, recovery_final_date+3d] window (if recovery_final_date exists).
    # This prevents recovery-final scans from contaminating standard-arm rescans window while
    # still allowing shared standard/recovery-baseline sessions.
    if (not is_recovery_event(event)) and recovery_final_date and xnat_session_data:
        before = list(xnat_session_data)
        xnat_session_data = [
            (sid, proj, dt)
            for (sid, proj, dt) in xnat_session_data
            if not in_recovery_final_window(dt, recovery_final_date, inclusive_end=True)
        ]
        if verbose and len(before) != len(xnat_session_data):
            removed = [(sid, proj, dt) for (sid, proj, dt) in before if (sid, proj, dt) not in xnat_session_data]
            print("INFO: Excluding sessions in recovery-final window for standard event {}: {}".format(event, removed))

    if not xnat_session_data:
        if today > visit_date_plusNd:
            # TODO: Check that today - date_of_birth doesn't fall into one of
            # the exceptions (if subject is 23, 25, or 26)
            error = 'Missing MRI for Subject with visit date.'
            age = round(old_div(red2cas.days_between_dates(date_of_birth, visit_date), 365.242), 2)
            age_note = ("Participant age on visit date was %.2f. It is "
                        "possible that scan wasn't acquired because protocol "
                        "states that scans be skipped at ages 23, 25, and 26."
                        % age)

            replication_cmd = f"{os.path.realpath(__file__)} -f --study-id {redcap_visit_id[:11]}"
            if args.pipeline_root_dir:
                replication_cmd += f" --pipeline-root-dir {args.pipeline_root_dir}"
            if args.run_pipeline_script:
                replication_cmd += f" --run-pipeline-script {args.run_pipeline_script}"



            try:
                dag = xnat_pid.replace('_incoming', '')
            except AttributeError:
                dag = None

            slog.info(redcap_visit_id,
                      error,
                      xnat_project_id=xnat_pid,
                      xnat_subject_id=xnat_sid,
                      visit_id=event,
                      visit_date=visit_date,
                      age_note=age_note,
                      replication_cmd=replication_cmd,
                      site_forward=dag,
                      site_resolution="If you believe the scan exists, please "
                      "upload it to XNAT. If the scan wasn't acquired, please "
                      "mark the MR Session Report as permanently missing and "
                      "state the reason. If the scan was acquired outside of "
                      "the 120-day visit window, please contact the Datacore "
                      "to set an exception.")
        return [None,True]


    # Get the experiment IDs for all sessions in the given range
    xnat_eid_list = [session_id for (session_id, project, date) in xnat_session_data]
    if not len(xnat_eid_list):
        return [result,False]

    result['mri_xnat_sid'] = pipe_id

    # Add New Variables 
    # this failed a lot 
    # scanner_model_str = 'xnat:mrSessionData/scanner/model'
    # scanner_model = xnat.select.experiment(xnat_eid).attrs.get(scanner_model_str)
    # scanner_mfc_str = 'xnat:mrSessionData/scanner/manufacturer'
    # scanner_mfc = xnat.select.experiment(xnat_eid).attrs.get(scanner_mfc_str)
    # Does not work if the scanner label is actually not defined  
    # field_regex = '.*<xnat:scanner manufacturer="(.*?)" model="(.*?)">(.*?)</xnat:scanner>'
    first_eid = xnat_eid_list[0]
    field_regex = '.*<xnat:scanner manufacturer="(.*?)" model="(.*?)"'
    match = re.match(field_regex, xnat.raw_text(xnat.select.experiments[first_eid]), flags=re.DOTALL)
    scannerMfc = "" 
    if match:
        scannerMfc = match.group(1).upper().split(" ",1)[0]
        result['mri_scanner'] = match.group(1) + " " + match.group(2) + " " + str(xnat.select.experiments[first_eid].get('scanner'))

    # For all experiments we have found, get list of all "usable" scans
    [usable_scans_list,errFlag] = get_usable_scans_list(session, xnat_eid_list, redcap_visit_id, xnat_sid)
    if errFlag : 
        if verbose : 
            print("ERROR: Failed to get usable scans for ", redcap_visit_id, "(" +  xnat_sid + ")!")
        return [None, True]

    # Now each of the standard NCANDA scans from the usable list - select
    # closes to "visit_date" if there is more than one for a given type
    # precompute subject recovery event dates (used only to suppress benign multi-scan INFO)
    recovery_event_dates = set(d for (_, d) in get_recovery_event_dates_for_subject(visit_log_redcap, subject))
    scans_by_type = get_scans_by_type(
        red2cas, usable_scans_list, visit_date, redcap_visit_id,
        event_label=event, recovery_event_dates=recovery_event_dates
    )

    result['mri_series_t2'] = encode_session_and_scan(scans_by_type, ['t2fse'])
    # Make sure sessions are from the same experiment 
    struct_eid = get_eid_from_scan_list(scans_by_type,'t2fse')
    result['mri_series_t1'] = encode_session_and_scan(scans_by_type, ['t1spgr', 'mprage'],struct_eid)

    # Get fieldmap series for the DTI and the rs-fMRI scans
    if 'dti60b1000' in list(scans_by_type.keys()) and 'dti6b500pepolar' in list(scans_by_type.keys()) :
        # Make sure all scans  are from the same experiment

        result['mri_series_dti6b500pepolar'] = encode_session_and_scan(scans_by_type, ['dti6b500pepolar'])
        dti_eid = get_eid_from_scan_list(scans_by_type,'dti6b500pepolar')

        result['mri_series_dti60b1000'] = encode_session_and_scan( scans_by_type, ['dti60b1000'],dti_eid)
        result['mri_series_dti30b400'] = encode_session_and_scan( scans_by_type, ['dti30b400'],dti_eid)

        fieldmaps_dti60 = get_fieldmap_scans(usable_scans_list, scans_by_type['dti60b1000'],scannerMfc,redcap_visit_id, exceptions_num_type)
        result['mri_series_dti_fieldmap'] = ' '.join(['%s/%s' % (eid,scan) for (eid, scan) in fieldmaps_dti60])

        result['mri_dti_date'] = xnat_sessions_dict[scans_by_type['dti60b1000'][0]][0]
        result['mri_dti_age'] = str(round(old_div(red2cas.days_between_dates( date_of_birth, result['mri_dti_date']), 365.242),10))

    if 'rsfmri' in list(scans_by_type.keys()):
        result['mri_series_rsfmri'] = encode_session_and_scan( scans_by_type, ['rsfmri'])

        # only choose gradient map that was acquired in the same session as fmri scan
        fieldmaps_rsfmri = get_fieldmap_scans( usable_scans_list, scans_by_type['rsfmri'],scannerMfc,redcap_visit_id, exceptions_num_type)
        result['mri_series_rsfmri_fieldmap'] = ' '.join(['%s/%s' % (eid,scan) for (eid, scan) in fieldmaps_rsfmri])

        result['mri_rsfmri_date'] = xnat_sessions_dict[scans_by_type['rsfmri'][0]][0]
        result['mri_rsfmri_age'] = str(round(old_div(red2cas.days_between_dates(date_of_birth, result['mri_rsfmri_date']), 365.242),10))

    # new dti6b and dti96b series
    if 'pe1-dti6b3000' in list(scans_by_type.keys()) and 'dti96b3000' in list(scans_by_type.keys()) :
        # Joe: removed dependcy from dti_eid - as it can be differernt session then dti6 !
        # only importance is that dti96b3000 and dit6b3000 are from same session !
        result['mri_series_dti96b3000'] = encode_session_and_scan(scans_by_type, ['dti96b3000'])
        dti96_eid = get_eid_from_scan_list(scans_by_type,'dti96b3000')

        dti6p1=encode_session_and_scan( scans_by_type, ['pe1-dti6b3000'],dti96_eid)
        dti6p2=encode_session_and_scan( scans_by_type, ['pe2-dti6b3000'],dti96_eid)
        if dti6p2 :
            result['mri_series_dti6b3000'] = "{} {}".format(dti6p1, dti6p2)
        else :
            result['mri_series_dti6b3000'] = dti6p1

    # alpic task fMRI series
    if 'alcpic' in scans_by_type:
        result['mri_series_taskfmri_alcpic_scan'] = encode_session_and_scan(scans_by_type, ['alcpic'])

        # Build the filename prefix your uploader uses; commonly just the subject ID
        redcap_key_str = redcap_key[0] if isinstance(redcap_key, (list, tuple)) else redcap_key

        # Exactly like spiral, we return "EID/RESOURCE_ID/Name" tokens (space-separated)
        chosen_eid = scans_by_type['alcpic'][0]
        result['mri_series_taskfmri_alcpic_eprime'] = get_alcpic_uris(xnat_eid_list, redcap_key_str, xnat_pid, match_eid=chosen_eid)        

    for xnat_eid in xnat_eid_list:
        result['mri_xnat_eids'] += xnat_eid + ' '
        note = xnat.select.experiments[xnat_eid].note or ''
        experiment_note = note.strip()
        if len(experiment_note) > 0:
            result['mri_notes'] += '[%s] %s ' % (xnat_eid, re.sub('&quot;', '"', experiment_note))

    # Take off extra spaces
    result['mri_xnat_eids'] = result['mri_xnat_eids'].strip()
    result['mri_notes'] = result['mri_notes'].strip()

    # mlalcpic task fMRI series (could be recovery or standard arm, only take what is for standard currently)
    if 'mlalcpic' in scans_by_type and 'alcpic' not in scans_by_type:
        # If there is no EID, this is the first scan being uploaded, assuming standard arm scan
        # or if there is an EID, check that current session eid matches what is already in mr_session_report
        if mri_session_report_eid == '' or mri_session_report_eid in result['mri_xnat_eids']:
            result['mri_series_taskfmri_alcpic_scan'] = encode_session_and_scan(scans_by_type, ['mlalcpic'])

            # Build the filename prefix your uploader uses; commonly just the subject ID
            redcap_key_str = redcap_key[0] if isinstance(redcap_key, (list, tuple)) else redcap_key

            # Exactly like spiral, we return "EID/RESOURCE_ID/Name" tokens (space-separated)
            chosen_eid = scans_by_type['mlalcpic'][0]
            result['mri_series_taskfmri_alcpic_eprime'] = get_alcpic_uris(
                xnat_eid_list, redcap_key_str, xnat_pid, match_eid=chosen_eid
            )


    # Get the uri's for the spiral task and spiral resting state
    (result['mri_eid_spiral_stroop'], result['mri_eid_spiral_rest']) = get_spiral_uris(xnat_eid_list)

    # Get the T1w data (MPRAGE or SPGR) and its associated ADNI phantom scan
    if 't1spgr' in list(scans_by_type.keys()):
        t1w_experiment_data = xnat_sessions_dict[scans_by_type['t1spgr'][0]]
    elif 'mprage' in list(scans_by_type.keys()):
        t1w_experiment_data = xnat_sessions_dict[scans_by_type['mprage'][0]]
    else:
        if verbose :
            print("INFO: no T1w-MRI found for session so QA status will be set to incomplete (0)!") 
        t1w_experiment_data = None

    if t1w_experiment_data:
        # Compute age at T1w scan
        result['mri_t1_date'] = t1w_experiment_data[0]
        result['mri_t1_age'] = str(round(old_div(red2cas.days_between_dates( date_of_birth, t1w_experiment_data[0]), 365.242),10))

        # Find ADNI phantom scan in appropriate date range (either same day or within 24h)
        # Found same-day phantom scan?
        phantom_scans = get_phantom_scans_for_date(t1w_experiment_data[0], t1w_experiment_data[1])
        if len(phantom_scans):
            result['mri_adni_phantom'] = '1' # Found same day
            result['mri_adni_phantom_eid'] = phantom_scans[0]
        else:
            # No - look one day before and after
            this_date = datetime.datetime.strptime( t1w_experiment_data[0], sutils.date_format_ymd)
            tomorrow = (this_date + datetime.timedelta(1)).strftime(sutils.date_format_ymd)
            yesterday = (this_date - datetime.timedelta(1)).strftime(sutils.date_format_ymd)

            # Search for all sessions on previous day after given time, or next day before given time (we already know there isn't a scan on the same date)
            phantom_scans = get_phantom_scans_for_date_24h(yesterday, tomorrow, t1w_experiment_data[1])

            # Found it now or not?
            if len(phantom_scans):
                result['mri_adni_phantom'] = '2'  # Found 24h
                result['mri_adni_phantom_eid'] = phantom_scans[0]
            else:
                result['mri_adni_phantom'] = '3'  # Missing

    # Get custom variables of the "Reading" group
    try:
        t1w_experiment = xnat.select.projects[xnat_pid].subjects[xnat_sid].experiments[re.sub('/.*', '', result['mri_series_t1'])]
        [ result['mri_datetodvd'], result['mri_findingsdate'], result['mri_findings'],
        result['mri_excludefromanalysis'], result['mri_referredtopi']] = xnat.get_custom_variables( t1w_experiment, [ 'DateToDVD', 'FindingsDate', 'Findings', 'ExcludeFromAnalysis', 'ReferredToPI'], '')
    except KeyError:
        def _empty_init(obj, f):
            obj[f] = ''
        any(_empty_init(result, x) for x in ['mri_datetodvd', 'mri_findingsdate', 'mri_findings', 'mri_excludefromanalysis', 'mri_referredtopi'])

    # Check if images have received reading and have either been labeled 'normal' or marked as checked
    if (result['mri_findings'].lower() == 'normal') or mri_inspection_completed:
        result['mri_qa_completed'] = '1'
    else:
        result['mri_qa_completed'] = '0'

    # Set scan site to project from xnat
    result['mri_site'] = xnat_session_data[0][1].split('_incoming>')[0].strip('<')

    # Set completion status of REDCap form based on whether QA is done (all sessions/scans looked at and no showstoppers in clinical reading)
    all_sessions_and_scans_used = [ sscn for sscn in [ result['mri_series_t1'], result['mri_series_t2'], result['mri_series_dti6b500pepolar'], result['mri_series_dti30b400'], result['mri_series_dti60b1000'],
                                                       result['mri_series_dti_fieldmap'], result['mri_series_rsfmri'], result['mri_series_rsfmri_fieldmap'] ] if sscn != '' ]
    if len( all_sessions_and_scans_used ) > 0:
        # if it was set as completed in the past it just means that something changed now (e.g. scan was marked as unusable), 
        # which should not change the status  
        if  mri_session_report_complete == 2: 
            result['mr_session_report_complete'] = 2
        else : 
            mandatory_fields = [ result[f] for f in ['mri_adni_phantom', 'mri_adni_phantom_eid', 'mri_series_t1', 'mri_series_t2', 'mri_series_dti6b500pepolar',  'mri_series_dti30b400', 'mri_series_dti60b1000',
                                                     'mri_series_dti_fieldmap', 'mri_series_rsfmri', 'mri_series_rsfmri_fieldmap'] ]
            if (result['mri_qa_completed'] == '1') and not ('' in mandatory_fields):
                result['mr_session_report_complete'] = '2'
            else:
                result['mr_session_report_complete'] = '1'
    else:
        result['mr_session_report_complete'] = '0'

    # Return the result
    return [result,False]


# Function to get a subject's next visit - this is so we can exclude MRI
# collected after the next visit date, but still within N days
def get_subject_next_visit_date(subject, after_visit_date):
    subject_visit_dates = visit_log_redcap.xs( subject, level=0 )['visit_date'].dropna()
    # Remove recovery baseline and final events from being the subject next visit date.
    subject_visit_dates = subject_visit_dates[
        ~subject_visit_dates.index.isin(["recovery_baseline_arm_2", "recovery_final_arm_2"])
    ]
    later_visits_this_subject = sorted( [ date for date in subject_visit_dates.tolist() if date > after_visit_date ] )
    if len( later_visits_this_subject ) > 0:
        return later_visits_this_subject[0]
    else:
        return None


def get_sibling_id1(subject_label):
    if subject_label in list(subject_label_to_sid_dict.keys()):
        result = subject_label_to_sid_dict[subject_label]
    else:
        result = ''
    return result


# ----------------------------------------
# MAIN 
# ----------------------------------------

# Setup command line parser
parser = argparse.ArgumentParser(description="For all subjects and visits in the REDCap database, find MR sessions in XNAT",
                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter )
parser.add_argument("-v", "--verbose",
                    help="Verbose operation",
                    action="store_true")
parser.add_argument("--max-days-after-visit",
                    help="Maximum number of days the scan session can be after the entered 'visit date' in REDCap to be assigned to a given event.",
                    action="store",
                    default=120,
                    type=int)
parser.add_argument("--site",
                    help="Limit processing by site (SRI, UCSD, OHSU, UPMC, DUKE). Multiple sites can be listed, separated by comma (',')",
                    action="store",
                    default=None )
parser.add_argument("--study-id",
                    help="Limit processing to subject id (e.g., A-00000-F-1)",
                    action="store",
                    default=None)
parser.add_argument("--event",help = "When called in combination with --study-id, only process a specific event (e.g. baseline_visit_arm_1 or 1y_visit_arm_1)",
                    action="store",
                    default=None)
parser.add_argument("--pipeline-root-dir",
                    help="Root directory of the image analysis pipeline. Newly detected imaging series will be converted to NIFTI files and put here for processing. ",
                    action="store")
parser.add_argument("--run-pipeline-script",
                    help="Run image processing pipeline if new files were exported.",
                    action="store")
parser.add_argument("-f", "--force-update",
                    help="Check all records in REDCap even if marked as complete -does not recreate image data if it already exists and did not change",
                    action="store_true")
parser.add_argument("--missing-only",
                     help="Only consider missing records in REDCap, rather than unverified ones also.",
                    action="store_true")
parser.add_argument("--force-update-stroop",
                    help="Update all Stroop records in REDCap, overwriting existing data",
                     action="store_true")
parser.add_argument("--no-stroop",
                    help="Do not check for, or upload, MRI Stroop results (ePrime files in XNAT)",
                    action="store_true")
parser.add_argument("-n", "--no-upload",
                    help="Only check correspondences; do not upload results to REDCap",
                    action="store_true")
parser.add_argument("-p", "--post-to-github", help="Post all issues to GitHub instead of std out.", action="store_true")

parser.add_argument("-t","--time-log-dir",
                    help="If set then time logs are written to that directory",
                    action="store",
                    default=None)

args = parser.parse_args()

verbose = args.verbose

if args.verbose:
    print(args)

slog.init_log(args.verbose, args.post_to_github,'NCANDA Pipeline Feeder Messages', 'import_mr_sessions', args.time_log_dir)
slog.startTimer1()

session = sibispy.Session() 
if not session.configure(ordered_config_load_flag = True) :
    if args.verbose:
        print("Error: session configure file was not found")
 
    sys.exit()

redcap_project = session.connect_server('data_entry', True) 
if not redcap_project : 
    if args.verbose:
        print("Error: Could not connect to Redcap") 

    sys.exit()

# Open connection with XNAT server
xnat = session.connect_server('xnat',True) 
if not xnat : 
    if args.verbose:
        print("Error: Could not connect to XNAT") 

    sys.exit()

# yml = os.path.join(os.path.expanduser("~"), '.server_config/config.yml')
# with open(yml, 'r') as fi:
#    sibis_config = yaml.load(fi).get('operations')
sibis_config = session.get_operations_dir()
special_cases_file = os.path.join(sibis_config, 'special_cases.yml')
if not os.path.isfile(special_cases_file) : 
    slog.info("import_mr_sesions","Error: The following file does not exist :" + special_cases_file)
    sys.exit(1)
              
# Get a list of cases outside the visit window that should be included.
with open(os.path.join(sibis_config, 'special_cases.yml')) as fi:
    special_cases = yaml.safe_load(fi)
    export_measures_map = special_cases.get('site_change').get('export_measures')
    exceptions_window = special_cases.get('outside_visit_window')
    exceptions_num_type = special_cases.get('more_of_type')
    merge_xnat_sessions = special_cases.get('merge_xnat_sessions')

form_event_mapping = redcap_project.export_instrument_event_mappings( format_type='df' )
form_key = session.get_redcap_form_key()

# Organize REDCap metadata, e.g., filter all confidential fields out of export lists, and make code-to-label lookup dictionaries
# rcpipeline.organize_metadata( redcap_project.metadata )
# Replaced by 

red2cas = redcap_to_casesdir.redcap_to_casesdir() 
if not red2cas.configure(session,redcap_project.metadata) :
    sys.exit(1)


#
# Get subject and project IDs
#
subject_project_list = session.xnat_export_general( 'xnat:subjectData', ['xnat:subjectData/SUBJECT_LABEL', 'xnat:subjectData/SUBJECT_ID','xnat:subjectData/PROJECT'], [ ('xnat:subjectData/SUBJECT_LABEL','LIKE', '%')],"subject_list")
# do not perform if not subject_project_list : as this is also true for [] !
if subject_project_list == None: 
    if args.verbose:
        print("ERROR: retrieving subject list from XNAT failed.")
    sys.exit(1)

subject_project_dict = dict()
subject_label_to_sid_dict = dict()
for subject_label, subject_id, projects in subject_project_list:
    subject_project_dict[subject_label] = (subject_id, projects)
    subject_label_to_sid_dict[subject_label] = subject_id

#
# Get all scan sessions in permissible date range for a given subject and visit
#
xnat_sessions_fields = ['xnat:mrSessionData/SESSION_ID','xnat:mrSessionData/SUBJECT_ID','xnat:mrSessionData/PROJECTS','xnat:mrSessionData/DATE','xnat:mrSessionData/SCANNER']
xnat_sessions_list = session.xnat_export_general( 'xnat:mrSessionData', xnat_sessions_fields, [ ('xnat:mrSessionData/SESSION_ID','LIKE', '%') ],"subject_session_data")
if xnat_sessions_list == None :
    if args.verbose : 
        print("ERROR: retrieving session list from XNAT failed.")

    sys.exit(1) 

xnat_sessions_dict = dict()
for ( session_id, session_subject_id, projects, date, scanner ) in xnat_sessions_list:
    xnat_sessions_dict[session_id] = ( date, scanner, projects )


#
# Get ADNI phantom scans from XNAT
#
# try:
#     xnat_phantom_sessions_list = xnat.search( 'xnat:mrSessionData', ['xnat:mrSessionData/SESSION_ID','xnat:mrSessionData/SCANNER','xnat:mrSessionData/DATE'] ).where( [ ('xnat:mrSessionData/LABEL','LIKE', '%-99999-P-9-%') ] ).items()
# except:
#     sys.exit( "ERROR: retrieving phantom session list from XNAT failed." )
xnat_phantom_sessions_list = session.xnat_export_general('xnat:mrSessionData', ['xnat:mrSessionData/SESSION_ID','xnat:mrSessionData/SCANNER','xnat:mrSessionData/DATE'], [ ('xnat:mrSessionData/LABEL','LIKE', '%-99999-P-9-%') ],'phantom_session_data')
if xnat_phantom_sessions_list  == None :
    if args.verbose:
       print("ERROR: retrieving subject list from XNAT failed.") 

    sys.exit(1)


#
# Main program loop
#
# these are the "baseline" events of the study arms that have them
baseline_events = ['baseline_visit_arm_1'] #, 'baseline_visit_arm_4']

subject_data = session.redcap_export_records("subject_data",fields=['study_id','dob','exclude','enroll_exception','siblings_enrolled','siblings_id1'], events = baseline_events, event_name='unique', format_type='df')
visit_data = session.redcap_export_records("subject_data",fields=['visit_site'], format_type='df')

if type(subject_data) == type(None) or subject_data.empty:
    if verbose: 
        print("No subjects selected") 
    sys.exit(1)

# Gather all the subject data.
subject_data = pd.concat([subject_data.xs(event, level=1)
                          for event in baseline_events])

# Get the sibling id
subject_data['siblings_id1'] = subject_data['siblings_id1'].map(get_sibling_id1)

visit_log_redcap = session.redcap_export_records("visit_log", 
                                                 fields=['study_id',
                                                         'visit_date', 'visit_ignore',
                                                         'mr_session_report_complete',
                                                         'mri_xnat_sid',
                                                         'mri_xnat_eids',
                                                         'mri_stroop_complete',
                                                         'mri_inspection',
                                                         'mri_missing'],
                                                 event_name='unique',
                                                 export_data_access_groups=True,
                                                 format_type='df')

if type(visit_log_redcap) == type(None) or visit_log_redcap.empty:
    if verbose: 
        print("No subjects selected") 
    sys.exit(1)

# Limit export by site.
if args.site:
    sites = args.site.lower().split( ',' )
    visit_log_redcap = visit_log_redcap[ visit_log_redcap['redcap_data_access_group'].map( lambda dag: dag in sites ) ]

# Limit export by site id (e.g., A-00000-F-1)
if args.study_id:
    try : 
        visit_log_redcap = visit_log_redcap.xs(args.study_id)
    except:
            print("ERROR: study_id " + args.study_id + " not found in redcap!")
            sys.exit(1)
            
    visit_log_redcap.reset_index(inplace=True)
    visit_log_redcap['study_id'] = args.study_id
    event="" 
    if args.event : 
        visit_log_redcap =  visit_log_redcap[ visit_log_redcap['redcap_event_name'] == args.event ]
        event="-"+args.event

    if len(visit_log_redcap) == 0 : 
        slog.info(args.study_id + event, "No data for this subject (and event)")
        sys.exit(1)

    visit_log_redcap.set_index(['study_id', 'redcap_event_name'],inplace=True)
      
        

# Select only events that have the "MRI Session Report" form
mri_events_list = form_event_mapping[form_event_mapping[form_key] == 'mr_session_report' ]['unique_event_name'].tolist()
get_events = lambda x: x[1] in mri_events_list
events_filter = visit_log_redcap.index.map(get_events)
columns = ['visit_date', 'visit_ignore___yes', 'mr_session_report_complete',
           'mri_xnat_sid', 'mri_inspection___completed', 'mri_missing',
           'redcap_data_access_group', 'mri_xnat_eids']
mr_sessions_redcap = visit_log_redcap[events_filter][columns]

forms_by_event_dict = dict()
for redcap_event in redcap_project.export_events():
    event_id = redcap_event['unique_event_name']
    forms_by_event_dict[event_id] = set( form_event_mapping[form_event_mapping['unique_event_name'] == event_id ][form_key].tolist() )

# Have pipeline feeder check for "excluded" subjects that might have previously entered the pipeline
if args.pipeline_root_dir:
    try:
        excluded_subjects = mr_sessions_redcap[ mr_sessions_redcap.index.map( lambda key: subject_data['exclude'][key[0]] == 1 ) ]['mri_xnat_sid'].dropna().tolist()
    except KeyError as key_err:
        bad_key = key_err.args[0]
        err_row = mr_sessions_redcap.loc[(bad_key, slice(None)), :]
        index_values = err_row.index.get_level_values('study_id').tolist()
        index_values += err_row.index.get_level_values('redcap_event_name').tolist()
        header = '-'.join(index_values)
        slog.info(
            header,
            "Subject exists in REDCap that does not exist in Arm 1.",
            info="There is a subject that exists in Redcap that is not part of subject_data, currently \
            identified cause of the discrepancy is a new subject has been created in an arm that doesn't \
            also exist in arm 1.", 
            site_resolution="1. Identify what the intended subject ID was. \n \
            2. Input any information that was entered under the incorrect subject ID to the correct \
            location. \n \
            3. Once entered, post on this issue that the incorrectly created subject can be removed."
        )
        # drop the offending key error from the mr_sessions_redcap dataframe
        mr_sessions_redcap = mr_sessions_redcap[mr_sessions_redcap.index.get_level_values('study_id') != bad_key]
        if mr_sessions_redcap.empty:
            excluded_subjects = None
        else:
            excluded_subjects = mr_sessions_redcap[ mr_sessions_redcap.index.map( lambda key: subject_data['exclude'][key[0]] == 1 ) ]['mri_xnat_sid'].dropna().tolist()
            mrpipeline.check_excluded_subjects( excluded_subjects, args.pipeline_root_dir )

# Filter out all records marked as "Complete", unless user instructed otherwise
if not args.force_update:
    mr_sessions_redcap = mr_sessions_redcap[ ~(mr_sessions_redcap['mr_session_report_complete'] > 1) ]
if args.missing_only:
    mr_sessions_redcap = mr_sessions_redcap[ ~(mr_sessions_redcap['mr_session_report_complete'] > 0) ]

# Filter out all excluded subjects
mr_sessions_redcap = mr_sessions_redcap[ mr_sessions_redcap.index.map( lambda key: False if subject_data['exclude'][key[0]] == 1 else True ) ]

# Filter out all visits where the MR Session report is permanenetly missing 
if mr_sessions_redcap.empty : 
    if args.verbose:
        print("Warning: Nothing to import !") 
    sys.exit()

mr_sessions_redcap = mr_sessions_redcap[ ~(mr_sessions_redcap['mri_missing'] > 0) ]

if args.verbose:
    print("Checking %d REDCap records." % len( mr_sessions_redcap ))


# Iterate over all remaining rows
records_uploaded = 0
index = 0
# timer is just run once for dicom conversion if timer log dir is set 
runTimerForImportToPipeline=True
xnat_dir = session.get_xnat_dir()
foundFlag=False
for [key, row] in mr_sessions_redcap.iterrows():
    index +=1 
    subject_label = key[0]
    event = key[1]

    # just start where script stopped the last time 
    #if not foundFlag :
    #    if subject_label != "E-00490-F-2" :
    #        continue 
    #    foundFlag = True 
    #    print "Found subject -skipped everything before" 

    if not subject_label in subject_project_dict:
        if args.verbose: 
            print(index, "Passing on", key , " does not exist in XNAT")
        continue

    if args.verbose: 
        print("\n====",index, "Processing", key,"====") 

    # Need to drop it otherwise upload to redcap fails 
    row = row.drop('mri_missing') 

    visit_date = str(visit_log_redcap['visit_date'][key])

    if visit_date == 'nan':
        if float(row['visit_ignore___yes']) != 1:
            error = f'Missing visit date for subject with visit data at {key[1]}.'

            project_id = redcap_project.export_project_info()['project_id']
            try :
                arm_num = int(re.search(r'arm_(\d*)', event).group(1))
                redcap_url = session.get_formattable_redcap_subject_address(project_id, arm_num, subject_label)
            except Exception as err_msg:
                redcap_url = ""
            
            slog.info(
                key[0], error, visit_id=key[1],
                site_forward=row.get('redcap_data_access_group'),
                redcap_url=redcap_url,
                site_resolution="The visit was most likely mistakenly created "
                "ahead of time. If that is the case, please set the visit to "
                "be ignored in Visit Notes, with the reason 'Temporary "
                "exclusion of a visit created ahead of time'. If the visit "
                "was not created accidentally, please set the visit date to "
                "the earliest data collection timepoint for this visit.")
    else:
        redcap_visit_id=subject_label+"-"+visit_date

        this_subject_data = subject_data.loc[key[0]]
        this_visit_data = visit_data.loc[key]

        if str( this_subject_data['dob'] ) == 'nan':
            print("Missing birthdate for subject %s" % key[0])
        else:
            # Collect all projects subject has been uploaded under
            proj_list = {projects: xnat_sid for ncanda_sid, xnat_sid, projects in subject_project_list if ncanda_sid == subject_label}
            
            default_site = site_map[subject_label[0]]   # default site based on first char in NCANDA ID
            visit_site = this_visit_data.iloc[0]             # visit_site from visit notes redcap form


            # first choose the candidate
            if pd.isna(visit_site):
                pid = f"{default_site}_incoming"
            else:
                pid = f"{visit_site}_incoming"

            sid = proj_list.get(pid)

            if sid is None:
                if args.verbose:
                    print(
                        f"INFO: No XNAT subject found for {subject_label} in project "
                        f"{pid}. Trying other projects: {list(proj_list.keys())}"
                    )

                # Try every other project that subject appears in
                for retry_pid, retry_sid in proj_list.items():
                    sid = retry_sid
                    pid = retry_pid
                    if args.verbose:
                        print(f"    Using {pid} (sid={sid}) instead")
                    break          # take the first match and stop

                # If still none, log and skip this row
                if sid is None:
                    if args.verbose:
                        print(
                        subject_label,
                        f"No XNAT session found for visit {event}. "
                        "Check visit_site in Visit-Notes or verify the scan was uploaded."
                    )
                    continue
            
            # either way pipe_id has to be default xnat subj id
            pipe_id = proj_list[f'{default_site}_incoming']

            visit_age = round(old_div(red2cas.days_between_dates( this_subject_data['dob'], visit_date ), 365.242),10)
            next_visit_date = get_subject_next_visit_date(key[0], visit_date)
            [xnat_data,errFlag] = get_xnat_data(session,red2cas,
                                      key,
                                      xnat,
                                      sid,
                                      pid,
                                      pipe_id,
                                      visit_date,
                                      this_subject_data['dob'],
                                      next_visit_date,
                                      row['mri_inspection___completed'],
                                      row['mr_session_report_complete'],
                                      row['mri_xnat_eids'],
                                      verbose=args.verbose)
            if not xnat_data and len(proj_list) > 1 and pd.isna(visit_site):
                # Couldn't find xnat session based on default values, test if session is under different project
                found_data = False
                for retry_pid, retry_sid in proj_list.items():
                    if retry_pid != pid:
                        xnat_data, errFlag = get_xnat_data(
                        session, red2cas, key, xnat, retry_sid, retry_pid, pipe_id,
                        visit_date, this_subject_data['dob'], next_visit_date,
                        row['mri_inspection___completed'], row['mr_session_report_complete'], row['mri_xnat_eids'],
                        verbose=args.verbose
                    )

                    if xnat_data:
                        found_data = True
                        # If subject changed site without visit_site being filled in, throw an error.
                        error_header = f"{key[0]}_{key[1]}-visit_site"
                        error = "Failed to get scan, visit_site is empty."
                        slog.info(
                            error_header, error,
                            Info="Failed to find XNAT session for subject based on default XNAT subject ID, "
                                "but found a result for the same NCANDA ID under a different project. This typically "
                                "occurs because a subject changed site for the scan.",
                            site_forward=row.get('redcap_data_access_group'),
                            Resolution="Fill in the visit_site variable in the Visit Notes form "
                                    "with the correct DAG/site at that timepoint. The actual returned result holds the site "
                                    "where a scan was found within the window of the visit date for the given subject.",
                            default_project_searched=f'{default_site}_incoming',
                            actual_returned_results=f'{retry_pid}, {retry_sid}'
                        )
                        break  # Exit loop as data is found
                if not found_data:
                    if args.verbose: 
                        print("INFO: No XNAT session data found after checking all available projects.")

            if errFlag:   
                if args.verbose: 
                    print("ERROR: Failed to get xnat data for ", red2cas, "(" +  sid + ")!")
                continue 
                
            if xnat_data['mri_xnat_eids'] != '':
                # Check whether this MR session also has Stroop data
                (stroop_eid,stroop_resource,stroop_file) = (None, None, None)
                if not args.no_stroop:
                    if args.force_update_stroop or not visit_log_redcap['mri_stroop_complete'][key] > 0:
                        (stroop_eid,stroop_resource,stroop_file) = stroop.check_for_stroop( xnat, xnat_data['mri_xnat_eids'].split( ' ' ), verbose=args.verbose )
                        if stroop_eid != None:
                            stroop.import_stroop_to_redcap( xnat, stroop_eid, \
                                                            stroop_resource, stroop_file, key, verbose=args.verbose, \
                                                            no_upload=args.no_upload, post_to_github=args.post_to_github, \
                                                            time_log_dir=args.time_log_dir)

                # Check if pipeline directory given and export imaging series there
                if args.pipeline_root_dir and (this_subject_data['exclude'] != 1):
                    did_export = mrpipeline.export_and_queue(
                        red2cas, redcap_visit_id, xnat, xnat_data, key,
                        args.pipeline_root_dir, xnat_dir,
                        row['mr_session_report_complete'],
                        run_pipeline_script=args.run_pipeline_script,
                        stroop=(stroop_eid, stroop_resource, stroop_file),
                        verbose=args.verbose,
                        timerFlag=runTimerForImportToPipeline
                    )
                    if did_export:
                        runTimerForImportToPipeline = False

            if not args.no_upload and (int(xnat_data['mr_session_report_complete']) > 0 or args.force_update):
                # Make session data into dict for REDCap import
                record = dict( row )
                (record['study_id'], record['redcap_event_name']) = key
                for (xnat_key, xnat_value) in xnat_data.items():
                    record[xnat_key] = xnat_value

                # only record the first upload - otherwise creating too many records
                if records_uploaded :
                    timer_label = None
                else :
                    timer_label = "mr_session_report"

                import_response =  session.redcap_import_record( redcap_visit_id, subject_label, event, timer_label, [record], import_format="json") 
                if not import_response : 
                    continue

                if 'count' in list(import_response.keys()):
                    records_uploaded += import_response['count']

                if 'error' in list(import_response.keys()):
                    slog.info(redcap_visit_id, "UPLOAD ERROR: {}".format(import_response['error']), record)

                if 'records' in list(import_response.keys()):
                    for r in import_response['records']:
                        print("\t Import Response from REDCap: ", r)


if args.verbose:
    if not args.no_upload:
        print("Successfully uploaded %d/%d records to REDCap." % ( records_uploaded, len( mr_sessions_redcap ) ))
    else:
        print("Suppressed uploading of %d records to REDCap." % ( len( mr_sessions_redcap ) ))

slog.takeTimer1("script_time","{'records': " + str(len(mr_sessions_redcap)) + ", 'uploads': " +  str(records_uploaded) + "}")

