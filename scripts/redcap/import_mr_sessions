#!/usr/bin/env python

##
##  See COPYING file distributed along with the ncanda-data-integration package
##  for the copyright and license terms
##

from __future__ import print_function
from __future__ import division
from builtins import str
from past.utils import old_div
import os
import re
import ast
import sys
import time
import hashlib
import datetime
import argparse
import operator

import yaml
import redcap
import pandas as pd

import sibispy
from sibispy import sibislogger as slog
from sibispy import utils as sutils
from sibispy import redcap_to_casesdir 
# import export_redcap_to_pipeline as rcpipeline

import import_mr_sessions_stroop as stroop
import export_mr_sessions_pipeline as mrpipeline


#
# GLOBAL VARIABLES 
# 
today = time.strftime(sutils.date_format_ymd)

ncanda_scan_types = [ 't1spgr', 'mprage', 't2fse', 'dti6b500pepolar', 'dti30b400', 'dti60b1000', 'rsfmri' ]

site_map = {
    'A': 'upmc',
    'B': 'sri',
    'C': 'duke',
    'D': 'ohsu',
    'E': 'ucsd',
}

#
# Functions 
# 
def get_sessions_in_range(redcap_visit_id,xnat, subject_label, project_id, subject_id, date_range_from, date_range_to, verbose, inclusive_end=True):
    #print "get_sessions_in_range", redcap_visit_id,xnat, subject_label, project_id, subject_id, date_range_from, date_range_to

    # Specify comparison function for the end date
    if inclusive_end:
        before_or_on = operator.le
    else:
        before_or_on = operator.lt
    sessions_in_range = []
    for session_id, session_subject_id, projects, date, scanner in xnat_sessions_list:
        if (subject_id == session_subject_id) and (date >= date_range_from) and before_or_on(date, date_range_to):
            sessions_in_range.append((session_id, projects, date))

    if not sessions_in_range:
        # handling special cases 
        if verbose: 
            print("  No session in range for ", subject_id, date_range_from, date_range_to)

        # Outside visit window
        exception_list = exceptions_window.get(subject_id)
        if exception_list:
            for except_entry in exception_list.split(';'):
                [e_eid,e_visit] = except_entry.split(',')
                if (e_visit >= date_range_from) and before_or_on(e_visit, date_range_to):
                    for eid, session_subject_id, projects, date, scanner in xnat_sessions_list:
                        if eid == e_eid : 
                            if subject_id != session_subject_id:
                                error='The eid defined in outside_visit_window of special_cases.yml is not correct as subject_id associated with eid in xnat does not match the subject id associated with the eid in special_cases.yml'
                                slog.info(redcap_visit_id,error,
                                          expected_subject_id=subject_id,
                                          xnat_subject_id=session_subject_id,
                                          xnat_visit_id = e_eid
                                )
                                return sessions_in_range

                            else:
                                if verbose: 
                                    print("  Exception: Adding session", e_eid, projects, date) 

                                sessions_in_range.append((e_eid, projects, date))

        # Session might have changed site - this is not necessary - bug in code 
        # if not sessions_in_range and subject_label in export_measures_map.iterkeys():
        #     orig_subject_id = export_measures_map.get(subject_label).get('default').get('xnat_subject_id')
        #     for session_id, session_subject_id, projects, date, scanner in xnat_sessions_list:
        #         if (orig_subject_id == session_subject_id) and (date >= date_range_from) and (date <= date_range_to):
        #             if verbose: 
        #                 print "  Exception: Session (", session_id, projects, date , ") changed site - used ", orig_subject_id ," to find session!"  
        #             sessions_in_range.append((session_id, projects, date))            

    return sessions_in_range


# Get URIs for spiral data (Stroop and resting state, where they exist)
def get_spiral_uris( xnat_eid_list ):
    spiral_uri = ''
    spiralrest_uri = ''
    for xnat_eid in xnat_eid_list:
        resource_dict_list = xnat._get_json( '/data/experiments/%s/resources/' %xnat_eid )
        for res in resource_dict_list:
            if 'spiral' in res['label'].lower():
                resource_id = res['xnat_abstractresource_id']
                eid = res['cat_id']
                obj = xnat._get_json('/data/experiments/%s/resources/%s/files' %(eid, resource_id))
                if len( obj ) > 0:
                    file_path = obj[0]['Name']
                    if 'rest' in res['label'].lower():
                        spiralrest_uri = "/".join([eid, resource_id, file_path])
                    else:
                        spiral_uri = "/".join([eid, resource_id, file_path])

    return (spiral_uri, spiralrest_uri)

def get_phantom_scans_for_date( date, scanner ):
    return [ session for (session,sscanner,sdate) in xnat_phantom_sessions_list if (sdate == date) and (sscanner == scanner) ]

def get_phantom_scans_for_date_24h( yesterday, tomorrow, scanner ):
    return [ session for (session,sscanner,sdate) in xnat_phantom_sessions_list if ((sdate == yesterday) or (sdate == tomorrow)) and (sscanner == scanner) ]


#
# Get list of all usable scans in the experiments listed
#
def get_usable_scans_list( session, xnat_eid_list, redcap_visit_id, xnat_sid):
    result = []

    for xnat_eid in xnat_eid_list:
        xnat_exp = session.xnat_get_experiment(xnat_eid)
        xnat_url = session.get_xnat_session_address(xnat_eid)
        if not xnat_exp : 
            slog.info(redcap_visit_id + "-" +  + hashlib.sha1(xnat_eid.encode()).hexdigest()[0:6],"ERROR: could not get experiment",
                      info="Most likely due to internet connection! Please rerun script for subject and visit", 
                      redcap_visit_id = redcap_visit_id,
                      xnat_sid = xnat_sid)
            return [None,True]  

        for scan in list(xnat_exp.scans):
            try : 
                type = xnat_exp.scans[scan].type or ''
                quality = xnat_exp.scans[scan].quality or ''
            except Exception as err_msg:
                slog.info(redcap_visit_id + "-" + scan + "-" + hashlib.sha1(str(err_msg).encode()).hexdigest()[0:6],
                          "ERROR: could not get type and quality of scan",
                          info="Most likely due to internet connection! Please rerun script for subject and visit", 
                          redcap_visit_id = redcap_visit_id,
                          xnat_sid = xnat_sid,
                          xnat_eid = xnat_eid,
                          xnat_url=xnat_url,
                          scan = scan,
                          err_msg = str(err_msg))

                return [None,True] 
 
            if quality == 'usable':
                result.append( ( type, xnat_eid, xnat_url, scan ) )

    return [result,False]

#
# Get scans from a list, selected by type
#

def get_scans_by_type( red2cas, usable_scans_list, visit_date, redcap_visit_id):
    result = dict()
    for type in ncanda_scan_types:
        # Get list of scans for this type; as we go, compute and sort by number of days between visit date and scan date
        # scan type has to end with -v1 otherwise it is ignored 
        scans = sorted( [ (eid, xnat_url, scan, red2cas.days_between_dates(visit_date,xnat_sessions_dict[eid][0])) for (scan_type,eid,xnat_url,scan) in usable_scans_list if re.match( '^ncanda-%s-v1$' % type, scan_type ) ], key=lambda x: abs(x[3]) )
 
        # Changed logic here should generally just be one scan across all sessions
        # if (len( scans ) == 1) or (len( scans ) > 1 and scans[0][2] < scans[1][2]): 
        if (len( scans ) == 1) :
            # either only one usable scan, or unique usable scan with lowest number of days after "visit_date"
            result[type] = scans[0]
        elif len(scans) > 1:
            slog.info(redcap_visit_id, 
                      "ERROR: more than one scan of type {} on the same visit ".format(type),
                      eid_and_scan_number=str(scans),
                      type = str(type))
    return result

#
# Get fieldmap series for a given scan series (either DTI or rs-fMRI) - this can be more than one, because Siemens writes two under the same type
#
def get_fieldmap_scans( usable_scans_list, for_scan, scannerMfg,redcap_visit_id, exceptions_num_type):
    matched_fieldmaps = [ (eid,scan) for (type,eid,xnat_url,scan) in usable_scans_list if 'grefieldmap' in type and for_scan[0]==eid ]

    # only point out if we have more usable scans than needed so it is correctly labelled in xnat
    # if they are not enough scans it should have been cought before otherwise need to add another round of exception /get error message twice
    # as it is originally checked in check_new_sessions
    exception_list = exceptions_num_type.get(redcap_visit_id) 
    if exception_list and 'grefieldmap' in exception_list:
        return matched_fieldmaps
        
    if scannerMfg == "SIEMENS":
        if len(matched_fieldmaps) > 2 : 
            slog.info(redcap_visit_id,"Error: More than two usable grefieldmaps!",
                      number_of_scans = str(len(matched_fieldmaps)),
                      xnat_visit_id = for_scan[0], 
                      scanner_mfg = scannerMfg)

    elif scannerMfg == "GE":
        if len(matched_fieldmaps) > 1 : 
            slog.info(redcap_visit_id,"Error: More than one usable grefieldmaps!",
                      number_of_scans = str(len(matched_fieldmaps)),
                      xnat_visit_id = for_scan[0], 
                      scanner_mfg = scannerMfg)

    elif len(matched_fieldmaps) > 0 : 
            slog.info(redcap_visit_id,"Error: Scanner manufacturer not known even though usable grefieldmap exists!",
                      number_of_scans = str(len(matched_fieldmaps)),
                      xnat_visit_id = for_scan[0], 
                      scanner_mfg = scannerMfg)
            return []
        
    return matched_fieldmaps

def get_eid_from_scan_list(session_and_scan, sType):
    if sType in list(session_and_scan.keys()): 
        return session_and_scan[sType][0]
    return None

#
# Encode session and scan in a single string
#
def encode_session_and_scan( session_and_scan, type_list, match_eid = None ):
    # GE and siemens use different names for scans such as mprage and t1spgr
    for type in type_list:
        if type in list(session_and_scan.keys()): 
            type_id = session_and_scan[type][0]
            if not match_eid :
                return "%s/%s" % (type_id,session_and_scan[type][2])

            if type_id == match_eid:
                return "%s/%s" % (type_id,session_and_scan[type][2])

            id_list = [type_id,match_eid] if type_id < match_eid else [match_eid,type_id]
            exception_id = merge_xnat_sessions.get(id_list[0])
            if exception_id and exception_id  == id_list[1] :
                return "%s/%s" % (type_id,session_and_scan[type][2])

    return ""

#
# Get data from XNAT for one subject/visit date
#
#  Returned result is a dictionary of keys and values to enter into the REDCap record for this subject/visit
#

def get_xnat_data(session,red2cas, redcap_key, xnat, xnat_sid, xnat_pid, pipe_id, visit_date, date_of_birth,
                  next_visit_date, mri_inspection_completed, mri_session_report_complete, verbose=None):
    subject = redcap_key[0]
    event = redcap_key[1]

    result = dict()

    # Initialize result as "nothing there"
    result['mr_session_report_complete'] = ''
    result['mri_xnat_sid'] = ''
    result['mri_xnat_eids'] = ''
    result['mri_qa_completed'] = ''
    result['mri_t1_date'] = ''
    result['mri_t1_age'] = ''
    result['mri_dti_date'] = ''
    result['mri_dti_age'] = ''
    result['mri_rsfmri_date'] = ''
    result['mri_rsfmri_age'] = ''
    result['mri_notes'] = ''
    result['mri_adni_phantom'] = ''
    result['mri_adni_phantom_eid'] = ''

    result['mri_series_t1'] = ''
    result['mri_series_t2'] = ''
    result['mri_series_dti6b500pepolar'] = ''
    result['mri_series_dti30b400'] = ''
    result['mri_series_dti60b1000'] = ''
    result['mri_series_dti_fieldmap'] = ''
    result['mri_series_rsfmri'] = ''
    result['mri_series_rsfmri_fieldmap'] = ''
    result['mri_scanner'] = ''
    result['mri_site'] = ''

    # First, see if this subject is in the XNAT database and has a scan session
    # for the given date or later
    visit_date_plusNd = (datetime.datetime.strptime( visit_date, sutils.date_format_ymd) + datetime.timedelta(args.max_days_after_visit)).strftime(sutils.date_format_ymd)
    # If we have a date for the next visit, and it's earlier than +N days (could
    # be for "Recovery" final visit), then use that date instead
    if next_visit_date and next_visit_date < visit_date_plusNd:
        visit_date_plusNd = next_visit_date
        if verbose:
            print("Due to next visit date being within visit date range, the visit date range is shortened to (", visit_date , ", " , visit_date_plusNd +").")  

    if verbose:
        print("Checking {} for {} with visit date {} to {}".format(subject,
                                                                   event,
                                                                   visit_date,
                                                                   visit_date_plusNd))

    # Get project and subject IDs for this subject by name
    redcap_visit_id=subject+"-"+visit_date

    if subject not in list(subject_project_dict.keys()):
        slog.info(redcap_visit_id,"Subject cannot be found in XNAT!",
                  subject = subject, 
                  xnat_subject_id=xnat_sid)
        return [None,True]

    # Get all experiments for this subject within the range of the visit date
    # First, exclude the end date; only include it if there are no hits.
    xnat_session_data = get_sessions_in_range(redcap_visit_id, xnat,
                                              subject,
                                              xnat_pid,
                                              xnat_sid,
                                              visit_date,
                                              visit_date_plusNd,
                                              verbose,
                                              inclusive_end=False)
    if not xnat_session_data:
        if verbose:
            print ("XNAT Session Data: No initial hits. Retrying with range"
                   " end-date {} now in the search".format(visit_date_plusNd))
        xnat_session_data = get_sessions_in_range(redcap_visit_id, xnat,
                                                  subject, xnat_pid, xnat_sid,
                                                  visit_date,
                                                  visit_date_plusNd, verbose,
                                                  inclusive_end=True)


    if verbose:
        print("XNAT Session Data:", xnat_session_data)

    if not xnat_session_data:
        if today > visit_date_plusNd:
            # TODO: Check that today - date_of_birth doesn't fall into one of
            # the exceptions (if subject is 23, 25, or 26)
            error = 'Missing MRI for Subject with visit date.'
            age = round(old_div(red2cas.days_between_dates(date_of_birth, visit_date), 365.242), 2)
            age_note = ("Participant age on visit date was %.2f. It is "
                        "possible that scan wasn't acquired because protocol "
                        "states that scans be skipped at ages 23, 25, and 26."
                        % age)

            replication_cmd = f"{os.path.realpath(__file__)} -f --study-id {redcap_visit_id[:11]}"
            if args.pipeline_root_dir:
                replication_cmd += f" --pipeline-root-dir {args.pipeline_root_dir}"
            if args.run_pipeline_script:
                replication_cmd += f" --run-pipeline-script {args.run_pipeline_script}"



            try:
                dag = xnat_pid.replace('_incoming', '')
            except AttributeError:
                dag = None

            slog.info(redcap_visit_id,
                      error,
                      xnat_project_id=xnat_pid,
                      xnat_subject_id=xnat_sid,
                      visit_id=event,
                      visit_date=visit_date,
                      age_note=age_note,
                      replication_cmd=replication_cmd,
                      site_forward=dag,
                      site_resolution="If you believe the scan exists, please "
                      "upload it to XNAT. If the scan wasn't acquired, please "
                      "mark the MR Session Report as permanently missing and "
                      "state the reason. If the scan was acquired outside of "
                      "the 120-day visit window, please contact the Datacore "
                      "to set an exception.")
        return [None,True]


    # Get the experiment IDs for all sessions in the given range
    xnat_eid_list = [session_id for (session_id, project, date) in xnat_session_data]
    if not len(xnat_eid_list):
        return [result,False]

    result['mri_xnat_sid'] = pipe_id

    # Add New Variables 
    # this failed a lot 
    # scanner_model_str = 'xnat:mrSessionData/scanner/model'
    # scanner_model = xnat.select.experiment(xnat_eid).attrs.get(scanner_model_str)
    # scanner_mfc_str = 'xnat:mrSessionData/scanner/manufacturer'
    # scanner_mfc = xnat.select.experiment(xnat_eid).attrs.get(scanner_mfc_str)
    # Does not work if the scanner label is actually not defined  
    # field_regex = '.*<xnat:scanner manufacturer="(.*?)" model="(.*?)">(.*?)</xnat:scanner>'
    first_eid = xnat_eid_list[0]
    field_regex = '.*<xnat:scanner manufacturer="(.*?)" model="(.*?)"'
    match = re.match(field_regex, xnat.raw_text(xnat.select.experiments[first_eid]), flags=re.DOTALL)
    scannerMfc = "" 
    if match:
        scannerMfc = match.group(1).upper().split(" ",1)[0]
        result['mri_scanner'] = match.group(1) + " " + match.group(2) + " " + str(xnat.select.experiments[first_eid].get('scanner'))

    # For all experiments we have found, get list of all "usable" scans
    [usable_scans_list,errFlag] = get_usable_scans_list(session, xnat_eid_list, redcap_visit_id, xnat_sid)
    if errFlag : 
        if verbose : 
            print("ERROR: Failed to get usable scans for ", redcap_visit_id, "(" +  xnat_sid + ")!")
        return [None, True]

    # Now each of the standard NCANDA scans from the usable list - select
    # closes to "visit_date" if there is more than one for a given type
    scans_by_type = get_scans_by_type(red2cas,usable_scans_list, visit_date, redcap_visit_id)

    result['mri_series_t2'] = encode_session_and_scan(scans_by_type, ['t2fse'])
    # Make sure sessions are from the same experiment 
    struct_eid = get_eid_from_scan_list(scans_by_type,'t2fse')
    result['mri_series_t1'] = encode_session_and_scan(scans_by_type, ['t1spgr', 'mprage'],struct_eid)

    # Get fieldmap series for the DTI and the rs-fMRI scans
    if 'dti60b1000' in list(scans_by_type.keys()) and 'dti6b500pepolar' in list(scans_by_type.keys()) :
        # Make sure all scans  are from the same experiment

        result['mri_series_dti6b500pepolar'] = encode_session_and_scan(scans_by_type, ['dti6b500pepolar'])
        dti_eid = get_eid_from_scan_list(scans_by_type,'dti6b500pepolar')

        result['mri_series_dti60b1000'] = encode_session_and_scan( scans_by_type, ['dti60b1000'],dti_eid)
        result['mri_series_dti30b400'] = encode_session_and_scan( scans_by_type, ['dti30b400'],dti_eid)

        fieldmaps_dti60 = get_fieldmap_scans(usable_scans_list, scans_by_type['dti60b1000'],scannerMfc,redcap_visit_id, exceptions_num_type)
        result['mri_series_dti_fieldmap'] = ' '.join(['%s/%s' % (eid,scan) for (eid, scan) in fieldmaps_dti60])

        result['mri_dti_date'] = xnat_sessions_dict[scans_by_type['dti60b1000'][0]][0]
        result['mri_dti_age'] = str(round(old_div(red2cas.days_between_dates( date_of_birth, result['mri_dti_date']), 365.242),10))

    if 'rsfmri' in list(scans_by_type.keys()):
        result['mri_series_rsfmri'] = encode_session_and_scan( scans_by_type, ['rsfmri'])

        # only choose gradient map that was acquired in the same session as fmri scan
        fieldmaps_rsfmri = get_fieldmap_scans( usable_scans_list, scans_by_type['rsfmri'],scannerMfc,redcap_visit_id, exceptions_num_type)
        result['mri_series_rsfmri_fieldmap'] = ' '.join(['%s/%s' % (eid,scan) for (eid, scan) in fieldmaps_rsfmri])

        result['mri_rsfmri_date'] = xnat_sessions_dict[scans_by_type['rsfmri'][0]][0]
        result['mri_rsfmri_age'] = str(round(old_div(red2cas.days_between_dates(date_of_birth, result['mri_rsfmri_date']), 365.242),10))


    for xnat_eid in xnat_eid_list:
        result['mri_xnat_eids'] += xnat_eid + ' '
        note = xnat.select.experiments[xnat_eid].note or ''
        experiment_note = note.strip()
        if len(experiment_note) > 0:
            result['mri_notes'] += '[%s] %s ' % (xnat_eid, re.sub('&quot;', '"', experiment_note))

    # Take off extra spaces
    result['mri_xnat_eids'] = result['mri_xnat_eids'].strip()
    result['mri_notes'] = result['mri_notes'].strip()


    # Get the uri's for the spiral task and spiral resting state
    (result['mri_eid_spiral_stroop'], result['mri_eid_spiral_rest']) = get_spiral_uris(xnat_eid_list)

    # Get the T1w data (MPRAGE or SPGR) and its associated ADNI phantom scan
    if 't1spgr' in list(scans_by_type.keys()):
        t1w_experiment_data = xnat_sessions_dict[scans_by_type['t1spgr'][0]]
    elif 'mprage' in list(scans_by_type.keys()):
        t1w_experiment_data = xnat_sessions_dict[scans_by_type['mprage'][0]]
    else:
        if verbose :
            print("INFO: no T1w-MRI found for session so QA status will be set to incomplete (0)!") 
        t1w_experiment_data = None

    if t1w_experiment_data:
        # Compute age at T1w scan
        result['mri_t1_date'] = t1w_experiment_data[0]
        result['mri_t1_age'] = str(round(old_div(red2cas.days_between_dates( date_of_birth, t1w_experiment_data[0]), 365.242),10))

        # Find ADNI phantom scan in appropriate date range (either same day or within 24h)
        # Found same-day phantom scan?
        phantom_scans = get_phantom_scans_for_date(t1w_experiment_data[0], t1w_experiment_data[1])
        if len(phantom_scans):
            result['mri_adni_phantom'] = '1' # Found same day
            result['mri_adni_phantom_eid'] = phantom_scans[0]
        else:
            # No - look one day before and after
            this_date = datetime.datetime.strptime( t1w_experiment_data[0], sutils.date_format_ymd)
            tomorrow = (this_date + datetime.timedelta(1)).strftime(sutils.date_format_ymd)
            yesterday = (this_date - datetime.timedelta(1)).strftime(sutils.date_format_ymd)

            # Search for all sessions on previous day after given time, or next day before given time (we already know there isn't a scan on the same date)
            phantom_scans = get_phantom_scans_for_date_24h(yesterday, tomorrow, t1w_experiment_data[1])

            # Found it now or not?
            if len(phantom_scans):
                result['mri_adni_phantom'] = '2'  # Found 24h
                result['mri_adni_phantom_eid'] = phantom_scans[0]
            else:
                result['mri_adni_phantom'] = '3'  # Missing

    # Get custom variables of the "Reading" group
    try:
        t1w_experiment = xnat.select.projects[xnat_pid].subjects[xnat_sid].experiments[re.sub('/.*', '', result['mri_series_t1'])]
        [ result['mri_datetodvd'], result['mri_findingsdate'], result['mri_findings'],
        result['mri_excludefromanalysis'], result['mri_referredtopi']] = xnat.get_custom_variables( t1w_experiment, [ 'DateToDVD', 'FindingsDate', 'Findings', 'ExcludeFromAnalysis', 'ReferredToPI'], '')
    except KeyError:
        def _empty_init(obj, f):
            obj[f] = ''
        any(_empty_init(result, x) for x in ['mri_datetodvd', 'mri_findingsdate', 'mri_findings', 'mri_excludefromanalysis', 'mri_referredtopi'])

    # Check if images have received reading and have either been labeled 'normal' or marked as checked
    if (result['mri_findings'].lower() == 'normal') or mri_inspection_completed:
        result['mri_qa_completed'] = '1'
    else:
        result['mri_qa_completed'] = '0'

    # Set scan site to project from xnat
    result['mri_site'] = xnat_session_data[0][1].split('_incoming>')[0].strip('<')

    # Set completion status of REDCap form based on whether QA is done (all sessions/scans looked at and no showstoppers in clinical reading)
    all_sessions_and_scans_used = [ sscn for sscn in [ result['mri_series_t1'], result['mri_series_t2'], result['mri_series_dti6b500pepolar'], result['mri_series_dti30b400'], result['mri_series_dti60b1000'],
                                                       result['mri_series_dti_fieldmap'], result['mri_series_rsfmri'], result['mri_series_rsfmri_fieldmap'] ] if sscn != '' ]
    if len( all_sessions_and_scans_used ) > 0:
        # if it was set as completed in the past it just means that something changed now (e.g. scan was marked as unusable), 
        # which should not change the status  
        if  mri_session_report_complete == 2: 
            result['mr_session_report_complete'] = 2
        else : 
            mandatory_fields = [ result[f] for f in ['mri_adni_phantom', 'mri_adni_phantom_eid', 'mri_series_t1', 'mri_series_t2', 'mri_series_dti6b500pepolar',  'mri_series_dti30b400', 'mri_series_dti60b1000',
                                                     'mri_series_dti_fieldmap', 'mri_series_rsfmri', 'mri_series_rsfmri_fieldmap'] ]
            if (result['mri_qa_completed'] == '1') and not ('' in mandatory_fields):
                result['mr_session_report_complete'] = '2'
            else:
                result['mr_session_report_complete'] = '1'
    else:
        result['mr_session_report_complete'] = '0'

    # Return the result
    return [result,False]


# Function to get a subject's next visit - this is so we can exclude MRI
# collected after the next visit date, but still within N days
def get_subject_next_visit_date(subject, after_visit_date):
    subject_visit_dates = visit_log_redcap.xs( subject, level=0 )['visit_date'].dropna()
    subject_visit_dates = subject_visit_dates[ subject_visit_dates.index.map( lambda key: key != 'recovery_baseline_arm_2' ) ] # Exclude "Recovery" baseline from list - this will usually be the MR day of a normal visit
    later_visits_this_subject = sorted( [ date for date in subject_visit_dates.tolist() if date > after_visit_date ] )
    if len( later_visits_this_subject ) > 0:
        return later_visits_this_subject[0]
    else:
        return None


def get_sibling_id1(subject_label):
    if subject_label in list(subject_label_to_sid_dict.keys()):
        result = subject_label_to_sid_dict[subject_label]
    else:
        result = ''
    return result


# ----------------------------------------
# MAIN 
# ----------------------------------------

# Setup command line parser
parser = argparse.ArgumentParser(description="For all subjects and visits in the REDCap database, find MR sessions in XNAT",
                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter )
parser.add_argument("-v", "--verbose",
                    help="Verbose operation",
                    action="store_true")
parser.add_argument("--max-days-after-visit",
                    help="Maximum number of days the scan session can be after the entered 'visit date' in REDCap to be assigned to a given event.",
                    action="store",
                    default=120,
                    type=int)
parser.add_argument("--site",
                    help="Limit processing by site (SRI, UCSD, OHSU, UPMC, DUKE). Multiple sites can be listed, separated by comma (',')",
                    action="store",
                    default=None )
parser.add_argument("--study-id",
                    help="Limit processing to subject id (e.g., A-00000-F-1)",
                    action="store",
                    default=None)
parser.add_argument("--event",help = "When called in combination with --study-id, only process a specific event (e.g. baseline_visit_arm_1 or 1y_visit_arm_1)",
                    action="store",
                    default=None)
parser.add_argument("--pipeline-root-dir",
                    help="Root directory of the image analysis pipeline. Newly detected imaging series will be converted to NIFTI files and put here for processing. ",
                    action="store")
parser.add_argument("--run-pipeline-script",
                    help="Run image processing pipeline if new files were exported.",
                    action="store")
parser.add_argument("-f", "--force-update",
                    help="Check all records in REDCap even if marked as complete -does not recreate image data if it already exists and did not change",
                    action="store_true")
parser.add_argument("--missing-only",
                     help="Only consider missing records in REDCap, rather than unverified ones also.",
                    action="store_true")
parser.add_argument("--force-update-stroop",
                    help="Update all Stroop records in REDCap, overwriting existing data",
                     action="store_true")
parser.add_argument("--no-stroop",
                    help="Do not check for, or upload, MRI Stroop results (ePrime files in XNAT)",
                    action="store_true")
parser.add_argument("-n", "--no-upload",
                    help="Only check correspondences; do not upload results to REDCap",
                    action="store_true")
parser.add_argument("-p", "--post-to-github", help="Post all issues to GitHub instead of std out.", action="store_true")

parser.add_argument("-t","--time-log-dir",
                    help="If set then time logs are written to that directory",
                    action="store",
                    default=None)

args = parser.parse_args()

verbose = args.verbose

if args.verbose:
    print(args)

slog.init_log(args.verbose, args.post_to_github,'NCANDA Pipeline Feeder Messages', 'import_mr_sessions', args.time_log_dir)
slog.startTimer1()

session = sibispy.Session() 
if not session.configure(ordered_config_load_flag = True) :
    if args.verbose:
        print("Error: session configure file was not found")
 
    sys.exit()

redcap_project = session.connect_server('data_entry', True) 
if not redcap_project : 
    if args.verbose:
        print("Error: Could not connect to Redcap") 

    sys.exit()

# Open connection with XNAT server
xnat = session.connect_server('xnat',True) 
if not xnat : 
    if args.verbose:
        print("Error: Could not connect to XNAT") 

    sys.exit()

# yml = os.path.join(os.path.expanduser("~"), '.server_config/config.yml')
# with open(yml, 'r') as fi:
#    sibis_config = yaml.load(fi).get('operations')
sibis_config = session.get_operations_dir()
special_cases_file = os.path.join(sibis_config, 'special_cases.yml')
if not os.path.isfile(special_cases_file) : 
    slog.info("import_mr_sesions","Error: The following file does not exist :" + special_cases_file)
    sys.exit(1)
              
# Get a list of cases outside the visit window that should be included.
with open(os.path.join(sibis_config, 'special_cases.yml')) as fi:
    special_cases = yaml.safe_load(fi)
    export_measures_map = special_cases.get('site_change').get('export_measures')
    exceptions_window = special_cases.get('outside_visit_window')
    exceptions_num_type = special_cases.get('more_of_type')
    merge_xnat_sessions = special_cases.get('merge_xnat_sessions')

form_event_mapping = redcap_project.export_fem( format='df' )
form_key = session.get_redcap_form_key()

# Organize REDCap metadata, e.g., filter all confidential fields out of export lists, and make code-to-label lookup dictionaries
# rcpipeline.organize_metadata( redcap_project.metadata )
# Replaced by 

red2cas = redcap_to_casesdir.redcap_to_casesdir() 
if not red2cas.configure(session,redcap_project.metadata) :
    sys.exit(1)


#
# Get subject and project IDs
#
subject_project_list = session.xnat_export_general( 'xnat:subjectData', ['xnat:subjectData/SUBJECT_LABEL', 'xnat:subjectData/SUBJECT_ID','xnat:subjectData/PROJECT'], [ ('xnat:subjectData/SUBJECT_LABEL','LIKE', '%')],"subject_list")
# do not perform if not subject_project_list : as this is also true for [] !
if subject_project_list == None: 
    if args.verbose:
        print("ERROR: retrieving subject list from XNAT failed.")
    sys.exit(1)

subject_project_dict = dict()
subject_label_to_sid_dict = dict()
for subject_label, subject_id, projects in subject_project_list:
    subject_project_dict[subject_label] = (subject_id, projects)
    subject_label_to_sid_dict[subject_label] = subject_id

#
# Get all scan sessions in permissible date range for a given subject and visit
#
xnat_sessions_fields = ['xnat:mrSessionData/SESSION_ID','xnat:mrSessionData/SUBJECT_ID','xnat:mrSessionData/PROJECTS','xnat:mrSessionData/DATE','xnat:mrSessionData/SCANNER']
xnat_sessions_list = session.xnat_export_general( 'xnat:mrSessionData', xnat_sessions_fields, [ ('xnat:mrSessionData/SESSION_ID','LIKE', '%') ],"subject_session_data")
if xnat_sessions_list == None :
    if args.verbose : 
        print("ERROR: retrieving session list from XNAT failed.")

    sys.exit(1) 

xnat_sessions_dict = dict()
for ( session_id, session_subject_id, projects, date, scanner ) in xnat_sessions_list:
    xnat_sessions_dict[session_id] = ( date, scanner, projects )


#
# Get ADNI phantom scans from XNAT
#
# try:
#     xnat_phantom_sessions_list = xnat.search( 'xnat:mrSessionData', ['xnat:mrSessionData/SESSION_ID','xnat:mrSessionData/SCANNER','xnat:mrSessionData/DATE'] ).where( [ ('xnat:mrSessionData/LABEL','LIKE', '%-99999-P-9-%') ] ).items()
# except:
#     sys.exit( "ERROR: retrieving phantom session list from XNAT failed." )
xnat_phantom_sessions_list = session.xnat_export_general('xnat:mrSessionData', ['xnat:mrSessionData/SESSION_ID','xnat:mrSessionData/SCANNER','xnat:mrSessionData/DATE'], [ ('xnat:mrSessionData/LABEL','LIKE', '%-99999-P-9-%') ],'phantom_session_data')
if xnat_phantom_sessions_list  == None :
    if args.verbose:
       print("ERROR: retrieving subject list from XNAT failed.") 

    sys.exit(1)


#
# Main program loop
#
# these are the "baseline" events of the study arms that have them
baseline_events = ['baseline_visit_arm_1'] #, 'baseline_visit_arm_4']

subject_data = session.redcap_export_records("subject_data",fields=['study_id','dob','exclude','enroll_exception','siblings_enrolled','siblings_id1'], events = baseline_events, event_name='unique', format='df')
visit_data = session.redcap_export_records("subject_data",fields=['visit_site'], format='df')

if type(subject_data) == type(None) or subject_data.empty:
    if verbose: 
        print("No subjects selected") 
    sys.exit(1)

# Gather all the subject data.
subject_data = pd.concat([subject_data.xs(event, level=1)
                          for event in baseline_events])

# Get the sibling id
subject_data['siblings_id1'] = subject_data['siblings_id1'].map(get_sibling_id1)

visit_log_redcap = session.redcap_export_records("visit_log", 
                                                 fields=['study_id',
                                                         'visit_date', 'visit_ignore',
                                                         'mr_session_report_complete',
                                                         'mri_xnat_sid',
                                                         'mri_stroop_complete',
                                                         'mri_inspection',
                                                         'mri_missing'],
                                                 event_name='unique',
                                                 export_data_access_groups=True,
                                                 format='df')

if type(visit_log_redcap) == type(None) or visit_log_redcap.empty:
    if verbose: 
        print("No subjects selected") 
    sys.exit(1)

# Limit export by site.
if args.site:
    sites = args.site.lower().split( ',' )
    visit_log_redcap = visit_log_redcap[ visit_log_redcap['redcap_data_access_group'].map( lambda dag: dag in sites ) ]

# Limit export by site id (e.g., A-00000-F-1)
if args.study_id:
    try : 
        visit_log_redcap = visit_log_redcap.xs(args.study_id)
    except:
            print("ERROR: study_id " + args.study_id + " not found in redcap!")
            sys.exit(1)
            
    visit_log_redcap.reset_index(inplace=True)
    visit_log_redcap['study_id'] = args.study_id
    event="" 
    if args.event : 
        visit_log_redcap =  visit_log_redcap[ visit_log_redcap['redcap_event_name'] == args.event ]
        event="-"+args.event

    if len(visit_log_redcap) == 0 : 
        slog.info(args.study_id + event, "No data for this subject (and event)")
        sys.exit(1)

    visit_log_redcap.set_index(['study_id', 'redcap_event_name'],inplace=True)
      
        

# Select only events that have the "MRI Session Report" form
mri_events_list = form_event_mapping[form_event_mapping[form_key] == 'mr_session_report' ]['unique_event_name'].tolist()
get_events = lambda x: x[1] in mri_events_list
events_filter = visit_log_redcap.index.map(get_events)
columns = ['visit_date', 'visit_ignore___yes', 'mr_session_report_complete',
           'mri_xnat_sid', 'mri_inspection___completed', 'mri_missing',
           'redcap_data_access_group']
mr_sessions_redcap = visit_log_redcap[events_filter][columns]

forms_by_event_dict = dict()
for redcap_event in redcap_project.events:
    event_id = redcap_event['unique_event_name']
    forms_by_event_dict[event_id] = set( form_event_mapping[form_event_mapping['unique_event_name'] == event_id ][form_key].tolist() )

# Have pipeline feeder check for "excluded" subjects that might have previously entered the pipeline
if args.pipeline_root_dir:
    try:
        excluded_subjects = mr_sessions_redcap[ mr_sessions_redcap.index.map( lambda key: subject_data['exclude'][key[0]] == 1 ) ]['mri_xnat_sid'].dropna().tolist()
    except KeyError as key_err:
        bad_key = key_err.args[0]
        err_row = mr_sessions_redcap.loc[(bad_key, slice(None)), :]
        index_values = err_row.index.get_level_values('study_id').tolist()
        index_values += err_row.index.get_level_values('redcap_event_name').tolist()
        header = '-'.join(index_values)
        slog.info(
            header,
            "Subject exists in REDCap that does not exist in Arm 1.",
            info="There is a subject that exists in Redcap that is not part of subject_data, currently \
            identified cause of the discrepancy is a new subject has been created in an arm that doesn't \
            also exist in arm 1.", 
            site_resolution="1. Identify what the intended subject ID was. \n \
            2. Input any information that was entered under the incorrect subject ID to the correct \
            location. \n \
            3. Once entered, post on this issue that the incorrectly created subject can be removed."
        )
        # drop the offending key error from the mr_sessions_redcap dataframe
        mr_sessions_redcap = mr_sessions_redcap[mr_sessions_redcap.index.get_level_values('study_id') != bad_key]
        if mr_sessions_redcap.empty:
            excluded_subjects = None
        else:
            excluded_subjects = mr_sessions_redcap[ mr_sessions_redcap.index.map( lambda key: subject_data['exclude'][key[0]] == 1 ) ]['mri_xnat_sid'].dropna().tolist()
            mrpipeline.check_excluded_subjects( excluded_subjects, args.pipeline_root_dir )

# Filter out all records marked as "Complete", unless user instructed otherwise
if not args.force_update:
    mr_sessions_redcap = mr_sessions_redcap[ ~(mr_sessions_redcap['mr_session_report_complete'] > 1) ]
if args.missing_only:
    mr_sessions_redcap = mr_sessions_redcap[ ~(mr_sessions_redcap['mr_session_report_complete'] > 0) ]

# Filter out all excluded subjects
mr_sessions_redcap = mr_sessions_redcap[ mr_sessions_redcap.index.map( lambda key: False if subject_data['exclude'][key[0]] == 1 else True ) ]

# Filter out all visits where the MR Session report is permanenetly missing 
if mr_sessions_redcap.empty : 
    if args.verbose:
        print("Warning: Nothing to import !") 
    sys.exit()

mr_sessions_redcap = mr_sessions_redcap[ ~(mr_sessions_redcap['mri_missing'] > 0) ]

if args.verbose:
    print("Checking %d REDCap records." % len( mr_sessions_redcap ))


# Iterate over all remaining rows
records_uploaded = 0
index = 0
# timer is just run once for dicom conversion if timer log dir is set 
runTimerForImportToPipeline=True
xnat_dir = session.get_xnat_dir()
foundFlag=False
for [key, row] in mr_sessions_redcap.iterrows():
    index +=1 
    subject_label = key[0]
    event = key[1]

    # just start where script stopped the last time 
    #if not foundFlag :
    #    if subject_label != "E-00490-F-2" :
    #        continue 
    #    foundFlag = True 
    #    print "Found subject -skipped everything before" 

    if not subject_label in subject_project_dict:
        if args.verbose: 
            print(index, "Passing on", key , " does not exist in XNAT")
        continue

    if args.verbose: 
        print("\n====",index, "Processing", key,"====") 

    # Need to drop it otherwise upload to redcap fails 
    row = row.drop('mri_missing') 

    visit_date = str(visit_log_redcap['visit_date'][key])

    if visit_date == 'nan':
        if float(row['visit_ignore___yes']) != 1:
            error = f'Missing visit date for subject with visit data at {key[1]}.'

            project_id = redcap_project.export_project_info()['project_id']
            try :
                arm_num = int(re.search('arm_(\d*)', event).group(1))
                redcap_url = session.get_formattable_redcap_subject_address(project_id, arm_num, subject_label)
            except Exception as err_msg:
                redcap_url = ""
            
            slog.info(
                key[0], error, visit_id=key[1],
                site_forward=row.get('redcap_data_access_group'),
                redcap_url=redcap_url,
                site_resolution="The visit was most likely mistakenly created "
                "ahead of time. If that is the case, please set the visit to "
                "be ignored in Visit Notes, with the reason 'Temporary "
                "exclusion of a visit created ahead of time'. If the visit "
                "was not created accidentally, please set the visit date to "
                "the earliest data collection timepoint for this visit.")
    else:
        redcap_visit_id=subject_label+"-"+visit_date

        this_subject_data = subject_data.loc[key[0]]
        this_visit_data = visit_data.loc[key]

        if str( this_subject_data['dob'] ) == 'nan':
            print("Missing birthdate for subject %s" % key[0])
        else:
            # Collect all projects subject has been uploaded under
            proj_list = {projects: xnat_sid for ncanda_sid, xnat_sid, projects in subject_project_list if ncanda_sid == subject_label}
            
            default_site = site_map[subject_label[0]]   # default site based on first char in NCANDA ID
            visit_site = this_visit_data[0]             # visit_site from visit notes redcap form

            if pd.isna(visit_site):
                # if visit_notes is empty, first try default based on NCANDA ID
                pid = f'{default_site}_incoming'
                sid = proj_list[pid]
            else:
                pid = f'{visit_site}_incoming'
                sid = proj_list[pid]
            
            # either way pipe_id has to be default xnat subj id
            pipe_id = proj_list[f'{default_site}_incoming']

            visit_age = round(old_div(red2cas.days_between_dates( this_subject_data['dob'], visit_date ), 365.242),10)
            next_visit_date = get_subject_next_visit_date(key[0], visit_date)
            [xnat_data,errFlag] = get_xnat_data(session,red2cas,
                                      key,
                                      xnat,
                                      sid,
                                      pid,
                                      pipe_id,
                                      visit_date,
                                      this_subject_data['dob'],
                                      next_visit_date,
                                      row['mri_inspection___completed'],
                                      row['mr_session_report_complete'],
                                      verbose=args.verbose)
            if not xnat_data and len(proj_list) > 1 and pd.isna(visit_site):
                # Couldn't find xnat session based on default values, test if session is under different project
                found_data = False
                for retry_pid, retry_sid in proj_list.items():
                    if retry_pid != pid:
                        xnat_data, errFlag = get_xnat_data(
                        session, red2cas, key, xnat, retry_sid, retry_pid, pipe_id,
                        visit_date, this_subject_data['dob'], next_visit_date,
                        row['mri_inspection___completed'], row['mr_session_report_complete'],
                        verbose=args.verbose
                    )

                    if xnat_data:
                        found_data = True
                        # If subject changed site without visit_site being filled in, throw an error.
                        error_header = f"{key[0]}_{key[1]}-visit_site"
                        error = "Failed to get scan, visit_site is empty."
                        slog.info(
                            error_header, error,
                            Info="Failed to find XNAT session for subject based on default XNAT subject ID, "
                                "but found a result for the same NCANDA ID under a different project. This typically "
                                "occurs because a subject changed site for the scan.",
                            site_forward=row.get('redcap_data_access_group'),
                            Resolution="Fill in the visit_site variable in the Visit Notes form "
                                    "with the correct DAG/site at that timepoint. The actual returned result holds the site "
                                    "where a scan was found within the window of the visit date for the given subject.",
                            default_project_searched=f'{default_site}_incoming',
                            actual_returned_results=f'{retry_pid}, {retry_sid}'
                        )
                        break  # Exit loop as data is found
                if not found_data:
                    if args.verbose: 
                        print("INFO: No XNAT session data found after checking all available projects.")

            if errFlag:   
                if args.verbose: 
                    print("ERROR: Failed to get xnat data for ", red2cas, "(" +  sid + ")!")
                continue 
                
            if xnat_data['mri_xnat_eids'] != '':
                # Check whether this MR session also has Stroop data
                (stroop_eid,stroop_resource,stroop_file) = (None, None, None)
                if not args.no_stroop:
                    if args.force_update_stroop or not visit_log_redcap['mri_stroop_complete'][key] > 0:
                        (stroop_eid,stroop_resource,stroop_file) = stroop.check_for_stroop( xnat, xnat_data['mri_xnat_eids'].split( ' ' ), verbose=args.verbose )
                        if stroop_eid != None:
                            stroop.import_stroop_to_redcap( xnat, stroop_eid, \
                                                            stroop_resource, stroop_file, key, verbose=args.verbose, \
                                                            no_upload=args.no_upload, post_to_github=args.post_to_github, \
                                                            time_log_dir=args.time_log_dir)

                # Check if pipeline directory given and export imaging series there
                if args.pipeline_root_dir and (this_subject_data['exclude'] != 1):
                    if mrpipeline.export_and_queue(red2cas, redcap_visit_id, xnat, xnat_data, key, args.pipeline_root_dir, xnat_dir, row['mr_session_report_complete'],run_pipeline_script=args.run_pipeline_script,stroop=(stroop_eid,stroop_resource,stroop_file), verbose=args.verbose , timerFlag = runTimerForImportToPipeline) :
                        # only run timer once - otherwise collect too much data
                        runTimerForImportToPipeline = False

            if not args.no_upload and (int(xnat_data['mr_session_report_complete']) > 0 or args.force_update):
                # Make session data into dict for REDCap import
                record = dict( row )
                (record['study_id'], record['redcap_event_name']) = key
                for (xnat_key, xnat_value) in xnat_data.items():
                    record[xnat_key] = xnat_value

                # only record the first upload - otherwise creating too many records
                if records_uploaded :
                    timer_label = None
                else :
                    timer_label = "mr_session_report"

                import_response =  session.redcap_import_record( redcap_visit_id, subject_label, event, timer_label, [record]) 
                if not import_response : 
                    continue

                if 'count' in list(import_response.keys()):
                    records_uploaded += import_response['count']

                if 'error' in list(import_response.keys()):
                    slog.info(redcap_visit_id, "UPLOAD ERROR: {}".format(import_response['error']), record)

                if 'records' in list(import_response.keys()):
                    for r in import_response['records']:
                        print("\t Import Response from REDCap: ", r)


if args.verbose:
    if not args.no_upload:
        print("Successfully uploaded %d/%d records to REDCap." % ( records_uploaded, len( mr_sessions_redcap ) ))
    else:
        print("Suppressed uploading of %d records to REDCap." % ( len( mr_sessions_redcap ) ))

slog.takeTimer1("script_time","{'records': " + str(len(mr_sessions_redcap)) + ", 'uploads': " +  str(records_uploaded) + "}")

