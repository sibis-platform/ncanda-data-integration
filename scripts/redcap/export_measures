#!/usr/bin/env python

##
##  See COPYING file distributed along with the ncanda-data-integration package
##  for the copyright and license terms
##

from __future__ import print_function
from __future__ import division
from builtins import str
from past.utils import old_div
import os
import re
import sys
import argparse
import datetime
import hashlib

import yaml
import pandas
from tqdm import tqdm

import sibispy
import sibispy.session
from sibispy import sibislogger as slog
from sibispy import redcap_to_casesdir
from sibispy import utils as sutils
from sibispy import redcap_locking_data

#
# Functions
#
# Function to get a subject's next visit - this is so we can exclude MRI collected after the next visit date, but still within N days
def get_subject_next_visit_date( subject, after_visit_date ):
    subject_visit_dates = visit_log_redcap.xs( subject, level=0 )['visit_date'].dropna()
    subject_visit_dates = subject_visit_dates[ subject_visit_dates.index.map( lambda key: key != 'recovery_baseline_arm_2' ) ] # Exclude "Recovery" baseline from list - this will usually be the MR day of a normal visit
    later_visits_this_subject = sorted( [ date for date in subject_visit_dates.tolist() if date > after_visit_date ] )
    if len( later_visits_this_subject ) > 0:
        return later_visits_this_subject[0]
    else:
        return None

def get_subject_site_for_visit(redcap_subject, visit_code, row):
    """
    Determines the site character from subject ID or REDCap data.

    Args:
    - redcap_subject (str): Subject's NCANDA ID (format: X-99999-X-9)
    - visit_code (str): Follow-up year visit code
    - row (pd.Series): Data row containing 'visit_site', 'mri_site', and 'mrireport_site' from REDCap

    Returns:
    - str: First character of NCANDA subject ID indicating site (e.g., 'D'), or None if error.
    """
    visit_site = row.get('visit_site')
    mri_site = row.get('mri_site')
    mrireport_site = row.get('mrireport_site')

    visit_site_na = pandas.isna(visit_site)
    mri_site_na = pandas.isna(mri_site)
    mrireport_site_na = pandas.isna(mrireport_site)

    # Case 1: Both visit site and MRI site are available
    if not visit_site_na and not mri_site_na:
        if visit_site != mri_site:
            slog.info(
                f"export_measures-{redcap_subject}-{visit_code}",
                "ERROR: Visit Site and MRI Site don't match.",
                info="Visit_site (Visit Notes) and mri_site (MRI Session Report) must match.",
                visit_site=visit_site,
                mri_site=mri_site,
                resolution="Check XNAT for incoming project, confirm site with RA's, and update variables accordingly.",
            )
            return None

        return site_map.get(visit_site, None)

    # Case 2: Only visit site is available (just return visit site)
    if not visit_site_na:
        # If mrireport_site is populated, check it also matches visit_site
        if not mrireport_site_na:
            mrireport_site = mrireport_site.upper()
            if mrireport_site != site_map.get(visit_site, None):
                slog.info(
                    f"export_measures-{redcap_subject}-{visit_code}",
                    "ERROR: Visit Site and Mrireport Site don't match.",
                    info="Visit_site (Visit Notes) and mrireport_site (MRI Report (Limesurvey)) should match.",
                    visit_site=visit_site,
                    mrireport_site=mrireport_site,
                    resolution="Check that  confirm site with RA's, and update variables accordingly.",
                )
                return None

        return site_map.get(visit_site, None)

    # Case 3: Only MRI site is available
    if not mri_site_na:
        default_site = redcap_subject[0]
        mapped_mri_site = site_map.get(mri_site, None)
        # If MRI site doesn't match the default, throw an error
        if mapped_mri_site and mapped_mri_site != default_site:
            slog.info(
                f"export_measures-{redcap_subject}-{visit_code}",
                "ERROR: MRI Site and default site don't match.",
                info="MRI site (MRI Session Report) does not match expected default site.",
                mri_site=mapped_mri_site,
                default_site=default_site,
                resolution="Verify in XNAT and update visit_site in Visit Notes to correct site.",
            )
            return None

    # Case 4: Both are missing, use default from subject ID
    return redcap_subject[0]

#
# Main 
#

# Setup command line parser
parser = argparse.ArgumentParser( description="For all subjects and visits in the REDCap database, export demographics, clinical measures, NP test scores, and other configured information into the pipeline directory tree.", formatter_class=argparse.ArgumentDefaultsHelpFormatter )
parser.add_argument( "-v", "--verbose", help="Verbose operation", action="store_true")
parser.add_argument( "--locked_form_report", help="Output a report indicating locked forms ", action="store_true")
parser.add_argument( "--site", help="Limit export by site (SRI, UCSD, OHSU, UPMC, DUKE). Multiple sites can be listed, separated by comma (',')", action="store", default=None )
parser.add_argument( "--events", help="Limit export by event labels (e.g., 'baseline_visit_arm_1'). Multiple events can be listed, separated by comma (',')", action="store", default=None )
parser.add_argument( "--subject", help="Limit export by subject site id (e.g., 'X-12345-X-9') - multiple subjects seperated with ',' .", action="store", default=None )
parser.add_argument( "--export", help="Limit export by output file (e.g., 'cddr'; do not include '.txt' suffix). Multiple exports can be listed, separated by comma (',')", action="store", default=None )
parser.add_argument( "-e", "--exclude", help="Exports Meausres for excluded subjects", action="store_true" )
parser.add_argument( "--datadict-dir", help="Provides a directory in which the script creates data dictionaries for all supported export files.", action="store", default=None )
parser.add_argument( "pipelinedir", help="Root directory of the image analysis pipeline.", action="store")
parser.add_argument("-p", "--post-to-github", help="Post all issues to GitHub instead of std out.",action="store_true")
parser.add_argument("-t", "--time-log-dir",
                    help="If set then time logs are written to that directory",
                    action="store",
                    default=None)
parser.add_argument('--progress-bar', help="Show TQDM progress bar", action="store_true")
args = parser.parse_args()

slog.init_log(args.verbose, args.post_to_github, 'NCANDA ', 'export_measures',
                args.time_log_dir)
slog.startTimer1()

global uploads
uploads = 0

# Open connection with REDCap server
session = sibispy.session.Session()
if not session.configure(ordered_config_load_flag = True):
    if args.verbose:
        print("Error: session configure file was not found")

    sys.exit()

# Site changes are mapped here to the correct case identifier.
sibis_config = session.get_operations_dir()
special_cases_file = os.path.join(sibis_config, 'special_cases.yml')
if not os.path.isfile(special_cases_file) :
    slog.info("export_measures","Error: The following file does not exist :" + special_cases_file)
    sys.exit(1)

# Get a map of subjects that changed sited
with open(os.path.join(sibis_config, 'special_cases.yml')) as fi:
    special_cases_map=yaml.safe_load(fi)

    exceeds_criteria_baseline = special_cases_map.get('exceeds_criteria_baseline')
    siblings_enrolled_yn_correction = special_cases_map.get('siblings_enrolled_yn')
    siblings_id_first_correction = special_cases_map.get('siblings_id_first')

redcap_project = session.connect_server('data_entry', True)
if not redcap_project :
    if args.verbose:
        slog.info("export_measures","Error: Could not connect to Redcap")

    sys.exit()

red2cas = redcap_to_casesdir.redcap_to_casesdir() 
if not red2cas.configure(session,redcap_project.metadata) :
    sys.exit(1)


if not session.connect_server('redcap_mysql_db', True) :
    if args.verbose:
        slog.info("export_measures","Error: Could not connect to redcap mysql db")

    sys.exit(1)


# Organize REDCap metadata, e.g., filter all confidential fields out of export lists, and make code-to-label lookup dictionaries
#red.organize_metadata( redcap_project.metadata )
# now done part as part of the configure statement 

form_event_mapping = redcap_project.export_instrument_event_mappings( format_type='df' )

# Get the 'form'/'form_name' used by this version of Redcap
form_key = session.get_redcap_form_key()

# If a directory for creating data dictionaries is given, make those first
if args.datadict_dir:
    red2cas.create_all_datadicts(args.datadict_dir)

# Open a connection with REDCap MySQL server.
if args.locked_form_report:
    engine = session.connect_server('redcap_mysql_db', True)
    if not engine :
        if args.verbose:
            print("Error: Could not connect to REDCap mysql db")

        sys.exit(1)

    if args.verbose:
        print("Configured to output a report of locked forms...")
        print("Connected to REDCap MySQL: {0}".format(engine))

    # if you do not sort it - the list arranges the form names every time differently - so you get different outputs when run seperately 
    locked_forms_name = sorted(list(redcap_project.forms))

    red_lock = redcap_locking_data.redcap_locking_data()
    red_lock.configure(session)

    locked_form_table=red_lock.report_locked_forms_all('ncanda_subject_visit_log')
    

# Open connection with XNAT server
xnat = session.connect_server('xnat',True)
if not xnat :
    if args.verbose:
        print("Error: Could not connect to XNAT")

    sys.exit(1)

#
# Get subject and project IDs
#
try:
    subject_project_list = list(xnat.search( 'xnat:subjectData', ['xnat:subjectData/SUBJECT_LABEL', 'xnat:subjectData/SUBJECT_ID','xnat:subjectData/PROJECT'] ).where( [ ('xnat:subjectData/SUBJECT_LABEL','LIKE', '%')] ).items())
except:
    sys.exit( "ERROR: retrieving subject list from XNAT failed." )

subject_label_to_sid_dict = dict()
# Always assign it to lowest subject number as this is the first (also length must be 13 chars) - no need to look up 
for ( subject_label, subject_id, projects ) in subject_project_list:
    if subject_label not in list(subject_label_to_sid_dict.keys()):         
        subject_label_to_sid_dict[subject_label] = subject_id
    elif len(subject_id) == 13 and (
        len(subject_label_to_sid_dict[subject_label]) != 13  # replace any non-canonical ID
        or subject_id < subject_label_to_sid_dict[subject_label]  # or keep the smaller 13-char one
    ):
        if args.verbose:
            print('INFO: Modified link for', subject_label,
                'from', subject_label_to_sid_dict[subject_label],
                'to', subject_id, '!')
        subject_label_to_sid_dict[subject_label] = subject_id
    elif args.verbose :
        print('INFO: Ignoring link',subject_label,'to',subject_id,'as already already linked to',subject_label_to_sid_dict[subject_label],'!')

#
# Main program loop
#
# NCANDA SPECIFIC 
baseline_events = ['baseline_visit_arm_1'] #, 'baseline_visit_arm_4']
subject_fields = ['study_id', 'dob', 'exclude', 'enroll_exception',
                  'siblings_enrolled', 'siblings_id1', 'family_id',
                  'hispanic', 'race', 'race_other_code','ndar_guid_id', 'ndar_guid_pseudo_id',
                  'ndar_guid_anomaly', 'ndar_guid_anomaly_visit',
                  'ndar_guid_aud_dx_followup', 'ndar_guid_aud_dx_initial']
subject_data = redcap_project.export_records(fields=subject_fields,
                                             events=baseline_events,
                                             event_name='unique',
                                             format_type='df')
subject_data = pandas.concat([subject_data.xs(event, level=1) for event in baseline_events])
# take out ones where exclude is not defined -otherwise causes issues!
doubleEntryList=subject_data.index.duplicated(keep='first')

if len(subject_data[doubleEntryList]):
    subjectNDList=str(subject_data[doubleEntryList].index.unique())
    slog.info("export_measures-" + hashlib.sha1(subjectNDList.encode()).hexdigest()[0:6], "ERROR: the following subjects have entries in baseline_visit_arm_1 and baseline_visit_arm_4 !",
              subject_list=subjectNDList,
              info="Currently only use demogrpahic information asssociated with baseline_visit_arm_1. Please remove subject from one of the two events to gurantee correct processing!")

    # drop the second entry right now for checking if case is excluded   
    # print(subject_data[doubleEntryList])
    subject_data=subject_data[~doubleEntryList]
    
subject_data['siblings_id1'] = subject_data['siblings_id1'].map( lambda x: subject_label_to_sid_dict[x] if x in list(subject_label_to_sid_dict.keys()) else '' )


visit_log_fields = ['study_id', 'visit_date',
                    'mri_qa_completed', 'mri_t1_age', 'mri_dti_age',
                    'mri_rsfmri_age', 'mri_scanner', 'visit_ignore', 
                    'mri_site', 'visit_site', 'mrireport_site']
visit_log_redcap = redcap_project.export_records(fields=visit_log_fields,
                                                 event_name='unique',
                                                 export_data_access_groups=True,
                                                 format_type='df')

site_map = {
    'upmc': 'A',
    'sri': 'B',
    'duke': 'C',
    'ohsu': 'D',
    'ucsd': 'E',
}

# check that all subjects listed in visit_log are also part of baseline
visit_log_subject_list=visit_log_redcap.index.get_level_values(0).drop_duplicates()
subject_data_list=subject_data.index.get_level_values(0).drop_duplicates()
missing_baseline=visit_log_subject_list[(~visit_log_subject_list.isin(subject_data_list))]

if len(missing_baseline) :
    subject_arm_missing=visit_log_redcap.loc[missing_baseline,:].index.to_list()

    #project_id = redcap_project.export_project_info()['project_id']
    #arm_name = 'Standard Protocol'
    #formattable_address = session.get_formattable_redcap_subject_address(project_id, arm_name)
    #urls = [formattable_address % (x[0]) for x in subject_arm_missing]
    
    # session.get_formattable_redcap_subject_address(
    slog.info("export_measures-" + hashlib.sha1(str(missing_baseline).encode()).hexdigest()[0:6], "ERROR: Subjects are in arms but not part of baseline.", entries = str(subject_arm_missing), info = "Please remove from redcap")

    visit_log_redcap = visit_log_redcap[ visit_log_redcap.index.map( lambda key: False if key[0] in missing_baseline else True )]

if args.site:
    sites = args.site.lower().split( ',' )
    visit_log_redcap = visit_log_redcap[ visit_log_redcap['redcap_data_access_group'].map( lambda dag: dag in sites ) ]

# Filter out all excluded subjects
if args.exclude:
    visit_log_redcap = visit_log_redcap[ visit_log_redcap.index.map( lambda key: False if subject_data['exclude'][key[0]] != 1 else True ) ]
    visit_log_redcap = visit_log_redcap[~visit_log_redcap.visit_date.isnull()]
else:
    #for key in visit_log_redcap.index:
    #    if subject_data['exclude'][key[0]] == 1 :
    #        print("1")

    visit_log_redcap = visit_log_redcap[ visit_log_redcap.index.map( lambda key: False if subject_data['exclude'][key[0]] == 1 else True ) ]


# Limit to selected events
if args.events:
    events = args.events.lower().split( ',' )
    visit_log_redcap = visit_log_redcap[ visit_log_redcap.index.map( lambda key: key[1] in events ) ]

# Filter out events not yet supported by the pipeline exporter
visit_log_redcap = visit_log_redcap[ visit_log_redcap.index.map( lambda key: key[1] in list(red2cas.get_event_dictionary().keys()) ) ]

forms_by_event_dict = dict()
for event in redcap_project.export_events():
    event_id = event['unique_event_name']
    forms_by_event_dict[event_id] = set( form_event_mapping[form_event_mapping['unique_event_name'] == event_id ][form_key].tolist() )

# Limit to selected export files
if args.export:
    select_exports = args.export.lower().split( ',' )
else:
    select_exports = None

if args.subject:
    visit_log_redcap = visit_log_redcap.loc[args.subject.split( ',' )]

if args.verbose:
    print("Exporting %d REDCap records." % len( visit_log_redcap ))

# Iterate over all remaining rows
prior_subject=''
prior_visit_ignore=False
for [key, row] in tqdm(visit_log_redcap.iterrows(),  # the actual iterator
                       total=visit_log_redcap.shape[0],
                       unit="subjects",
                       disable=not args.progress_bar):
    # map the redcap subject key to readable vars
    redcap_subject, redcap_event = key
    
    #
    # Check that visit should be exported 
    #
    if redcap_subject not in list(subject_label_to_sid_dict.keys()):
        if args.verbose:
            # there is no xnat id over entire study for this subject , thus no subhect id to write to casesdir, thus ignore  
            print("Missing XNAT ID for subject",redcap_subject)
        continue
 
    # only do sessions that are not ignore
    if row['visit_ignore___yes'] :
        prior_subject=redcap_subject
        prior_visit_ignore=True
        continue
       
    visit_date = str(row['visit_date'])
    if visit_date == 'nan':
        if args.verbose:
            print("Missing '%s' visit date for subject %s" % ( redcap_event, redcap_subject ))
        continue

    this_subject_data = subject_data.loc[redcap_subject]
    # If exclude flag is set, this will override the excludes value and export excluded subjects
    if args.exclude:
        excludes = 0.0
    else:
        excludes = 1
    
    # Check if pipeline directory given and export imaging series there
    if (this_subject_data['exclude'] == excludes):
        continue

    subject_dob_str = str( this_subject_data['dob'] )
    if not re.match( '[0-9]{4}-[0-9]{2}-[0-9]{2}', subject_dob_str ):
        error = "Missing or invalid birthdate '%s' for subject %s" % ( subject_dob_str, redcap_subject )
        slog.info(str(redcap_subject), error)
        continue 

    visit_age = old_div(red2cas.days_between_dates( subject_dob_str, visit_date ), 365.242)

    subject_pipeline_id = subject_label_to_sid_dict[redcap_subject]

    (arm_code,visit_code,subject_datadir_rel) = (None, None, None)
    try:
        (arm_code,visit_code,subject_datadir_rel) = red2cas.translate_subject_and_event( subject_pipeline_id, redcap_event )
    except: 
        slog.info("export_measures-" + redcap_subject, "ERROR: Event " + redcap_event + " is not supported yet.",
                      info = "Add event to ncanda_operations/sibis-sys-config.yml")
        continue

    if not arm_code:
        continue

    #
    # export measures
    #
    uploads += 1
    
    subject_datadir = os.path.join(args.pipelinedir,subject_datadir_rel)

    site = get_subject_site_for_visit(redcap_subject,visit_code,row)
    if not site:
        continue

    exceeds_criteria_subject = exceeds_criteria_baseline.get(subject_pipeline_id)
    if exceeds_criteria_subject == None:
          exceeds_criteria_subject_value=-1                             
    else :
          exceeds_criteria_subject_value=exceeds_criteria_subject

    siblings_enrolled_yn_subject = siblings_enrolled_yn_correction.get(subject_pipeline_id)
    if siblings_enrolled_yn_subject == None:
          siblings_enrolled_yn_subject=-1

    siblings_id_first_subject = siblings_id_first_correction.get(subject_pipeline_id)

    # Only relavent for midyear visits so that they are updated if main visits was skipped
    # the demographics of main visits are always updated but not of mid year visits so that they do not overwrite main visits demographics 
    if  prior_visit_ignore and prior_subject == redcap_subject:
        force_demo_flag=True  
    else :
        force_demo_flag=False
        
    # Export measures from RECap into the pipeline.
    red2cas.export_subject_all_forms(redcap_project,
                       site,
                       redcap_subject,
                       redcap_event,
                       this_subject_data,
                       visit_age,
                       row,
                       arm_code,
                       visit_code,
                       subject_pipeline_id,
                       subject_datadir,
                       forms_by_event_dict[redcap_event],
                       exceeds_criteria_subject_value,
                       siblings_enrolled_yn_subject,
                       siblings_id_first_subject,
                       select_exports=select_exports,
                       force_demo_flag=force_demo_flag,  
                       verbose=args.verbose)
    
    prior_subject=redcap_subject
    prior_visit_ignore=False
        
    # Write report of forms locked for this subject, arm,
    # visit
    if args.locked_form_report and arm_code == 'standard':
         # Link directory names with names in REDCap mysql
         if visit_code == 'baseline' :
             visit = "Baseline visit"
         else :
             visit = visit_code.split('_',1)[1] + " visit"
    
         # Get a dataframe of the locked forms
         arm = "{0} Protocol".format(arm_code.capitalize())

         # locked_forms = red_lock.report_locked_forms(redcap_subject, subject_pipeline_id, locked_forms_name, 'ncanda_subject_visit_log', arm, visit,locked_form_table)
         locked_forms = red_lock.report_locked_forms_from_enriched_lock_table(
             subject_id=redcap_subject,
             xnat_id=subject_pipeline_id,
             forms=locked_forms_name,
             project_name='ncanda_subject_visit_log',
             redcap_event_name=redcap_event,
             enriched_table=locked_form_table,
         )
         
         filename = os.path.join(os.path.abspath(subject_datadir), 'measures', 'locked_forms.csv')
         sutils.safe_dataframe_to_csv(locked_forms, filename, verbose=args.verbose)

slog.takeTimer1("script_time","{'records': " + str(len(visit_log_redcap)) + ", 'uploads': " +  str(uploads) + "}")
