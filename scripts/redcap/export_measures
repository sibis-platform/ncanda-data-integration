#!/usr/bin/env python

##
##  See COPYING file distributed along with the ncanda-data-integration package
##  for the copyright and license terms
##

from __future__ import print_function
from __future__ import division
from builtins import str
from past.utils import old_div
import os
import re
import sys
import argparse
import datetime
import hashlib

import yaml
import pandas
from tqdm import tqdm

import sibispy
from sibispy import sibislogger as slog
from sibispy import redcap_to_casesdir
from sibispy import utils as sutils
from sibispy import redcap_locking_data

#
# Functions
#
# Function to get a subject's next visit - this is so we can exclude MRI collected after the next visit date, but still within N days
def get_subject_next_visit_date( subject, after_visit_date ):
    subject_visit_dates = visit_log_redcap.xs( subject, level=0 )['visit_date'].dropna()
    subject_visit_dates = subject_visit_dates[ subject_visit_dates.index.map( lambda key: key != 'recovery_baseline_arm_2' ) ] # Exclude "Recovery" baseline from list - this will usually be the MR day of a normal visit
    later_visits_this_subject = sorted( [ date for date in subject_visit_dates.tolist() if date > after_visit_date ] )
    if len( later_visits_this_subject ) > 0:
        return later_visits_this_subject[0]
    else:
        return None

def get_subject_site_for_visit(redcap_subject,visit_code,export_measures_map):
    # Handle mapping demographic info for subjects that changed site
    if redcap_subject in iter(export_measures_map.keys()):
         # Only set for visits in the past
         _visit_case_id_map = export_measures_map.get(redcap_subject)
         if visit_code in iter(_visit_case_id_map.keys()):
             _case_id_map = _visit_case_id_map.get(visit_code)
         else : 
             _case_id_map = _visit_case_id_map.get('default')
             
         return _case_id_map.get('site')

    return redcap_subject[0]
#
# Main 
#

# Setup command line parser
parser = argparse.ArgumentParser( description="For all subjects and visits in the REDCap database, export demographics, clinical measures, NP test scores, and other configured information into the pipeline directory tree.", formatter_class=argparse.ArgumentDefaultsHelpFormatter )
parser.add_argument( "-v", "--verbose", help="Verbose operation", action="store_true")
parser.add_argument( "--locked_form_report", help="Output a report indicating locked forms ", action="store_true")
parser.add_argument( "--site", help="Limit export by site (SRI, UCSD, OHSU, UPMC, DUKE). Multiple sites can be listed, separated by comma (',')", action="store", default=None )
parser.add_argument( "--events", help="Limit export by event labels (e.g., 'baseline_visit_arm_1'). Multiple events can be listed, separated by comma (',')", action="store", default=None )
parser.add_argument( "--subject", help="Limit export by subject site id (e.g., 'X-12345-X-9') - multiple subjects seperated with ',' .", action="store", default=None )
parser.add_argument( "--export", help="Limit export by output file (e.g., 'cddr'; do not include '.txt' suffix). Multiple exports can be listed, separated by comma (',')", action="store", default=None )
parser.add_argument( "-e", "--exclude", help="Exports Meausres for excluded subjects", action="store_true" )
parser.add_argument( "--datadict-dir", help="Provides a directory in which the script creates data dictionaries for all supported export files.", action="store", default=None )
parser.add_argument( "pipelinedir", help="Root directory of the image analysis pipeline.", action="store")
parser.add_argument("-p", "--post-to-github", help="Post all issues to GitHub instead of std out.",action="store_true")
parser.add_argument("-t", "--time-log-dir",
                    help="If set then time logs are written to that directory",
                    action="store",
                    default=None)
parser.add_argument('--progress-bar', help="Show TQDM progress bar", action="store_true")
args = parser.parse_args()

slog.init_log(args.verbose, args.post_to_github, 'NCANDA ', 'export_measures',
                args.time_log_dir)
slog.startTimer1()

global uploads
uploads = 0

# Open connection with REDCap server
session = sibispy.Session()
if not session.configure(ordered_config_load_flag = True):
    if args.verbose:
        print("Error: session configure file was not found")

    sys.exit()

# Site changes are mapped here to the correct case identifier.
sibis_config = session.get_operations_dir()
special_cases_file = os.path.join(sibis_config, 'special_cases.yml')
if not os.path.isfile(special_cases_file) :
    slog.info("export_measures","Error: The following file does not exist :" + special_cases_file)
    sys.exit(1)

# Get a map of subjects that changed sited
with open(os.path.join(sibis_config, 'special_cases.yml')) as fi:
    special_cases_map=yaml.load(fi)
    site_change_map = special_cases_map.get('site_change')
    export_measures_map = site_change_map.get('export_measures')

    exceeds_criteria_baseline = special_cases_map.get('exceeds_criteria_baseline')
    siblings_enrolled_yn_correction = special_cases_map.get('siblings_enrolled_yn')
    siblings_id_first_correction = special_cases_map.get('siblings_id_first')

redcap_project = session.connect_server('data_entry', True)
if not redcap_project :
    if args.verbose:
        slog.info("export_measures","Error: Could not connect to Redcap")

    sys.exit()

red2cas = redcap_to_casesdir.redcap_to_casesdir() 
if not red2cas.configure(session,redcap_project.metadata) :
    sys.exit(1)


if not session.connect_server('redcap_mysql_db', True) :
    if args.verbose:
        slog.info("export_measures","Error: Could not connect to redcap mysql db")

    sys.exit(1)


# Organize REDCap metadata, e.g., filter all confidential fields out of export lists, and make code-to-label lookup dictionaries
#red.organize_metadata( redcap_project.metadata )
# now done part as part of the configure statement 

form_event_mapping = redcap_project.export_fem( format='df' )

# Get the 'form'/'form_name' used by this version of Redcap
form_key = session.get_redcap_form_key()

# If a directory for creating data dictionaries is given, make those first
if args.datadict_dir:
    red2cas.create_all_datadicts(args.datadict_dir)

# Open a connection with REDCap MySQL server.
if args.locked_form_report:
    engine = session.connect_server('redcap_mysql_db', True)
    if not engine :
        if args.verbose:
            print("Error: Could not connect to REDCap mysql db")

        sys.exit(1)

    if args.verbose:
        print("Configured to output a report of locked forms...")
        print("Connected to REDCap MySQL: {0}".format(engine))

    # if you do not sort it - the list arranges the form names every time differently - so you get different outputs when run seperately 
    locked_forms_name = sorted(list(redcap_project.forms))

    red_lock = redcap_locking_data.redcap_locking_data()
    red_lock.configure(session)

    locked_form_table=red_lock.report_locked_forms_all('ncanda_subject_visit_log')
    

# Open connection with XNAT server
xnat = session.connect_server('xnat',True)
if not xnat :
    if args.verbose:
        print("Error: Could not connect to XNAT")

    sys.exit(1)

#
# Get subject and project IDs
#
try:
    subject_project_list = list(xnat.search( 'xnat:subjectData', ['xnat:subjectData/SUBJECT_LABEL', 'xnat:subjectData/SUBJECT_ID','xnat:subjectData/PROJECT'] ).where( [ ('xnat:subjectData/SUBJECT_LABEL','LIKE', '%')] ).items())
except:
    sys.exit( "ERROR: retrieving subject list from XNAT failed." )

subject_label_to_sid_dict = dict()
# Always assign it to lowest subject number as this is the first - no need to look up 
for ( subject_label, subject_id, projects ) in subject_project_list:
    if subject_label not in list(subject_label_to_sid_dict.keys()):         
        subject_label_to_sid_dict[subject_label] = subject_id
    elif subject_id < subject_label_to_sid_dict[subject_label] :
        if args.verbose :
            print('INFO: Modified link for',subject_label,'from', subject_label_to_sid_dict[subject_label], 'to', subject_id, '!')
        subject_label_to_sid_dict[subject_label] = subject_id
    elif args.verbose :
        print('INFO: Ignoring link',subject_label,'to',subject_id,'as already already linked to',subject_label_to_sid_dict[subject_label],'!')

#
# Main program loop
#
# NCANDA SPICIFIC 
baseline_events = ['baseline_visit_arm_1', 'baseline_visit_arm_4']
subject_fields = ['study_id', 'dob', 'exclude', 'enroll_exception',
                  'siblings_enrolled', 'siblings_id1', 'family_id',
                  'hispanic', 'race', 'race_other_code']
subject_data = redcap_project.export_records(fields=subject_fields,
                                             events=baseline_events,
                                             event_name='unique',
                                             format='df')
subject_data = pandas.concat([subject_data.xs(event, level=1) for event in baseline_events])
# take out ones where exclude is not defined -otherwise causes issues!
doubleEntryList=subject_data.index.duplicated(keep='first')

if len(subject_data[doubleEntryList]):
    subjectNDList=str(subject_data[doubleEntryList].index.unique())
    slog.info("export_measures-" + hashlib.sha1(subjectNDList.encode()).hexdigest()[0:6], "ERROR: the following subjects have entries in baseline_visit_arm_1 and baseline_visit_arm_4 !",
              subject_list=subjectNDList,
              info="Currently only use demogrpahic information asssociated with baseline_visit_arm_1. Please remove subject from one of the two events to gurantee correct processing!")

    # drop the second entry right now for checking if case is excluded   
    # print(subject_data[doubleEntryList])
    subject_data=subject_data[~doubleEntryList]
    
subject_data['siblings_id1'] = subject_data['siblings_id1'].map( lambda x: subject_label_to_sid_dict[x] if x in list(subject_label_to_sid_dict.keys()) else '' )


visit_log_fields = ['study_id', 'redcap_data_access_group', 'visit_date',
                    'mri_qa_completed', 'mri_t1_age', 'mri_dti_age',
                    'mri_rsfmri_age','mri_scanner', 'visit_ignore']
visit_log_redcap = redcap_project.export_records(fields=visit_log_fields,
                                                 event_name='unique',
                                                 export_data_access_groups=True,
                                                 format='df')

# check that all subjects listed in visit_log are also part of baseline
visit_log_subject_list=visit_log_redcap.index.get_level_values(0).drop_duplicates()
subject_data_list=subject_data.index.get_level_values(0).drop_duplicates()
missing_baseline=visit_log_subject_list[(~visit_log_subject_list.isin(subject_data_list))]

if len(missing_baseline) :
    subject_arm_missing=visit_log_redcap.loc[missing_baseline,:].index.to_list()
    slog.info("export_measures-" + hashlib.sha1(str(missing_baseline).encode()).hexdigest()[0:6], "ERROR: Subjects are in arms but not part of baseline.",
              entries = str(subject_arm_missing), 
              info = "Please remove from redcap")

    visit_log_redcap = visit_log_redcap[ visit_log_redcap.index.map( lambda key: False if key[0] in missing_baseline else True )]

if args.site:
    sites = args.site.lower().split( ',' )
    visit_log_redcap = visit_log_redcap[ visit_log_redcap['redcap_data_access_group'].map( lambda dag: dag in sites ) ]

# Filter out all excluded subjects
if args.exclude:
    visit_log_redcap = visit_log_redcap[ visit_log_redcap.index.map( lambda key: False if subject_data['exclude'][key[0]] != 1 else True ) ]
    visit_log_redcap = visit_log_redcap[~visit_log_redcap.visit_date.isnull()]
else:
    #for key in visit_log_redcap.index:
    #    if subject_data['exclude'][key[0]] == 1 :
    #        print("1")

    visit_log_redcap = visit_log_redcap[ visit_log_redcap.index.map( lambda key: False if subject_data['exclude'][key[0]] == 1 else True ) ]


# Limit to selected events
if args.events:
    events = args.events.lower().split( ',' )
    visit_log_redcap = visit_log_redcap[ visit_log_redcap.index.map( lambda key: key[1] in events ) ]

# Filter out events not yet supported by the pipeline exporter
visit_log_redcap = visit_log_redcap[ visit_log_redcap.index.map( lambda key: key[1] in list(red2cas.get_event_dictionary().keys()) ) ]

forms_by_event_dict = dict()
for event in redcap_project.events:
    event_id = event['unique_event_name']
    forms_by_event_dict[event_id] = set( form_event_mapping[form_event_mapping['unique_event_name'] == event_id ][form_key].tolist() )

# Limit to selected export files
if args.export:
    select_exports = args.export.lower().split( ',' )
else:
    select_exports = None

if args.subject:
    visit_log_redcap = visit_log_redcap.loc[args.subject.split( ',' )]

if args.verbose:
    print("Exporting %d REDCap records." % len( visit_log_redcap ))

# Iterate over all remaining rows
for [key, row] in tqdm(visit_log_redcap.iterrows(),  # the actual iterator
                       total=visit_log_redcap.shape[0],
                       unit="subjects",
                       disable=not args.progress_bar):
    # map the redcap subject key to readable vars
    redcap_subject, redcap_event = key
    
    #
    # Check that visit should be exported 
    #
    if redcap_subject not in list(subject_label_to_sid_dict.keys()):
        if args.verbose:
            # there is no xnat id over entire study for this subject , thus no subhect id to write to casesdir, thus ignore  
            print("Missing XNAT ID for subject",redcap_subject)
        continue
 
    # only do sessions that are not ignored
    if row['visit_ignore___yes'] :
        continue

    visit_date = str(row['visit_date'])
    if visit_date == 'nan':
        if args.verbose:
            print("Missing '%s' visit date for subject %s" % ( redcap_event, redcap_subject ))
        continue

    this_subject_data = subject_data.loc[redcap_subject]
    # If exclude flag is set, this will override the excludes value and export excluded subjects
    if args.exclude:
        excludes = 0.0
    else:
        excludes = 1
    
    # Check if pipeline directory given and export imaging series there
    if (this_subject_data['exclude'] == excludes):
        continue

    subject_dob_str = str( this_subject_data['dob'] )
    if not re.match( '[0-9]{4}-[0-9]{2}-[0-9]{2}', subject_dob_str ):
        error = "Missing or invalid birthdate '%s' for subject %s" % ( subject_dob_str, redcap_subject )
        slog.info(str(redcap_subject), error)
        continue 

    visit_age = old_div(red2cas.days_between_dates( subject_dob_str, visit_date ), 365.242)

    subject_pipeline_id = subject_label_to_sid_dict[redcap_subject]

    (arm_code,visit_code,subject_datadir_rel) = (None, None, None)
    try:
        (arm_code,visit_code,subject_datadir_rel) = red2cas.translate_subject_and_event( subject_pipeline_id, redcap_event )
    except: 
        slog.info("export_measures-" + redcap_subject, "ERROR: Event " + redcap_event + " is not supported yet.",
                      info = "Add event to ncanda_operations/sibis-sys-config.yml")
        continue

    if not arm_code:
        continue

    #
    # export measures
    #
    uploads += 1
    
    subject_datadir = os.path.join(args.pipelinedir,subject_datadir_rel)

    site = get_subject_site_for_visit(redcap_subject,visit_code,export_measures_map)

    exceeds_criteria_subject = exceeds_criteria_baseline.get(subject_pipeline_id)
    if exceeds_criteria_subject == None:
          exceeds_criteria_subject_value=-1                             
    else :
          exceeds_criteria_subject_value=exceeds_criteria_subject

    siblings_enrolled_yn_subject = siblings_enrolled_yn_correction.get(subject_pipeline_id)
    if siblings_enrolled_yn_subject == None:
          siblings_enrolled_yn_subject=-1

    siblings_id_first_subject = siblings_id_first_correction.get(subject_pipeline_id)
           
    # Export measures from RECap into the pipeline.
    red2cas.export_subject_all_forms(redcap_project,
                       site,
                       redcap_subject,
                       redcap_event,
                       this_subject_data,
                       visit_age,
                       row,
                       arm_code,
                       visit_code,
                       subject_pipeline_id,
                       subject_datadir,
                       forms_by_event_dict[redcap_event],
                       exceeds_criteria_subject_value,
                       siblings_enrolled_yn_subject,
                       siblings_id_first_subject,
                       select_exports=select_exports,
                       verbose=args.verbose)
    
    # Write report of forms locked for this subject, arm,
    # visit
    if args.locked_form_report and arm_code == 'standard':
         # Link directory names with names in REDCap mysql
         if visit_code == 'baseline' :
             visit = "Baseline visit"
         else :
             visit = visit_code.split('_',1)[1] + " visit"
    
         # Get a dataframe of the locked forms
         arm = "{0} Protocol".format(arm_code.capitalize())

         locked_forms = red_lock.report_locked_forms(redcap_subject, subject_pipeline_id, locked_forms_name, 'ncanda_subject_visit_log', arm, visit,locked_form_table)
         
         filename = os.path.join(os.path.abspath(subject_datadir), 'measures', 'locked_forms.csv')
         sutils.safe_dataframe_to_csv(locked_forms, filename, verbose=args.verbose)

slog.takeTimer1("script_time","{'records': " + str(len(visit_log_redcap)) + ", 'uploads': " +  str(uploads) + "}")
